<!doctype html>
<meta charset="utf-8">
<script src="https://distill.pub/template.v2.js"></script>
<script src="https://d3js.org/d3.v7.min.js"></script>
<script src="https://cdn.plot.ly/plotly-3.0.1.min.js"></script>
<script src="data/top_10_per_conf.js"></script>
<script src="data/bubble-sample-data.js"></script>
<script src="data/high_impact_first_authors_rejected.js"></script>
<script src="best-rejected-papers.js" defer></script>
<script src="bubble-visualization.js" defer></script>
<script src="high-impact-first-authors.js" defer></script>
<link rel="stylesheet" href="styles.css">
<link rel="stylesheet" href="best-rejected-papers.css">
<link rel="stylesheet" href="bubble-visualization.css">
<link rel="stylesheet" href="high-impact-first-authors.css">

<!-- Fragments -->
<script src="fragments/paper_matching_success_rate.js"></script>
<script src="fragments/failed_papers_by_conference.js"></script>
<script src="fragments/citation_count_vs_review_score.js"></script>
<d-front-matter>
  <script id='distill-front-matter' type="text/json">{
    "title": " The Best Rejected Papers",
    "description": "OpenReview's radical transparency allows us to look at the quality of peer review over time.",
    "published": "Feb 19, 2025",
    "doi": "TBC",
    "authors": [
      {
        "author": "Mark Neumann",
        "authorURL": "https://markneumann.xyz",
        "affiliation":"markneumann.xyz",
        "affiliationURL":"https://markneumann.xyz"
      }
    ],
    "katex": {
      "delimiters" : [
        {"left": "$", "right": "$", "display": false}
      ]
    }
  }</script>
</d-front-matter>

<d-title>
  <h1>The Best Rejected Papers</h1>
</d-title>
<d-byline></d-byline>


<d-article>

  <h2>What is OpenReview?</h2>
  <p>
    <a href="https://openreview.net/" target="_blank">OpenReview</a> is a platform designed to
    encourage openness and public access in scientific communication, with a particular emphasis
    on the peer review process.
    It provides an <a href="https://github.com/openreview" target="_blank">open source platform</a> 
    for conferences to manage their review process. OpenReview has been used by many large Machine Learning conferences
    to manage workshops, full conference submissions and even longer running editorial review processes. 
    OpenReview.net <d-cite key="Soergel2013OpenSA"></d-cite> was created by Andrew McCallum's Information 
    Extraction and Synthesis Laboratory at UMass Amherst. 
  </p>

  <p>
   One particularly interesting feature of conference submissions using OpenReview is the
   publication of paper acceptance decisions, official reviews and fully anonymized 
   discussions surrounding paper submissions. 
  </p>

  <p>
    As these acceptance decisions are public, we can look at the quality of peer review over time (and other interesting patterns)
    by linking OpenReview submissions to external academic graphs (in this case, <a href="https://semanticscholar.org/" target="_blank">Semantic Scholar</a>).
  </p>


  <h2>The Data</h2>
  
  <p>
    Many conferences use OpenReview to manage parts of their conference process (in particular, for workshop reviewing).
    Two conferences have used OpenReview consistently to manage their main conference tracks - 
    <a href="https://openreview.net/group?id=ICLR.cc/2013/Conference" target="_blank">The International Conference on Learning Representations (ICLR)</a> and 
    <a href="https://openreview.net/group?id=NeurIPS.cc/2017/Conference" target="_blank">Neural Information Processing Systems (NeurIPS)</a>.

  In particular, we will focus on the following conference years:
  <ul>
    <li> ICLR: 2017, 2019-2025
    <li> Neurips: 2021-2025
  </ul>

  <p>
    Neurips only transitioned to OpenReview in 2021, and for 2018, OpenReview was used for ICLR reviewing but the decisions and reviews were not published.
  </p>


  </p>

  <h2>Paper Matching Success Rate</h2>

  <p>
    To link OpenReview papers to their Semantic Scholar papers, we used the <a href="https://api.semanticscholar.org/api-docs/graph" target="_blank">Semantic Scholar Graph API</a>.
    As a first step, I just used exact title matching to link papers, which is reasonably effective. 
    The largest source of errors when using this approach came from papers with LaTeX in the title, 
    as well as as papers which changed their title from a pre-print version which was already publicly available.
  </p>

  <p>
    The following chart shows the success rate of this approach over time.
  </p>

    <div id="4b284f59-68f8-4606-9df1-192afcf39a27" class="l-body-outset" style="height:500px; width:800px;"></div>


    <p>
      To catch some of these errors, I then used a second pass to approximately link papers. This used Semantic Scholar's Paper Search API to retrieve
      the top 10 search results for a given paper title. I then checked for the highest scoring result based on the following criteria:

      <ul>
        <li>
          Levenshtein distance between titles
        </li>
        <li>
          Average Levenshtein distance between authors, ordered
        </li>
        <li>
          Discarding results where the highest ranking result based on the above criteria had a title similarity of less than 0.7
        </li>
      </ul>

      This catches quite a few of the errors (particularly related to syntactical differences in the title). For some papers submitted
      to OpenReview, there actually is no publicly available paper, typically because these papers are either improved for another subsequent
      conference, or are not high enough quality to be published.
    </p>

    <p>
      To check this, we can look at the acceptance rate of papers which were not matched to a publicly available paper. As the graph below shows,
      most papers across all conferences which were not linkable were either rejected or withdrawn.
    </p>

    <div id="92dddb17-1483-4db3-afc8-0e627a1d8080" class="l-body-outset" style="height: 500px; width: 800px" ></div>



    <div id="98482921-8bd7-431e-bab8-521dcde1ff79" class="l-screen-inset" style="height: 1600px; width: 1200px; margin: 0 auto" ></div>


  <h2>üèÜ Best Rejected Papers üèÜ</h2>
  <p>Below are the most highly cited papers that were initially rejected from these conferences, organized by venue:</p>
  
  <p>
  <div id="best-rejected-visualization" style="margin-top: 20px; margin-bottom: 20px;">
    <div class="conference-tabs">
      <!-- Tab buttons will be dynamically generated based on available data -->
    </div>
    
    <div class="papers-container">
      <div id="papers-loading" class="loading-message">Loading papers...</div>
      <div id="papers-content" class="papers-content"></div>
    </div>
  </div>
  </p>




  <h2> High Impact, "Unlucky" First Authors </h2>

  <p>
    The following shows the most productive first authors whose papers were initially rejected from these conferences. 
    Each author is ranked by their average citations per year, with expandable details showing their rejected papers and citation counts.
  </p>

  <div id="high-impact-first-author-rejected-visualization" style="margin-top: 20px; margin-bottom: 20px;">
  </div>

  <p>This is a footnote <d-footnote>This will become a hoverable footnote.</d-footnote></p>

</d-article>

<d-appendix>
  <d-bibliography>
    <script type="text/bibtex">
      @article{gregor2015draw,
        title={DRAW: A recurrent neural network for image generation},
        author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
        journal={arXivreprint arXiv:1502.04623},
        year={2015},
        url={https://arxiv.org/pdf/1502.04623.pdf}
      }
      @inproceedings{Soergel2013OpenSA,
        title={Open Scholarship and Peer Review: a Time for Experimentation},
        author={David Soergel and Adam Saunders and Andrew McCallum},
        year={2013},
        url={https://api.semanticscholar.org/CorpusID:14548845}
      }
    </script>
  </d-bibliography>
  <style>
      d-appendix .citation {
          font-size: 11px;
          line-height: 15px;
          border-left: 1px solid rgba(0, 0, 0, 0.1);
          padding-left: 18px;
          border: 1px solid rgba(0, 0, 0, 0.1);
          background: rgba(0, 0, 0, 0.02);
          padding: 10px 18px;
          border-radius: 3px;
          color: rgba(150, 150, 150, 1);
          overflow: hidden;
          margin-top: -12px;
          white-space: pre-wrap;
          word-wrap: break-word;
      }
  </style>

  <h3 id="citation">Citation</h3>
  <p>For attribution in academic contexts, please cite this work as</p>
  <pre
      class="citation short">"The Distill Blog Template", 2025.</pre>
  <p>BibTeX citation</p>
  <pre class="citation long">@misc{distill_blog_template,
title={The Distill Blog Template},
author={Some Authors et al},
year={2025},
}</pre>
</d-appendix>
