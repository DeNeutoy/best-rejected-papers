window.bestRejectedPapersData = {
  iclr2017: [
    {
      id: "B1-Hhnslg",
      semantic_scholar_id: "c269858a7bb34e8350f2442ccf37797856ae9bca",
      raw_decision: "Submitted to ICLR 2017",
      normalized_decision: "Reject",
      title: "Prototypical Networks for Few-shot Learning",
      abstract:
        "A recent approach to few-shot classification called matching networks has demonstrated the benefits of coupling metric learning with a training procedure that mimics test. This approach relies on a complicated fine-tuning procedure and an attention scheme that forms a distribution over all points in the support set, scaling poorly with its size. We propose a more streamlined approach, prototypical networks, that learns a metric space in which few-shot classification can be performed by computing Euclidean distances to prototype representations of each class, rather than individual points. Our method is competitive with state-of-the-art one-shot classification approaches while being much simpler and more scalable with the size of the support set. We empirically demonstrate the performance of our approach on the Omniglot and mini-ImageNet datasets. We further demonstrate that a similar idea can be used for zero-shot learning, where each class is described by a set of attributes, and achieve state-of-the-art results on the Caltech UCSD bird dataset.",
      keywords: ["Deep learning", "Transfer Learning"],
      accepted: false,
      publication_venue: "Neural Information Processing Systems",
      publication_venue_id: "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
      url: "https://www.semanticscholar.org/paper/c269858a7bb34e8350f2442ccf37797856ae9bca",
      citation_count: 7822,
      authors: ["Jake Snell", "Kevin Swersky", "R. Zemel"],
      authorIds: ["39770136", "1754860", "1804104"],
      conference_year: 2017,
      conference_name: "iclr",
      conf_id: "iclr2017",
      review_scores: [6.0, 4.0, 5.0],
      review_score_avg: 5.0,
      review_confidences: [6.0, 4.0, 5.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "S1xh5sYgx",
      semantic_scholar_id: "592d2e65489f23ebd993dbdc0c84eda9ac8aadbe",
      raw_decision: "Submitted to ICLR 2017",
      normalized_decision: "Reject",
      title:
        "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <1MB model size",
      abstract:
        "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet).",
      keywords: ["Computer vision", "Deep learning"],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/592d2e65489f23ebd993dbdc0c84eda9ac8aadbe",
      citation_count: 7294,
      authors: [
        "F. Iandola",
        "Matthew W. Moskewicz",
        "Khalid Ashraf",
        "Song Han",
        "W. Dally",
        "K. Keutzer",
      ],
      authorIds: [
        "3346186",
        "2318023",
        "2059241",
        "143840275",
        "80724002",
        "1732330",
      ],
      conference_year: 2017,
      conference_name: "iclr",
      conf_id: "iclr2017",
      review_scores: [7.0, 5.0, 7.0],
      review_score_avg: 6.3333333333,
      review_confidences: [7.0, 5.0, 7.0],
      review_confidence_avg: 3.6666666667,
    },
    {
      id: "S1OufnIlx",
      semantic_scholar_id: "b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b",
      raw_decision: "ICLR 2017 Invite to Workshop",
      normalized_decision: "Invite to Workshop",
      title: "Adversarial examples in the physical world",
      abstract:
        "Most existing machine learning classifiers are highly vulnerable to adversarial examples.\nAn adversarial example is a sample of input data which has been modified\nvery slightly in a way that is intended to cause a machine learning classifier\nto misclassify it.\nIn many cases, these modifications can be so subtle that a human observer does\nnot even notice the modification at all, yet the classifier still makes a mistake.\nAdversarial examples pose security concerns\nbecause they could be used to perform an attack on machine learning systems, even if the adversary has no\naccess to the underlying model.\nUp to now, all previous work has assumed a threat model in which the adversary can\nfeed data directly into the machine learning classifier.\nThis is not always the case for systems operating in the physical world,\nfor example those which are using signals from cameras and other sensors as input.\nThis paper shows that even in such physical world scenarios, machine learning systems are vulnerable\nto adversarial examples.\nWe demonstrate this by feeding adversarial images obtained from a cell-phone camera\nto an ImageNet Inception classifier and measuring the classification accuracy of the system.\nWe find that a large fraction of adversarial examples are classified incorrectly\neven when perceived through the camera.",
      keywords: ["Supervised Learning", "Computer vision"],
      accepted: false,
      publication_venue: "International Conference on Learning Representations",
      publication_venue_id: "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
      url: "https://www.semanticscholar.org/paper/b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b",
      citation_count: 5719,
      authors: ["Alexey Kurakin", "I. Goodfellow", "Samy Bengio"],
      authorIds: ["145714153", "153440022", "1751569"],
      conference_year: 2017,
      conference_name: "iclr",
      conf_id: "iclr2017",
      review_scores: [6.0, 6.0, 5.0],
      review_score_avg: 5.6666666667,
      review_confidences: [6.0, 6.0, 5.0],
      review_confidence_avg: 3.3333333333,
    },
    {
      id: "rJXTf9Bxg",
      semantic_scholar_id: "ecc0edd450ae7e52f65ddf61405b30ad6dbabdd7",
      raw_decision: "Submitted to ICLR 2017",
      normalized_decision: "Reject",
      title: "Conditional Image Synthesis with Auxiliary Classifier GANs",
      abstract:
        "Synthesizing high resolution photorealistic images has been a long-standing challenge in machine learning. In this paper we introduce new methods for the improved training of generative adversarial networks (GANs) for image synthesis. We construct a variant of GANs employing label conditioning that results in 128x128 resolution image samples exhibiting global coherence. We expand on previous work for image quality assessment to provide two new analyses for assessing the discriminability and diversity of samples from class-conditional image synthesis models. These analyses demonstrate that high resolution samples provide class information not present in low resolution samples. Across 1000 ImageNet classes, 128x128 samples are more than twice as discriminable as artificially resized 32x32 samples. In addition, 84.7% of the classes have samples exhibiting diversity comparable to real ImageNet data.",
      keywords: ["Deep learning"],
      accepted: false,
      publication_venue: "International Conference on Machine Learning",
      publication_venue_id: "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
      url: "https://www.semanticscholar.org/paper/ecc0edd450ae7e52f65ddf61405b30ad6dbabdd7",
      citation_count: 3161,
      authors: ["Augustus Odena", "C. Olah", "Jonathon Shlens"],
      authorIds: ["2624088", "37232298", "1789737"],
      conference_year: 2017,
      conference_name: "iclr",
      conf_id: "iclr2017",
      review_scores: [6.0, 3.0, 6.0],
      review_score_avg: 5.0,
      review_confidences: [6.0, 3.0, 6.0],
      review_confidence_avg: 4.3333333333,
    },
    {
      id: "Hk1iOLcle",
      semantic_scholar_id: "dd95f96e3322dcaee9b1e3f7871ecc3ebcd51bfe",
      raw_decision: "Submitted to ICLR 2017",
      normalized_decision: "Reject",
      title:
        "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset",
      abstract:
        "This paper presents our recent work on the design and development of a new, large scale dataset, which we name MS MARCO, for MAchine Reading COmprehension. This new dataset is aimed to overcome a number of well-known weaknesses of previous publicly available datasets for the same task of reading comprehension and question answering. In MS MARCO, all questions are sampled from real anonymized user queries. The context passages, from which answers in the dataset are derived, are extracted from real web documents using the most advanced version of the Bing search engine. The answers to the queries are human generated. Finally, a subset of these queries has multiple answers. We aim to release one million queries and the corresponding answers in the dataset, which, to the best of our knowledge, is the most comprehensive real-world dataset of its kind in both quantity and quality. We are currently releasing 100,000 queries with their corresponding answers to inspire work in reading comprehension and question answering along with gathering feedback from the research community.",
      keywords: [],
      accepted: false,
      publication_venue: null,
      publication_venue_id: null,
      url: "https://www.semanticscholar.org/paper/dd95f96e3322dcaee9b1e3f7871ecc3ebcd51bfe",
      citation_count: 2568,
      authors: [
        "Daniel Fernando Campos",
        "Tri Nguyen",
        "Mir Rosenberg",
        "Xia Song",
        "Jianfeng Gao",
        "Saurabh Tiwary",
        "Rangan Majumder",
        "L. Deng",
        "Bhaskar Mitra",
      ],
      authorIds: [
        "144081089",
        "2116109215",
        "40319105",
        "50706785",
        "1800422",
        "40070335",
        "32431940",
        "144718788",
        "116506812",
      ],
      conference_year: 2017,
      conference_name: "iclr",
      conf_id: "iclr2017",
      review_scores: [6.0, 6.0, 6.0],
      review_score_avg: 6.0,
      review_confidences: [6.0, 6.0, 6.0],
      review_confidence_avg: 3.0,
    },
    {
      id: "HJy_5Mcll",
      semantic_scholar_id: "daf74c34f7da0695b154f645c8b78a7397a98f16",
      raw_decision: "Submitted to ICLR 2017",
      normalized_decision: "Reject",
      title:
        "ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation",
      abstract:
        "The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in practical mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper, we propose a novel deep neural network architecture named ENet (efficient neural network), created specifically for tasks requiring low latency operation. ENet is up to 18x faster, requires 75x less FLOPs, has 79x less parameters, and provides similar or better accuracy to existing models.           \nWe have tested it on CamVid, Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods, and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.      \n",
      keywords: ["Deep learning"],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/daf74c34f7da0695b154f645c8b78a7397a98f16",
      citation_count: 2020,
      authors: [
        "Adam Paszke",
        "Abhishek Chaurasia",
        "Sangpil Kim",
        "E. Culurciello",
      ],
      authorIds: ["3407277", "3422735", "2142668751", "2889774"],
      conference_year: 2017,
      conference_name: "iclr",
      conf_id: "iclr2017",
      review_scores: [3.0, 5.0, 4.0, 4.0],
      review_score_avg: 4.0,
      review_confidences: [3.0, 5.0, 4.0, 4.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "BJC8LF9ex",
      semantic_scholar_id: "bd723bc768baa78b7bd3e6f28a401d6d5cfe87f8",
      raw_decision: "Submitted to ICLR 2017",
      normalized_decision: "Reject",
      title:
        "Recurrent Neural Networks for Multivariate Time Series with Missing Values",
      abstract:
        "Multivariate time series data in practical applications, such as health care, geoscience, and biology, are characterized by a variety of missing values. In time series prediction and other related tasks, it has been noted that missing values and their missing patterns are often correlated with the target labels, a.k.a., informative missingness. There is very limited work on exploiting the missing patterns for effective imputation and improving prediction performance. In this paper, we develop novel deep learning models, namely GRU-D, as one of the early attempts. GRU-D is based on Gated Recurrent Units (GRU), a state-of-the-art recurrent neural network. It takes two representations of missing patterns, i.e., masking and time interval, and effectively incorporates them into a deep model architecture so that it not only captures the long-term temporal dependencies in time series, but also utilizes the missing patterns to achieve better prediction results. Experiments of time series classification tasks on real-world clinical datasets (MIMIC-III, PhysioNet) and synthetic datasets demonstrate that our models achieve state-of-the-art performance and provides useful insights for better understanding and utilization of missing values in time series analysis.",
      keywords: ["Deep learning"],
      accepted: false,
      publication_venue: "Scientific Reports",
      publication_venue_id: "f99f77b7-b1b6-44d3-984a-f288e9884b9b",
      url: "https://www.semanticscholar.org/paper/bd723bc768baa78b7bd3e6f28a401d6d5cfe87f8",
      citation_count: 1866,
      authors: [
        "Zhengping Che",
        "S. Purushotham",
        "Kyunghyun Cho",
        "D. Sontag",
        "Yan Liu",
      ],
      authorIds: ["1939695", "144735626", "1979489", "1746662", "47909587"],
      conference_year: 2017,
      conference_name: "iclr",
      conf_id: "iclr2017",
      review_scores: [6.0, 6.0, 5.0],
      review_score_avg: 5.6666666667,
      review_confidences: [6.0, 6.0, 5.0],
      review_confidence_avg: 3.3333333333,
    },
    {
      id: "rJY3vK9eg",
      semantic_scholar_id: "d7878c2044fb699e0ce0cad83e411824b1499dc8",
      raw_decision: "Submitted to ICLR 2017",
      normalized_decision: "Reject",
      title: "Neural Combinatorial Optimization with Reinforcement Learning",
      abstract:
        "This paper presents a framework to tackle combinatorial optimization problems using neural networks and reinforcement learning. We focus on the traveling salesman problem (TSP) and train a recurrent neural network that, given a set of city coordinates, predicts a distribution over different city permutations. Using negative tour length as the reward signal, we optimize the parameters of the recurrent neural network using a policy gradient method. We compare learning the network parameters on a set of training graphs against learning them on individual test graphs. Without much engineering and heuristic designing, Neural Combinatorial Optimization achieves close to optimal results on 2D Euclidean graphs with up to 100 nodes. Applied to the KnapSack, another NP-hard problem, the same method obtains optimal solutions for instances with up to 200 items. These results, albeit still far from state-of-the-art, give insights into how neural networks can be used as a general tool for tackling combinatorial optimization problems.",
      keywords: ["Reinforcement Learning", "Deep learning"],
      accepted: false,
      publication_venue: "International Conference on Learning Representations",
      publication_venue_id: "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
      url: "https://www.semanticscholar.org/paper/d7878c2044fb699e0ce0cad83e411824b1499dc8",
      citation_count: 1417,
      authors: [
        "Irwan Bello",
        "Hieu Pham",
        "Quoc V. Le",
        "Mohammad Norouzi",
        "Samy Bengio",
      ],
      authorIds: ["4689792", "143950636", "2827616", "144739074", "1751569"],
      conference_year: 2017,
      conference_name: "iclr",
      conf_id: "iclr2017",
      review_scores: [6.0, 6.0, 6.0],
      review_score_avg: 6.0,
      review_confidences: [6.0, 6.0, 6.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "SJc1hL5ee",
      semantic_scholar_id: "5feb32a73dd1bd9e13f84a7b3344497a5545106b",
      raw_decision: "Submitted to ICLR 2017",
      normalized_decision: "Reject",
      title: "FastText.zip: Compressing text classification models",
      abstract:
        "We consider the problem of producing compact architectures for text classification, such that the full model fits in a limited amount of memory.  After considering different solutions inspired by the hashing literature, we propose a method built upon product quantization to store the word embeddings.  While the original technique leads to a loss in accuracy,  we adapt this method to circumvent the quantization artifacts. As a result, our approach produces a text classifier, derived from the fastText approach, which at test time requires only a fraction of the memory compared to the original one, without noticeably sacrificing the quality in terms of classification accuracy. Our experiments carried out on several benchmarks show that our approach typically requires two orders of magnitude less memory than fastText while being only slightly inferior with respect to accuracy. As a result, it outperforms the state of the art by a good margin in terms of the compromise between memory usage and accuracy.",
      keywords: [
        "Natural language processing",
        "Supervised Learning",
        "Applications",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/5feb32a73dd1bd9e13f84a7b3344497a5545106b",
      citation_count: 1165,
      authors: [
        "Armand Joulin",
        "Edouard Grave",
        "Piotr Bojanowski",
        "Matthijs Douze",
        "H. J\u00e9gou",
        "Tomas Mikolov",
      ],
      authorIds: [
        "2319608",
        "3024698",
        "2329288",
        "3271933",
        "1681054",
        "2047446108",
      ],
      conference_year: 2017,
      conference_name: "iclr",
      conf_id: "iclr2017",
      review_scores: [6.0, 5.0, 6.0],
      review_score_avg: 5.6666666667,
      review_confidences: [6.0, 5.0, 6.0],
      review_confidence_avg: 3.6666666667,
    },
    {
      id: "Bygq-H9eg",
      semantic_scholar_id: "9a786d1ecf77dfba3459a83cd3fa0f1781bbcba4",
      raw_decision: "Submitted to ICLR 2017",
      normalized_decision: "Reject",
      title:
        "An Analysis of Deep Neural Network Models for Practical Applications",
      abstract:
        "Since the emergence of Deep Neural Networks (DNNs) as a prominent technique in the field of computer vision, the ImageNet classification challenge has played a major role in advancing the state-of-the-art. While accuracy figures have steadily increased, the resource utilisation of winning models has not been properly taken into account. In this work, we present a comprehensive analysis of important metrics in practical applications: accuracy, memory footprint, parameters, operations count, inference time and power consumption. Key findings are: (1) power consumption is independent of batch size and architecture; (2) accuracy and inference time are in a hyperbolic relationship; (3) energy constraint are an upper bound on the maximum achievable accuracy and model complexity; (4) the number of operations is a reliable estimate of the inference time. We believe our analysis provides a compelling set of information that helps design and engineer efficient DNNs.",
      keywords: ["Computer vision", "Deep learning", "Applications"],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/9a786d1ecf77dfba3459a83cd3fa0f1781bbcba4",
      citation_count: 1149,
      authors: ["A. Canziani", "Adam Paszke", "E. Culurciello"],
      authorIds: ["2067767", "3407277", "2889774"],
      conference_year: 2017,
      conference_name: "iclr",
      conf_id: "iclr2017",
      review_scores: [4.0, 5.0, 4.0],
      review_score_avg: 4.3333333333,
      review_confidences: [4.0, 5.0, 4.0],
      review_confidence_avg: 3.3333333333,
    },
  ],
  iclr2019: [
    {
      id: "r1gR2sC9FX",
      semantic_scholar_id: "715a73290f260cf2196307e59fe0b6776841f170",
      raw_decision: "ICLR 2019 Reject",
      normalized_decision: "Reject",
      title: "On the Spectral Bias of Neural Networks",
      abstract:
        "Neural networks are known to be a class of highly expressive functions able to fit even random input-output mappings with 100% accuracy. In this work we present properties of neural networks that complement this aspect of expressivity. By using tools from Fourier analysis, we show that deep ReLU networks are biased towards low frequency functions, meaning that they cannot have local fluctuations without affecting their global behavior. Intuitively, this property is in line with the observation that over-parameterized networks find simple patterns that generalize across data samples. We also investigate how the shape of the data manifold affects expressivity by showing evidence that learning high frequencies gets easier with increasing manifold complexity, and present a theoretical understanding of this behavior. Finally, we study the robustness of the frequency components with respect to parameter perturbation, to develop the intuition that the parameters must be finely tuned to express high frequency functions.",
      keywords: ["deep learning theory", "fourier analysis"],
      accepted: false,
      publication_venue: "International Conference on Machine Learning",
      publication_venue_id: "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
      url: "https://www.semanticscholar.org/paper/715a73290f260cf2196307e59fe0b6776841f170",
      citation_count: 1318,
      authors: [
        "Nasim Rahaman",
        "A. Baratin",
        "Devansh Arpit",
        "Felix Dr\u00e4xler",
        "Min Lin",
        "F. Hamprecht",
        "Yoshua Bengio",
        "Aaron C. Courville",
      ],
      authorIds: [
        "40050919",
        "14398916",
        "2309967",
        "23152499",
        "1491081747",
        "1685187",
        "1751762",
        "1760871",
      ],
      conference_year: 2019,
      conference_name: "iclr",
      conf_id: "iclr2019",
      review_scores: [6.0, 5.0, 6.0, 4.0],
      review_score_avg: 5.25,
      review_confidences: [6.0, 5.0, 6.0, 4.0],
      review_confidence_avg: 3.4,
    },
    {
      id: "SkVRTj0cYQ",
      semantic_scholar_id: "b1e538dbf538fd9fdf5f5870c5b7416ae08c9882",
      raw_decision: "ICLR 2019 Reject",
      normalized_decision: "Reject",
      title:
        "Differentially Private Federated Learning: A Client Level Perspective",
      abstract:
        "Federated learning is a recent advance in privacy protection. \nIn this context, a trusted curator aggregates parameters optimized in decentralized fashion by multiple clients. The resulting model is then distributed back to all clients, ultimately converging to a joint representative model without explicitly having to share the data. \nHowever, the protocol is vulnerable to differential attacks, which could originate from any party contributing during federated optimization. In such an attack, a client's contribution during training and information about their data set is revealed through analyzing the distributed model. \nWe tackle this problem and propose an algorithm for client sided differential privacy preserving federated optimization. The aim is to hide clients' contributions during training, balancing the trade-off between privacy loss and model performance. \nEmpirical studies suggest that given a sufficiently large number of participating clients, our proposed procedure can maintain client-level differential privacy at only a minor cost in model performance. ",
      keywords: [
        "Machine Learning",
        "Federated Learning",
        "Privacy",
        "Security",
        "Differential Privacy",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/b1e538dbf538fd9fdf5f5870c5b7416ae08c9882",
      citation_count: 1234,
      authors: ["Robin C. Geyer", "T. Klein", "Moin Nabi"],
      authorIds: ["32580850", "35660331", "1848946"],
      conference_year: 2019,
      conference_name: "iclr",
      conf_id: "iclr2019",
      review_scores: [4.0, 4.0, 4.0],
      review_score_avg: 4.0,
      review_confidences: [4.0, 4.0, 4.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "HJei-2RcK7",
      semantic_scholar_id: "0ca7d8c3250d43d14fdde46bf6fc299654d861ef",
      raw_decision: "ICLR 2019 Reject",
      normalized_decision: "Reject",
      title: "Heterogeneous Graph Transformer",
      abstract:
        "Graph neural networks (GNN) have gained increasing research interests as a mean to the challenging goal of robust and universal graph learning. Previous GNNs have assumed single pre-fixed graph structure and permitted only local context encoding. This paper proposes a novel Graph Transformer (GTR) architecture that captures long-range dependency with global attention, and enables dynamic graph structures. In particular, GTR propagates features within the same graph structure via an intra-graph message passing, and transforms dynamic semantics across multi-domain graph-structured data (e.g. images, sequences, knowledge graphs) for multi-modal learning via an inter-graph message passing. Furthermore, GTR enables effective incorporation of any prior graph structure by weighted averaging of the prior and learned edges, which can be crucially useful for scenarios where prior knowledge is desired. The proposed GTR achieves new state-of-the-arts across three benchmark tasks, including few-shot learning, medical abnormality and disease classification, and graph classification. Experiments show that GTR is superior in learning robust graph representations, transforming high-level semantics across domains, and bridging between prior graph structure with automatic structure learning.  ",
      keywords: ["Graph neural networks", "transformer", "attention"],
      accepted: false,
      publication_venue: "The Web Conference",
      publication_venue_id: "e07422f9-c065-40c3-a37b-75e98dce79fe",
      url: "https://www.semanticscholar.org/paper/0ca7d8c3250d43d14fdde46bf6fc299654d861ef",
      citation_count: 1125,
      authors: ["Ziniu Hu", "Yuxiao Dong", "Kuansan Wang", "Yizhou Sun"],
      authorIds: ["3407296", "2047998", "1748169", "2109461904"],
      conference_year: 2019,
      conference_name: "iclr",
      conf_id: "iclr2019",
      review_scores: [6.0, 6.0, 6.0],
      review_score_avg: 6.0,
      review_confidences: [6.0, 6.0, 6.0],
      review_confidence_avg: 4.25,
    },
    {
      id: "S1g2V3Cct7",
      semantic_scholar_id: "d9ff7a9344dd5d6653bd7a02bfd704422bb29951",
      raw_decision: "ICLR 2019 Reject",
      normalized_decision: "Reject",
      title: "Experience Replay for Continual Learning",
      abstract:
        "Continual learning is the problem of learning new tasks or knowledge while protecting old knowledge and ideally generalizing from old experience to learn new tasks faster. Neural networks trained by stochastic gradient descent often degrade on old tasks when trained successively on new tasks with different data distributions. This phenomenon, referred to as catastrophic forgetting, is considered a major hurdle to learning with non-stationary data or sequences of new tasks, and prevents networks from continually accumulating knowledge and skills. We examine this issue in the context of reinforcement learning, in a setting where an agent is exposed to tasks in a sequence. Unlike most other work, we do not provide an explicit indication to the model of task boundaries, which is the most general circumstance for a learning agent exposed to continuous experience. While various methods to counteract catastrophic forgetting have recently been proposed, we explore a straightforward, general, and seemingly overlooked solution - that of using experience replay buffers for all past events - with a mixture of on- and off-policy learning, leveraging behavioral cloning. We show that this strategy can still learn new tasks quickly yet can substantially reduce catastrophic forgetting in both Atari and DMLab domains, even matching the performance of methods that require task identities. When buffer storage is constrained, we confirm that a simple mechanism for randomly discarding data allows a limited size buffer to perform almost as well as an unbounded one.",
      keywords: [
        "continual learning",
        "catastrophic forgetting",
        "lifelong learning",
        "behavioral cloning",
        "reinforcement learning",
        "interference",
        "stability-plasticity",
      ],
      accepted: false,
      publication_venue: "Neural Information Processing Systems",
      publication_venue_id: "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
      url: "https://www.semanticscholar.org/paper/d9ff7a9344dd5d6653bd7a02bfd704422bb29951",
      citation_count: 1046,
      authors: [
        "David Rolnick",
        "Arun Ahuja",
        "Jonathan Schwarz",
        "T. Lillicrap",
        "Greg Wayne",
      ],
      authorIds: ["2346588790", "37968006", "144735987", "2542999", "89504302"],
      conference_year: 2019,
      conference_name: "iclr",
      conf_id: "iclr2019",
      review_scores: [5.0, 5.0, 5.0],
      review_score_avg: 5.0,
      review_confidences: [5.0, 5.0, 5.0],
      review_confidence_avg: 4.5,
    },
    {
      id: "BkewX2C9tX",
      semantic_scholar_id: "6c66108edb9af0533309055e7b2ecb8922db03d8",
      raw_decision: "ICLR 2019 Reject",
      normalized_decision: "Reject",
      title: "Analyzing Federated Learning through an Adversarial Lens",
      abstract:
        "Federated learning distributes model training among a multitude of agents, who, guided by privacy concerns, perform training using their local data but share only model parameter updates, for iterative aggregation at the server. In this work, we explore the threat of model poisoning attacks on federated learning initiated by a single, non-colluding malicious agent where the adversarial objective is to cause the model to misclassify a set of chosen inputs with high confidence. We explore a number of strategies to carry out this attack, starting with simple boosting of the malicious agent's update to overcome the effects of other agents' updates. To increase attack stealth, we propose an alternating minimization strategy, which alternately optimizes for the training loss and the adversarial objective. We follow up by using parameter estimation for the benign agents' updates to improve on attack success. Finally, we use a suite of interpretability techniques to generate visual explanations of model decisions for both benign and malicious models and show that the explanations are nearly visually indistinguishable. Our results indicate that even a highly constrained adversary can carry out model poisoning attacks while simultaneously maintaining stealth, thus highlighting the vulnerability of the federated learning setting and the need to develop effective defense strategies.",
      keywords: ["federated learning", "model poisoning"],
      accepted: false,
      publication_venue: "International Conference on Machine Learning",
      publication_venue_id: "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
      url: "https://www.semanticscholar.org/paper/6c66108edb9af0533309055e7b2ecb8922db03d8",
      citation_count: 986,
      authors: [
        "A. Bhagoji",
        "Supriyo Chakraborty",
        "Prateek Mittal",
        "S. Calo",
      ],
      authorIds: ["10754103", "144387904", "143615345", "2096811"],
      conference_year: 2019,
      conference_name: "iclr",
      conf_id: "iclr2019",
      review_scores: [6.0, 4.0, 5.0],
      review_score_avg: 5.0,
      review_confidences: [6.0, 4.0, 5.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "SklVEnR5K7",
      semantic_scholar_id: "8c92054c26fb4c6dd7435bc99fbb8af3323eae1b",
      raw_decision: "ICLR 2019 Reject",
      normalized_decision: "Reject",
      title: "Making Convolutional Networks Shift-Invariant Again",
      abstract:
        "Modern convolutional networks are not shift-invariant, despite their convolutional nature: small shifts in the input can cause drastic changes in the internal feature maps and output. In this paper, we isolate the cause -- the downsampling operation in convolutional and pooling layers -- and apply the appropriate signal processing fix -- low-pass filtering before downsampling. This simple architectural modification boosts the shift-equivariance of the internal representations and consequently, shift-invariance of the output. Importantly, this is achieved while maintaining downstream classification performance. In addition, incorporating the inductive bias of shift-invariance largely removes the need for shift-based data augmentation. Lastly, we observe that the modification induces spatially-smoother learned convolutional kernels. Our results suggest that this classical signal processing technique has a place in modern deep networks.",
      keywords: [
        "convolutional networks",
        "signal processing",
        "shift",
        "translation",
        "invariance",
        "equivariance",
      ],
      accepted: false,
      publication_venue: "International Conference on Machine Learning",
      publication_venue_id: "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
      url: "https://www.semanticscholar.org/paper/8c92054c26fb4c6dd7435bc99fbb8af3323eae1b",
      citation_count: 774,
      authors: ["Richard Zhang"],
      authorIds: ["2844849"],
      conference_year: 2019,
      conference_name: "iclr",
      conf_id: "iclr2019",
      review_scores: [5.0, 5.0, 6.0],
      review_score_avg: 5.3333333333,
      review_confidences: [5.0, 5.0, 6.0],
      review_confidence_avg: 4.25,
    },
    {
      id: "HJx7l309Fm",
      semantic_scholar_id: "929bef0066bad871ba971b673c053112d055d29f",
      raw_decision: "ICLR 2019 Reject",
      normalized_decision: "Reject",
      title: "Actor-Attention-Critic for Multi-Agent Reinforcement Learning",
      abstract:
        "Reinforcement learning in multi-agent scenarios is important for real-world applications but presents challenges beyond those seen in single-agent settings. We present an actor-critic algorithm that trains decentralized policies in multi-agent settings, using centrally computed critics that share an attention mechanism which selects relevant information for each agent at every timestep. This attention mechanism enables more effective and scalable learning in complex multi-agent environments, when compared to recent approaches. Our approach is applicable not only to cooperative settings with shared rewards, but also individualized reward settings, including adversarial settings, and it makes no assumptions about the action spaces of the agents. As such, it is flexible enough to be applied to most multi-agent learning problems",
      keywords: [
        "multi-agent",
        "reinforcement learning",
        "attention",
        "actor-critic",
      ],
      accepted: false,
      publication_venue: "International Conference on Machine Learning",
      publication_venue_id: "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
      url: "https://www.semanticscholar.org/paper/929bef0066bad871ba971b673c053112d055d29f",
      citation_count: 712,
      authors: ["Shariq Iqbal", "Fei Sha"],
      authorIds: ["2899335", "145757665"],
      conference_year: 2019,
      conference_name: "iclr",
      conf_id: "iclr2019",
      review_scores: [4.0, 7.0, 6.0],
      review_score_avg: 5.6666666667,
      review_confidences: [4.0, 7.0, 6.0],
      review_confidence_avg: 3.5,
    },
    {
      id: "HyGh4sR9YQ",
      semantic_scholar_id: "819bcae49054e00cef3c0972d48b4e40a525f4d9",
      raw_decision: "ICLR 2019 Reject",
      normalized_decision: "Reject",
      title:
        "Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning",
      abstract:
        "Deep artificial neural networks (DNNs) are typically trained via gradient-based learning algorithms, namely backpropagation. \nEvolution strategies (ES) can rival backprop-based algorithms such as Q-learning and policy gradients on challenging deep reinforcement learning (RL) problems. However, ES can be considered a gradient-based algorithm because it performs stochastic gradient descent via an operation similar to a finite-difference approximation of the gradient.\nThat raises the question of whether non-gradient-based evolutionary algorithms can work at DNN scales. \nHere we demonstrate they can: we evolve the weights of a DNN with a simple, gradient-free, population-based genetic algorithm (GA) and it performs well on hard deep RL problems, including Atari and humanoid locomotion. The Deep GA successfully evolves networks with over four million free parameters, the largest neural networks ever evolved with a traditional evolutionary algorithm. These results (1) expand our sense of the scale at which GAs can operate, (2) suggest intriguingly that in some cases following the gradient is not the best choice for optimizing performance, and (3) make immediately available the multitude of neuroevolution techniques that improve performance. We demonstrate the latter by showing that combining DNNs with novelty search, which encourages exploration on tasks with deceptive or sparse reward functions, can solve a high-dimensional problem on which reward-maximizing algorithms (e.g.\\  DQN, A3C, ES, and the GA) fail. Additionally, the Deep GA is faster than ES, A3C, and DQN (it can train Atari in {\\raise.17ex\\hbox{$\\scriptstyle\\sim$}}4 hours on one workstation or {\\raise.17ex\\hbox{$\\scriptstyle\\sim$}}1 hour distributed on 720 cores), and enables a state-of-the-art, up to 10,000-fold compact encoding technique. ",
      keywords: ["Neuroevolution", "Reinforcement Learning"],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/819bcae49054e00cef3c0972d48b4e40a525f4d9",
      citation_count: 678,
      authors: [
        "F. Such",
        "Vashisht Madhavan",
        "Edoardo Conti",
        "J. Lehman",
        "Kenneth O. Stanley",
        "J. Clune",
      ],
      authorIds: [
        "9927844",
        "8309711",
        "32577240",
        "39799304",
        "1846883",
        "2552141",
      ],
      conference_year: 2019,
      conference_name: "iclr",
      conf_id: "iclr2019",
      review_scores: [7.0, 3.0, 4.0, 6.0, 6.0],
      review_score_avg: 5.2,
      review_confidences: [7.0, 3.0, 4.0, 6.0, 6.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "B1lfHhR9tm",
      semantic_scholar_id: "9784fbf77295860b2e412137b86356d70b25e3c0",
      raw_decision: "ICLR 2019 Reject",
      normalized_decision: "Reject",
      title:
        "The Natural Language Decathlon: Multitask Learning as Question Answering",
      abstract:
        "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.",
      keywords: [
        "multitask learning",
        "natural language processing",
        "question answering",
        "machine translation",
        "relation extraction",
        "semantic parsing",
        "commensense reasoning",
        "summarization",
        "entailment",
        "sentiment",
        "dialog",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/9784fbf77295860b2e412137b86356d70b25e3c0",
      citation_count: 635,
      authors: ["Bryan McCann", "N. Keskar", "Caiming Xiong", "R. Socher"],
      authorIds: ["143775536", "2844898", "2228109", "2166511"],
      conference_year: 2019,
      conference_name: "iclr",
      conf_id: "iclr2019",
      review_scores: [3.0, 5.0, 5.0],
      review_score_avg: 4.3333333333,
      review_confidences: [3.0, 5.0, 5.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "HJxYwiC5tm",
      semantic_scholar_id: "afe088dc92e0cc905bef086fbd23eaa8f1a43cd1",
      raw_decision: "ICLR 2019 Reject",
      normalized_decision: "Reject",
      title:
        "Why do deep convolutional networks generalize so poorly to small image transformations?",
      abstract:
        "Deep convolutional network architectures are often assumed to guarantee generalization for small image translations and deformations. In this paper we show that modern CNNs (VGG16, ResNet50, and InceptionResNetV2) can drastically change their output when an image is translated in the image plane by a few pixels, and that this failure of generalization also happens with other realistic small image transformations. Furthermore,  we see these failures to generalize more frequently in more modern networks. We show that these failures are related to the fact that the architecture of modern CNNs ignores the classical sampling theorem so that generalization is not guaranteed. We also show that biases in the statistics of commonly used image datasets makes it unlikely that CNNs will learn to be invariant to these transformations. Taken together our results suggest that the performance of CNNs in object recognition falls far short of the generalization capabilities of humans.",
      keywords: [
        "Convolutional neural networks",
        "The sampling theorem",
        "Sensitivity to small image transformations",
        "Dataset bias",
        "Shiftability",
      ],
      accepted: false,
      publication_venue: "Journal of machine learning research",
      publication_venue_id: "c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
      url: "https://www.semanticscholar.org/paper/afe088dc92e0cc905bef086fbd23eaa8f1a43cd1",
      citation_count: 553,
      authors: ["Aharon Azulay", "Yair Weiss"],
      authorIds: ["4044772", "30400079"],
      conference_year: 2019,
      conference_name: "iclr",
      conf_id: "iclr2019",
      review_scores: [5.0, 7.0, 7.0],
      review_score_avg: 6.3333333333,
      review_confidences: [5.0, 7.0, 7.0],
      review_confidence_avg: 4.5,
    },
  ],
  iclr2020: [
    {
      id: "SyxS0T4tvS",
      semantic_scholar_id: "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de",
      raw_decision: "ICLR 2020 Reject",
      normalized_decision: "Reject",
      title: "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
      abstract:
        "Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE, SQuAD, SuperGLUE and XNLI. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.",
      keywords: [
        "Deep learning",
        "language representation learning",
        "natural language understanding",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/077f8329a7b6fa3b7c877a57b81eb6c18b5f87de",
      citation_count: 23117,
      authors: [
        "Yinhan Liu",
        "Myle Ott",
        "Naman Goyal",
        "Jingfei Du",
        "Mandar Joshi",
        "Danqi Chen",
        "Omer Levy",
        "M. Lewis",
        "Luke Zettlemoyer",
        "Veselin Stoyanov",
      ],
      authorIds: [
        "11323179",
        "40511414",
        "39589154",
        "3048577",
        "144863691",
        "50536468",
        "39455775",
        "35084211",
        "1982950",
        "1759422",
      ],
      conference_year: 2020,
      conference_name: "iclr",
      conf_id: "iclr2020",
      review_scores: [6.0, 6.0, 6.0],
      review_score_avg: 6.0,
      review_confidences: [6.0, 6.0, 6.0],
      review_confidence_avg: 4.6666666667,
    },
    {
      id: "BkgStySKPB",
      semantic_scholar_id: "97f4d09175705be4677d675fa27e55defac44800",
      raw_decision: "ICLR 2020 Reject",
      normalized_decision: "Reject",
      title: "Contrastive Multiview Coding",
      abstract:
        'Humans view the world through many sensory channels, e.g., the long-wavelength light channel, viewed by the left eye, or the high-frequency vibrations channel, heard by the right ear. Each view is noisy and incomplete, but important factors, such as physics, geometry, and semantics, tend to be shared between all views (e.g., a "dog" can be seen, heard, and felt). We hypothesize that a powerful representation is one that models view-invariant factors. Based on this hypothesis, we investigate a contrastive coding scheme, in which a representation is learned that aims to maximize mutual information between different views but is otherwise compact. Our approach scales to any number of views, and is view-agnostic. The resulting learned representations perform above the state of the art for downstream tasks such as object classification, compared to formulations based on predictive learning or single view reconstruction, and improve as more views are added. On the Imagenet linear readoff benchmark, we achieve 68.4% top-1 accuracy. ',
      keywords: [
        "Representation Learning",
        "Unsupervised Learning",
        "Self-supervsied Learning",
        "Multiview Learning",
      ],
      accepted: false,
      publication_venue: "European Conference on Computer Vision",
      publication_venue_id: "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
      url: "https://www.semanticscholar.org/paper/97f4d09175705be4677d675fa27e55defac44800",
      citation_count: 2293,
      authors: ["Yonglong Tian", "Dilip Krishnan", "Phillip Isola"],
      authorIds: ["2476765", "1707347", "2094770"],
      conference_year: 2020,
      conference_name: "iclr",
      conf_id: "iclr2020",
      review_scores: [3.0, 6.0, 6.0],
      review_score_avg: 5.0,
      review_confidences: [3.0, 6.0, 6.0],
      review_confidence_avg: 2.6666666667,
    },
    {
      id: "ByeL1R4FvS",
      semantic_scholar_id: "0feea94f89d395436bf41bd10c797447eecbc128",
      raw_decision: "ICLR 2020 Reject",
      normalized_decision: "Reject",
      title: "Unsupervised Data Augmentation for Consistency Training",
      abstract:
        "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 2.7% with only 4,000 examples, nearly matching the performance of models trained on 50,000 labeled examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used.",
      keywords: [
        "Semi-supervised learning",
        "computer vision",
        "natural language processing",
      ],
      accepted: false,
      publication_venue: "Neural Information Processing Systems",
      publication_venue_id: "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
      url: "https://www.semanticscholar.org/paper/0feea94f89d395436bf41bd10c797447eecbc128",
      citation_count: 2222,
      authors: [
        "Qizhe Xie",
        "Zihang Dai",
        "E. Hovy",
        "Minh-Thang Luong",
        "Quoc V. Le",
      ],
      authorIds: ["1912046", "3422912", "144547315", "1707242", "2827616"],
      conference_year: 2020,
      conference_name: "iclr",
      conf_id: "iclr2020",
      review_scores: [8.0, 3.0, 3.0],
      review_score_avg: 4.6666666667,
      review_confidences: [8.0, 3.0, 3.0],
      review_confidence_avg: 3.6666666667,
    },
    {
      id: "rJx0Q6EFPB",
      semantic_scholar_id: "0cbf97173391b0430140117027edcaf1a37968c7",
      raw_decision: "ICLR 2020 Reject",
      normalized_decision: "Reject",
      title: "TinyBERT: Distilling BERT for Natural Language Understanding",
      abstract:
        "Language model pre-training, such as BERT, has significantly improved the performances of many natural language processing tasks. However, the pre-trained language models are usually computationally expensive and memory intensive, so it is difficult to effectively execute them on resource-restricted devices. To accelerate inference and reduce model size while maintaining accuracy, we firstly propose a novel Transformer distillation method that is specially designed for knowledge distillation (KD) of the Transformer-based models. By leveraging this new KD method, the plenty of knowledge encoded in a large \u201cteacher\u201d BERT can be well transferred to a small \u201cstudent\u201d TinyBERT. Moreover, we introduce a new two-stage learning framework for TinyBERT, which performs Transformer distillation at both the pre-training and task-specific learning stages. This framework ensures that TinyBERT can capture the general domain as well as the task-specific knowledge in BERT. TinyBERT is empirically effective and achieves comparable results with BERT on GLUE benchmark, while being 7.5x smaller and 9.4x faster on inference. TinyBERT is also significantly better than state-of-the-art baselines on BERT distillation, with only \u223c28% parameters and \u223c31% inference time of them.\n",
      keywords: ["BERT Compression", "Transformer Distillation", "TinyBERT"],
      accepted: false,
      publication_venue: "Findings",
      publication_venue_id: "479d5605-51be-4346-b1d6-4334084504df",
      url: "https://www.semanticscholar.org/paper/0cbf97173391b0430140117027edcaf1a37968c7",
      citation_count: 1759,
      authors: [
        "Xiaoqi Jiao",
        "Yichun Yin",
        "Lifeng Shang",
        "Xin Jiang",
        "Xiao Chen",
        "Linlin Li",
        "F. Wang",
        "Qun Liu",
      ],
      authorIds: [
        "39706649",
        "1384668226",
        "50812138",
        "145820291",
        "2117025507",
        "2111818678",
        "49451193",
        "1688015",
      ],
      conference_year: 2020,
      conference_name: "iclr",
      conf_id: "iclr2020",
      review_scores: [3.0, 8.0, 6.0],
      review_score_avg: 5.6666666667,
      review_confidences: [3.0, 8.0, 6.0],
      review_confidence_avg: 3.6666666667,
    },
    {
      id: "rJerHlrYwH",
      semantic_scholar_id: "1cae417456711c4da184f5efcd1b7464a7a0661a",
      raw_decision: "ICLR 2020 Reject",
      normalized_decision: "Reject",
      title:
        "Data-Efficient Image Recognition with Contrastive Predictive Coding",
      abstract:
        "Human observers can learn to recognize new categories of objects from a handful of examples, yet doing so with machine perception remains an open challenge. We hypothesize that data-efficient recognition is enabled by representations which make the variability in natural signals more predictable, as suggested by recent perceptual evidence. We therefore revisit and improve Contrastive Predictive Coding, a recently-proposed unsupervised learning framework, and arrive at a representation which enables generalization from small amounts of labeled data. When provided with only 1% of ImageNet labels (i.e. 13 per class), this model retains a strong classification performance, 73% Top-5 accuracy, outperforming supervised networks by 28% (a 65% relative improvement) and state-of-the-art semi-supervised methods by 14%. We also find this representation to serve as a useful substrate for object detection on the PASCAL-VOC 2007 dataset, approaching the performance of representations trained with a fully annotated ImageNet dataset.",
      keywords: [
        "Deep learning",
        "representation learning",
        "contrastive methods",
        "unsupervised learning",
        "self-supervised learning",
        "vision",
        "data-efficiency",
      ],
      accepted: false,
      publication_venue: "International Conference on Machine Learning",
      publication_venue_id: "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
      url: "https://www.semanticscholar.org/paper/1cae417456711c4da184f5efcd1b7464a7a0661a",
      citation_count: 1389,
      authors: [
        "Olivier J. H\u00e9naff",
        "A. Srinivas",
        "J. Fauw",
        "Ali Razavi",
        "Carl Doersch",
        "S. Eslami",
        "A\u00e4ron van den Oord",
      ],
      authorIds: [
        "2856712",
        "41207614",
        "3364908",
        "143653164",
        "2786693",
        "143648071",
        "3422336",
      ],
      conference_year: 2020,
      conference_name: "iclr",
      conf_id: "iclr2020",
      review_scores: [3.0, 6.0, 3.0, 3.0],
      review_score_avg: 3.75,
      review_confidences: [3.0, 6.0, 3.0, 3.0],
      review_confidence_avg: 3.75,
    },
    {
      id: "BylRkAEKDH",
      semantic_scholar_id: "9fe69cf5c104b2205cdb7908df8cdb389256b4b5",
      raw_decision: "ICLR 2020 Reject",
      normalized_decision: "Reject",
      title: "TabNet: Attentive Interpretable Tabular Learning",
      abstract:
        "We propose a novel high-performance interpretable deep tabular data learning network, TabNet. TabNet utilizes a sequential attention mechanism that softly selects features to reason from at each decision step and then aggregates the processed information to make a final prediction decision. By explicitly selecting sparse features, TabNet learns very efficiently as the model capacity at each decision step is fully utilized for the most relevant features, resulting in a high performance model. This sparsity also enables more interpretable decision making through the visualization of feature selection masks. We demonstrate that TabNet outperforms other neural network and decision tree variants on a wide range of tabular data learning datasets and yields interpretable feature attributions and insights into the global model behavior.",
      keywords: [
        "Tabular data",
        "interpretable neural networks",
        "attention models",
      ],
      accepted: false,
      publication_venue: "AAAI Conference on Artificial Intelligence",
      publication_venue_id: "bdc2e585-4e48-4e36-8af1-6d859763d405",
      url: "https://www.semanticscholar.org/paper/9fe69cf5c104b2205cdb7908df8cdb389256b4b5",
      citation_count: 1206,
      authors: ["Sercan \u00d6. Arik", "Tomas Pfister"],
      authorIds: ["2676352", "1945962"],
      conference_year: 2020,
      conference_name: "iclr",
      conf_id: "iclr2020",
      review_scores: [3.0, 3.0, 6.0],
      review_score_avg: 4.0,
      review_confidences: [3.0, 3.0, 6.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "HJewiCVFPB",
      semantic_scholar_id: "449c5660d637741f7aa7ff42549c32b43c9968bf",
      raw_decision: "ICLR 2020 Reject",
      normalized_decision: "Reject",
      title: "Gradient Surgery for Multi-Task Learning",
      abstract:
        "While deep learning and deep reinforcement learning systems have demonstrated impressive results in domains such as image classification, game playing, and robotic control, data efficiency remains a major challenge, particularly as these algorithms learn individual tasks from scratch. Multi-task learning has emerged as a promising approach for sharing structure across multiple tasks to enable more efficient learning. However, the multi-task setting presents a number of optimization challenges, making it difficult to realize large efficiency gains compared to learning tasks independently. The reasons why multi-task learning is so challenging compared to single task learning are not fully understood. Motivated by the insight that gradient interference causes optimization challenges, we develop a simple and general approach for avoiding interference between gradients from different tasks, by altering the gradients through a technique we refer to as \u201cgradient surgery\u201d. We propose a form of gradient surgery that projects the gradient of a task onto the normal plane of the gradient of any other task that has a conflicting gradient. On a series of challenging multi-task supervised and multi-task reinforcement learning problems, we find that this approach leads to substantial gains in efficiency and performance.  Further, it can be effectively combined with previously-proposed multi-task architectures for enhanced performance in a model-agnostic way.",
      keywords: ["multi-task learning", "deep learning"],
      accepted: false,
      publication_venue: "Neural Information Processing Systems",
      publication_venue_id: "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
      url: "https://www.semanticscholar.org/paper/449c5660d637741f7aa7ff42549c32b43c9968bf",
      citation_count: 1128,
      authors: [
        "Tianhe Yu",
        "Saurabh Kumar",
        "Abhishek Gupta",
        "S. Levine",
        "Karol Hausman",
        "Chelsea Finn",
      ],
      authorIds: [
        "10909315",
        "2121434953",
        "2129458064",
        "1736651",
        "1944801",
        "46881670",
      ],
      conference_year: 2020,
      conference_name: "iclr",
      conf_id: "iclr2020",
      review_scores: [6.0, 3.0, 3.0],
      review_score_avg: 4.0,
      review_confidences: [6.0, 3.0, 3.0],
      review_confidence_avg: 3.6666666667,
    },
    {
      id: "r1gPoCEKvH",
      semantic_scholar_id: "79e523beb1e1411a241edde0464b07c2ebc231d1",
      raw_decision: "ICLR 2020 Reject",
      normalized_decision: "Reject",
      title:
        "Single Path One-Shot Neural Architecture Search with Uniform Sampling",
      abstract:
        "We revisit the one-shot Neural Architecture Search (NAS) paradigm and analyze its advantages over existing NAS approaches. Existing one-shot method (Benderet al., 2018), however, is hard to train and not yet effective on large scale datasets like ImageNet.  This work propose a Single Path One-Shot model to address the challenge in the training.  Our central idea is to construct a simplified supernet, where all architectures are single paths so that weight co-adaption problem is alleviated. Training is performed by uniform path sampling. All architectures (and their weights) are trained fully and equally.\nComprehensive experiments verify that our approach is flexible and effective.  It is easy to train and fast to search.  It effortlessly supports complex search spaces(e.g., building blocks, channel, mixed-precision quantization) and different search constraints (e.g., FLOPs, latency).  It is thus convenient to use for various needs. It achieves start-of-the-art performance on the large dataset ImageNet.",
      keywords: ["Neural Architecture Search", "Single Path"],
      accepted: false,
      publication_venue: "European Conference on Computer Vision",
      publication_venue_id: "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
      url: "https://www.semanticscholar.org/paper/79e523beb1e1411a241edde0464b07c2ebc231d1",
      citation_count: 911,
      authors: [
        "Zichao Guo",
        "Xiangyu Zhang",
        "Haoyuan Mu",
        "Wen Heng",
        "Zechun Liu",
        "Yichen Wei",
        "Jian Sun",
      ],
      authorIds: [
        "3450466",
        "50875121",
        "2047503068",
        "145577184",
        "2109370860",
        "1732264",
        null,
      ],
      conference_year: 2020,
      conference_name: "iclr",
      conf_id: "iclr2020",
      review_scores: [8.0, 6.0, 6.0],
      review_score_avg: 6.6666666667,
      review_confidences: [8.0, 6.0, 6.0],
      review_confidence_avg: 3.3333333333,
    },
    {
      id: "B1x8anVFPr",
      semantic_scholar_id: "b45d656ac8cc2e940609580cf291ee76ffcac20a",
      raw_decision: "ICLR 2020 Reject",
      normalized_decision: "Reject",
      title: "On Layer Normalization in the Transformer Architecture",
      abstract:
        "The Transformer architecture is popularly used in natural language processing tasks. To train a Transformer model, a carefully designed learning rate warm-up stage is usually needed: the learning rate has to be set to an extremely small value at the beginning of the optimization and then gradually increases in some given number of iterations. Such a stage is shown to be crucial to the final performance and brings more hyper-parameter tunings. In this paper, we study why the learning rate warm-up stage is important in training the Transformer and theoretically show that the location of layer normalization matters. It can be proved that at the beginning of the optimization, for the original Transformer, which places the layer normalization between the residual blocks, the expected gradients of the parameters near the output layer are large. Then using a large learning rate on those gradients makes the training unstable. The warm-up stage is practically helpful to avoid this problem. Such an analysis motivates us to investigate a slightly modified Transformer architecture which locates the layer normalization inside the residual blocks. We show that the gradients in this Transformer architecture are well-behaved at initialization. Given these findings,  we are the first to show that this Transformer variant is easier and faster to train. The learning rate warm-up stage can be safely removed, and the training time can be largely reduced on a wide range of applications.",
      keywords: [
        "Transformer",
        "BERT",
        "Layer Normalization",
        "Natural Language Processing",
      ],
      accepted: false,
      publication_venue: "International Conference on Machine Learning",
      publication_venue_id: "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
      url: "https://www.semanticscholar.org/paper/b45d656ac8cc2e940609580cf291ee76ffcac20a",
      citation_count: 897,
      authors: [
        "Ruibin Xiong",
        "Yunchang Yang",
        "Di He",
        "Kai Zheng",
        "Shuxin Zheng",
        "Chen Xing",
        "Huishuai Zhang",
        "Yanyan Lan",
        "Liwei Wang",
        "Tie-Yan Liu",
      ],
      authorIds: [
        "51130380",
        "79327071",
        "1391126980",
        null,
        "150311931",
        "50461046",
        "2973831",
        "37510256",
        "24952249",
        "2110264337",
      ],
      conference_year: 2020,
      conference_name: "iclr",
      conf_id: "iclr2020",
      review_scores: [6.0, 6.0, 6.0],
      review_score_avg: 6.0,
      review_confidences: [6.0, 6.0, 6.0],
      review_confidence_avg: 3.6666666667,
    },
    {
      id: "rJel41BtDH",
      semantic_scholar_id: "35e8312d8bdcffb8e0c956d20d5a581cad1c1b8a",
      raw_decision: "ICLR 2020 Reject",
      normalized_decision: "Reject",
      title:
        "Pseudo-Labeling and Confirmation Bias in Deep Semi-Supervised Learning",
      abstract:
        "Semi-supervised learning, i.e. jointly learning from labeled an unlabeled samples, is an active research topic due to its key role on relaxing human annotation constraints. In the context of image classification, recent advances to learn from unlabeled samples are mainly focused on consistency regularization methods that encourage invariant predictions for different  perturbations of unlabeled samples. We, conversely, propose to learn from unlabeled data by generating soft pseudo-labels using the network predictions. We show that a naive pseudo-labeling overfits to incorrect pseudo-labels due to the so-called confirmation bias and demonstrate that mixup augmentation and setting a minimum number of labeled samples per mini-batch are effective regularization techniques for reducing it. The proposed approach achieves state-of-the-art results in CIFAR-10/100 and Mini-ImageNet despite being much simpler than other state-of-the-art. These results demonstrate that pseudo-labeling can outperform consistency regularization methods, while the opposite was supposed in previous work. Code will be made available.",
      keywords: [
        "Semi-supervised learning",
        "pseudo-labeling",
        "deep semi-supervised learning",
        "confirmation bias",
        "image classification",
      ],
      accepted: false,
      publication_venue:
        "IEEE International Joint Conference on Neural Network",
      publication_venue_id: "f80ba4a3-7aed-4021-b4d8-e4f50668847a",
      url: "https://www.semanticscholar.org/paper/35e8312d8bdcffb8e0c956d20d5a581cad1c1b8a",
      citation_count: 805,
      authors: [
        "Eric Arazo",
        "Diego Ortego",
        "Paul Albert",
        "N. O\u2019Connor",
        "Kevin McGuinness",
      ],
      authorIds: ["107621684", "2531432", "83107779", "98536322", "145470864"],
      conference_year: 2020,
      conference_name: "iclr",
      conf_id: "iclr2020",
      review_scores: [8.0, 3.0, 3.0],
      review_score_avg: 4.6666666667,
      review_confidences: [8.0, 3.0, 3.0],
      review_confidence_avg: 3.3333333333,
    },
  ],
  iclr2021: [
    {
      id: "-NEXDKk8gZ",
      semantic_scholar_id: "de18baa4964804cf471d85a5a090498242d2e79f",
      raw_decision: "ICLR 2021 Reject",
      normalized_decision: "Reject",
      title: "Improved Denoising Diffusion Probabilistic Models",
      abstract:
        "We explore denoising diffusion probabilistic models, a class of generative models which have recently been shown to produce excellent samples in the image and audio domains. While these models produce excellent samples, it has yet to be shown that they can achieve competitive log-likelihoods. We show that, with several small modifications, diffusion models can achieve competitive log-likelihoods in the image domain while maintaining high sample quality. Additionally, our models allow for sampling with an order of magnitude fewer diffusion steps with only a modest difference in sample quality. Finally, we explore how sample quality and log-likelihood scale with the number of diffusion steps and the amount of model capacity. We conclude that denoising diffusion probabilistic models are a promising class of generative models with excellent scaling properties and sample quality.",
      keywords: [
        "neural networks",
        "generative models",
        "log-likelihood",
        "diffusion models",
        "denoising diffusion probabilistic models",
        "image generation",
      ],
      accepted: false,
      publication_venue: "International Conference on Machine Learning",
      publication_venue_id: "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
      url: "https://www.semanticscholar.org/paper/de18baa4964804cf471d85a5a090498242d2e79f",
      citation_count: 3228,
      authors: ["Alex Nichol", "Prafulla Dhariwal"],
      authorIds: ["38967461", "6515819"],
      conference_year: 2021,
      conference_name: "iclr",
      conf_id: "iclr2021",
      review_scores: [5.0, 5.0, 5.0, 5.0],
      review_score_avg: 5.0,
      review_confidences: [5.0, 5.0, 5.0, 5.0],
      review_confidence_avg: 3.0,
    },
    {
      id: "px0-N3_KjA",
      semantic_scholar_id: "a326d9f2d2d351001fece788165dbcbb524da2e4",
      raw_decision: "ICLR 2021 Reject",
      normalized_decision: "Reject",
      title: "D4RL: Datasets for Deep Data-Driven Reinforcement Learning",
      abstract:
        "The offline reinforcement learning (RL) problem, also known as batch RL, refers to the setting where a policy must be learned from a static dataset, without additional online data collection. This setting is compelling as it potentially allows RL methods to take advantage of large, pre-collected datasets, much like how the rise of large datasets has fueled results in supervised learning in recent years. However, existing online RL benchmarks are not tailored towards the offline setting, making progress in offline RL difficult to measure. In this work, we introduce benchmarks specifically designed for the offline setting, guided by key properties of datasets relevant to real-world applications of offline RL. Examples of such properties include: datasets generated via hand-designed controllers and human demonstrators, multi-objective datasets where an agent can perform different tasks in the same environment, and datasets consisting of a mixtures of policies. To facilitate research, we release our benchmark tasks and datasets with a comprehensive evaluation of existing algorithms and an evaluation protocol together with an open-source codebase. We hope that our benchmark will focus research effort on methods that drive improvements not just on simulated tasks, but ultimately on the kinds of real-world problems where offline RL will have the largest impact. ",
      keywords: ["reinforcement learning", "deep learning", "benchmarks"],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/a326d9f2d2d351001fece788165dbcbb524da2e4",
      citation_count: 1251,
      authors: [
        "Justin Fu",
        "Aviral Kumar",
        "Ofir Nachum",
        "G. Tucker",
        "S. Levine",
      ],
      authorIds: ["2550764", "1488785534", "7624658", "145499435", "1736651"],
      conference_year: 2021,
      conference_name: "iclr",
      conf_id: "iclr2021",
      review_scores: [2.0, 6.0, 6.0, 6.0],
      review_score_avg: 5.0,
      review_confidences: [2.0, 6.0, 6.0, 6.0],
      review_confidence_avg: 4.75,
    },
    {
      id: "foNTMJHXHXC",
      semantic_scholar_id: "3621fff4a1c791901ea4a1359c10575193ec712d",
      raw_decision: "ICLR 2021 Reject",
      normalized_decision: "Reject",
      title: "Out-of-Distribution Generalization via Risk Extrapolation (REx)",
      abstract:
        "Distributional shift is one of the major obstacles when transferring machine learning prediction systems from the lab to the real world. To tackle this problem, we assume that variation across training domains is representative of the variation we might encounter at test time, but also that shifts at test time may be more extreme in magnitude. In particular, we show that reducing differences in risk across training domains can reduce a model\u2019s sensitivity to a wide range of extreme distributional shifts, including the challenging setting where the input contains both causal and anti-causal elements. We motivate this approach, Risk Extrapolation (REx), as a form of robust optimization over a perturbation set of extrapolated domains (MM-REx), and propose a penalty on the variance of training risks (V-REx) as a simpler variant. We prove that variants of REx can recover the causal mechanisms of the targets, while also providing some robustness to changes in the input distribution (``covariate shift''). By appropriately trading-off robustness to causally induced distributional shifts and covariate shift, REx is able to outperform alternative methods such as Invariant Risk Minimization in situations where these types of shift co-occur.",
      keywords: [
        "out of distribution",
        "domain generalization",
        "invariant risk minimization",
        "robust optimization",
        "invariant causal prediction",
        "spurious features",
        "generalization",
      ],
      accepted: false,
      publication_venue: "International Conference on Machine Learning",
      publication_venue_id: "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
      url: "https://www.semanticscholar.org/paper/3621fff4a1c791901ea4a1359c10575193ec712d",
      citation_count: 870,
      authors: [
        "David Krueger",
        "Ethan Caballero",
        "J. Jacobsen",
        "Amy Zhang",
        "Jonathan Binas",
        "R\u00e9mi Le Priol",
        "Aaron C. Courville",
      ],
      authorIds: [
        "145055042",
        "24130593",
        "51919565",
        "2111672235",
        "1737610",
        "10712297",
        "1760871",
      ],
      conference_year: 2021,
      conference_name: "iclr",
      conf_id: "iclr2021",
      review_scores: [6.0, 5.0, 6.0, 4.0],
      review_score_avg: 5.25,
      review_confidences: [6.0, 5.0, 6.0, 4.0],
      review_confidence_avg: 3.75,
    },
    {
      id: "lE1AB4stmX",
      semantic_scholar_id: "2051548f7681c96d603de932ee23406c525276f9",
      raw_decision: "ICLR 2021 Reject",
      normalized_decision: "Reject",
      title:
        "A Transformer-based Framework for Multivariate Time Series Representation Learning",
      abstract:
        "In this work we propose for the first time a transformer-based framework for unsupervised representation learning of multivariate time series. Pre-trained models can be potentially used for downstream tasks such as regression and classification, forecasting and missing value imputation. We evaluate our models on several benchmark datasets for multivariate time series regression and classification and show that they exceed current state-of-the-art performance, even when the number of training samples is very limited, while at the same time offering computational efficiency. We show that unsupervised pre-training of our transformer models offers a substantial performance benefit over fully supervised learning, even without leveraging additional unlabeled data, i.e., by reusing the same data samples through the unsupervised objective.",
      keywords: [
        "transformer",
        "multivariate time series",
        "unsupervised representation learning",
        "deep learning",
      ],
      accepted: false,
      publication_venue: "Knowledge Discovery and Data Mining",
      publication_venue_id: "a0edb93b-1e95-4128-a295-6b1659149cef",
      url: "https://www.semanticscholar.org/paper/2051548f7681c96d603de932ee23406c525276f9",
      citation_count: 839,
      authors: [
        "George Zerveas",
        "Srideepika Jayaraman",
        "Dhaval Patel",
        "A. Bhamidipaty",
        "Carsten Eickhoff",
      ],
      authorIds: [
        "30647302",
        "1988817745",
        "2059011837",
        "1804908",
        "30044743",
      ],
      conference_year: 2021,
      conference_name: "iclr",
      conf_id: "iclr2021",
      review_scores: [4.0, 4.0, 4.0, 4.0],
      review_score_avg: 4.0,
      review_confidences: [4.0, 4.0, 4.0, 4.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "io-EI8C0q6A",
      semantic_scholar_id: "863d7fdbdcd4bdb1b6eeb9c99ae144d236f03259",
      raw_decision: "ICLR 2021 Reject",
      normalized_decision: "Reject",
      title:
        "Unsupervised Cross-lingual Representation Learning for Speech Recognition",
      abstract:
        "This paper presents XLSR which learns cross-lingual speech representations by pretraining a single model from the raw waveform of speech in multiple languages. We build on wav2vec 2.0 which is trained by solving a contrastive task over masked latent speech representations and jointly learns a quantization of the latents shared across languages. The resulting model is fine-tuned on labeled data and experiments show that cross-lingual pretraining significantly outperforms monolingual pretraining. On the CommonVoice benchmark, XLSR shows a relative phoneme error rate reduction of 72% compared to the best known results. On BABEL, our approach improves word error rate by 16% relative compared to a comparable system. Our approach enables a single multilingual speech recognition model which is competitive to strong individual models. Analysis shows that the latent discrete speech representations are shared across languages with increased sharing for related languages.",
      keywords: [
        "Deep learning",
        "speech processing",
        "multilingual modeling",
        "cross-lingual",
      ],
      accepted: false,
      publication_venue: "Interspeech",
      publication_venue_id: "af90489e-312f-4514-bea2-bcb399cb8ece",
      url: "https://www.semanticscholar.org/paper/863d7fdbdcd4bdb1b6eeb9c99ae144d236f03259",
      citation_count: 736,
      authors: [
        "Alexis Conneau",
        "Alexei Baevski",
        "R. Collobert",
        "Abdel-rahman Mohamed",
        "Michael Auli",
      ],
      authorIds: ["2480903", "51428394", "2939803", "40360972", "2325985"],
      conference_year: 2021,
      conference_name: "iclr",
      conf_id: "iclr2021",
      review_scores: [6.0, 4.0, 6.0, 5.0],
      review_score_avg: 5.25,
      review_confidences: [6.0, 4.0, 6.0, 5.0],
      review_confidence_avg: 4.25,
    },
    {
      id: "B9t708KMr9d",
      semantic_scholar_id: "f5623cd36228c0606c1dbcd3ab034df24c58312f",
      raw_decision: "ICLR 2021 Reject",
      normalized_decision: "Reject",
      title:
        "Masked Label Prediction: Unified Massage Passing Model for Semi-Supervised Classification",
      abstract:
        "Graph neural network (GNN) and label propagation algorithm (LPA) are both message passing algorithms, which have achieved superior performance in semi-supervised classification. GNN performs \\emph{feature propagation} by a neural network to make predictions, while LPA uses \\emph{label propagation} across graph adjacency matrix to get results. However, there is still no good way to combine these two kinds of algorithms. In this paper, we proposed a new {\\bf Uni}fied {\\bf M}essage {\\bf P}assaging Model (UniMP) that can incorporate \\emph{feature propagation} and \\emph{label propagation} with a shared message passing network, providing a better performance in semi-supervised classification. First, we adopt a Graph Transformer jointly label embedding to propagate both the feature and label information. Second, to train UniMP without overfitting in self-loop label information, we propose a masked label prediction strategy, in which some percentage of training labels are simply masked at random, and then predicted. UniMP conceptually unifies feature propagation and label propagation and be empirically powerful. It obtains new state-of-the-art semi-supervised classification results in Open Graph Benchmark (OGB). ",
      keywords: [
        "Unified Message Passing Model",
        "Graph Neural Network",
        "Label Propagation Algorithm",
        "Semi-Supervised Classification.",
      ],
      accepted: false,
      publication_venue:
        "International Joint Conference on Artificial Intelligence",
      publication_venue_id: "67f7f831-711a-43c8-8785-1e09005359b5",
      url: "https://www.semanticscholar.org/paper/f5623cd36228c0606c1dbcd3ab034df24c58312f",
      citation_count: 693,
      authors: [
        "Yunsheng Shi",
        "Zhengjie Huang",
        "Wenjin Wang",
        "Hui Zhong",
        "Shikun Feng",
        "Yu Sun",
      ],
      authorIds: [
        "48081324",
        "2151325127",
        "2117833477",
        "2064918759",
        "1718657",
        "2117103617",
      ],
      conference_year: 2021,
      conference_name: "iclr",
      conf_id: "iclr2021",
      review_scores: [7.0, 6.0, 4.0, 5.0],
      review_score_avg: 5.5,
      review_confidences: [7.0, 6.0, 4.0, 5.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "T4gXBOXoIUr",
      semantic_scholar_id: "6dd9f99cecd38504b667d320eb2a6267a9fee35d",
      raw_decision: "ICLR 2021 Reject",
      normalized_decision: "Reject",
      title:
        "Contrastive Learning of Medical Visual Representations from Paired Images and Text",
      abstract:
        "Learning visual representations of medical images is core to medical image understanding but its progress has been held back by the small size of hand-labeled datasets. Existing work commonly relies on transferring weights from ImageNet pretraining, which is suboptimal due to drastically different image characteristics, or rule-based label extraction from the textual report data paired with medical images, which is inaccurate and hard to generalize. We propose an alternative unsupervised strategy to learn medical visual representations directly from the naturally occurring pairing of images and textual data. Our method of pretraining medical image encoders with the paired text data via a bidirectional contrastive objective between the two modalities is domain-agnostic, and requires no additional expert input. We test our method by transferring our pretrained weights to 4 medical image classification tasks and 2 zero-shot retrieval tasks, and show that our method leads to image representations that considerably outperform strong baselines in most settings. Notably, in all 4 classification tasks, our method requires only 10% as much labeled training data as an ImageNet initialized counterpart to achieve better or comparable performance, demonstrating superior data efficiency.",
      keywords: [
        "visual representation learning",
        "contrastive learning",
        "medical image understanding",
        "natural language processing",
      ],
      accepted: false,
      publication_venue: "Machine Learning in Health Care",
      publication_venue_id: "6171bcff-8306-41c7-af12-fa1d87117cf1",
      url: "https://www.semanticscholar.org/paper/6dd9f99cecd38504b667d320eb2a6267a9fee35d",
      citation_count: 689,
      authors: [
        "Yuhao Zhang",
        "Hang Jiang",
        "Yasuhide Miura",
        "Christopher D. Manning",
        "C. Langlotz",
      ],
      authorIds: ["49889487", "48579520", "2965600", "144783904", "2356307"],
      conference_year: 2021,
      conference_name: "iclr",
      conf_id: "iclr2021",
      review_scores: [4.0, 6.0, 5.0],
      review_score_avg: 5.0,
      review_confidences: [4.0, 6.0, 5.0],
      review_confidence_avg: 4.3333333333,
    },
    {
      id: "OJiM1R3jAtZ",
      semantic_scholar_id: "0272b14dd471fe7b81df703af1b71d7600b77215",
      raw_decision: "ICLR 2021 Reject",
      normalized_decision: "Reject",
      title: "Accelerating Online Reinforcement Learning with Offline Datasets",
      abstract:
        "Reinforcement learning provides an appealing formalism for learning control policies from experience. However, the classic active formulation of reinforcement learning necessitates a lengthy active exploration process for each behavior, making it difficult to apply in real-world settings. If we can instead allow reinforcement learning to effectively use previously collected data to aid the online learning process, where the data could be expert demonstrations or more generally any prior experience, we could make reinforcement learning a substantially more practical tool. While a number of recent methods have sought to learn offline from previously collected data, it remains exceptionally difficult to train a policy with offline data and improve it further with online reinforcement learning. In this paper we systematically analyze why this problem is so challenging, and propose an algorithm that combines sample-efficient dynamic programming with maximum likelihood policy updates, providing a simple and effective framework that is able to leverage large amounts of offline data and then quickly perform online fine-tuning of reinforcement learning policies. We show that our method enables rapid learning of skills with a combination of prior demonstration data and online experience across a suite of difficult dexterous manipulation and benchmark tasks.",
      keywords: ["reinforcement learning"],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/0272b14dd471fe7b81df703af1b71d7600b77215",
      citation_count: 583,
      authors: ["Ashvin Nair", "Murtaza Dalal", "Abhishek Gupta", "S. Levine"],
      authorIds: ["3422774", "35904540", "2129458064", "1736651"],
      conference_year: 2021,
      conference_name: "iclr",
      conf_id: "iclr2021",
      review_scores: [6.0, 3.0, 6.0, 6.0, 4.0],
      review_score_avg: 5.0,
      review_confidences: [6.0, 3.0, 6.0, 6.0, 4.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "CLnj31GZ4cI",
      semantic_scholar_id: "4f03e69963b9649950ba29ae864a0de8c14f1f86",
      raw_decision: "ICLR 2021 Reject",
      normalized_decision: "Reject",
      title:
        "K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters",
      abstract:
        "We study the problem of injecting knowledge into large pre-trained models like BERT and RoBERTa. Existing methods typically update the original parameters of pre-trained models when injecting knowledge. However, when multiple kinds of knowledge are injected, they may suffer from catastrophic forgetting.  To address this, we propose K-Adapter, which remains the original parameters of the pre-trained model fixed and supports continual knowledge infusion. Taking RoBERTa as the pre-trained model, K-Adapter has a neural adapter for each kind of infused knowledge, like a plug-in connected to RoBERTa. There is no information flow between different adapters, thus different adapters are efficiently trained in a distributed way. We inject two kinds of knowledge, including factual knowledge obtained from automatically aligned text-triplets on Wikipedia and Wikidata, and linguistic knowledge obtained from dependency parsing. Results on three knowledge-driven tasks (total six datasets) including relation classification, entity typing and question answering demonstrate that each adapter improves the performance, and the combination of both adapters brings further improvements. Probing experiments further indicate that K-Adapter captures richer factual and commonsense knowledge than RoBERTa.",
      keywords: [],
      accepted: false,
      publication_venue: "Findings",
      publication_venue_id: "479d5605-51be-4346-b1d6-4334084504df",
      url: "https://www.semanticscholar.org/paper/4f03e69963b9649950ba29ae864a0de8c14f1f86",
      citation_count: 537,
      authors: [
        "Ruize Wang",
        "Duyu Tang",
        "Nan Duan",
        "Zhongyu Wei",
        "Xuanjing Huang",
        "Jianshu Ji",
        "Guihong Cao",
        "Daxin Jiang",
        "Ming Zhou",
      ],
      authorIds: [
        "29068663",
        "39483833",
        "46429989",
        "2712533",
        "1790227",
        "22206677",
        "3320836",
        "71790825",
        "92660691",
      ],
      conference_year: 2021,
      conference_name: "iclr",
      conf_id: "iclr2021",
      review_scores: [6.0, 7.0, 4.0, 6.0],
      review_score_avg: 5.75,
      review_confidences: [6.0, 7.0, 4.0, 6.0],
      review_confidence_avg: 3.5,
    },
    {
      id: "g0a-XYjpQ7r",
      semantic_scholar_id: "5c6952731c5f5a5de1311f66a0590e035cca418d",
      raw_decision: "ICLR 2021 Reject",
      normalized_decision: "Reject",
      title: "Adaptive Personalized Federated Learning",
      abstract:
        "Investigation of the degree of personalization in federated learning algorithms has shown that only maximizing the performance of the global model will confine the capacity of the local models to personalize. In this paper, we advocate an adaptive personalized federated learning (APFL) algorithm, where each client will train their local models while contributing to the global model.  We derive the generalization bound of mixture of local and global models, and find the optimal mixing parameter. We also  propose a  communication-efficient  optimization method to collaboratively learn the personalized models and analyze its convergence in both smooth strongly convex and nonconvex settings.  The extensive experiments demonstrate the effectiveness of our personalization schema, as well as the correctness of established generalization theories.\n",
      keywords: ["Federated learning", "Personalization", "Optimization"],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/5c6952731c5f5a5de1311f66a0590e035cca418d",
      citation_count: 524,
      authors: ["Yuyang Deng", "Mohammad Mahdi Kamani", "M. Mahdavi"],
      authorIds: ["1598375183", "8917957", "1694826"],
      conference_year: 2021,
      conference_name: "iclr",
      conf_id: "iclr2021",
      review_scores: [6.0, 5.0, 7.0, 3.0],
      review_score_avg: 5.25,
      review_confidences: [6.0, 5.0, 7.0, 3.0],
      review_confidence_avg: 3.5,
    },
  ],
  iclr2022: [
    {
      id: "OgCcfc1m0TO",
      semantic_scholar_id: "96ea07447d2f9adefe03852a878517a2a6d45b96",
      raw_decision: "ICLR 2022 Rejected",
      normalized_decision: "Reject",
      title: "Learning to Prompt for Vision-Language Models",
      abstract:
        "Vision-language pre-training has recently emerged as a promising alternative for representation learning. It shifts from the tradition of using images and discrete labels for learning a fixed set of weights, seen as visual concepts, to aligning images and raw text for two separate encoders. Such a paradigm benefits from a broader source of supervision and allows zero-shot transfer to downstream tasks since visual concepts can be diametrically generated from natural language, known as prompt. In this paper, we identify that a major challenge of deploying such models in practice is prompt engineering. This is because designing a proper prompt, especially for context words surrounding a class name, requires domain expertise and typically takes a significant amount of time for words tuning since a slight change in wording could have a huge impact on performance. Moreover, different downstream tasks require specific designs, further hampering the efficiency of deployment. To overcome this challenge, we propose a novel approach named \\emph{context optimization (CoOp)}. The main idea is to model context in prompts using continuous representations and perform end-to-end learning from data while keeping the pre-trained parameters fixed. In this way, the design of task-relevant prompts can be fully automated. Experiments on 11 datasets show that CoOp effectively turns pre-trained vision-language models into data-efficient visual learners, requiring as few as one or two shots to beat hand-crafted prompts with a decent margin and able to gain significant improvements when using more shots (e.g., at 16 shots the average gain is around 17\\% with the highest reaching over 50\\%). CoOp also exhibits strong robustness to distribution shift.",
      keywords: [
        "vision-language models",
        "prompt learning",
        "computer vision",
        "transfer learning",
      ],
      accepted: false,
      publication_venue: "International Journal of Computer Vision",
      publication_venue_id: "939ee07c-6009-43f8-b884-69238b40659e",
      url: "https://www.semanticscholar.org/paper/96ea07447d2f9adefe03852a878517a2a6d45b96",
      citation_count: 2120,
      authors: [
        "Kaiyang Zhou",
        "Jingkang Yang",
        "Chen Change Loy",
        "Ziwei Liu",
      ],
      authorIds: ["9368124", "2295601", "1717179", "2117940996"],
      conference_year: 2022,
      conference_name: "iclr",
      conf_id: "iclr2022",
      review_scores: [6.0, 5.0, 5.0, 1.0],
      review_score_avg: 4.25,
      review_confidences: [6.0, 5.0, 5.0, 1.0],
      review_confidence_avg: 4.25,
    },
    {
      id: "6NT1a56mNim",
      semantic_scholar_id: "92a8f7f09f3705cb5a6009a42220a6f01ea084e8",
      raw_decision: "ICLR 2022 Rejected",
      normalized_decision: "Reject",
      title:
        "Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents",
      abstract:
        'Can world knowledge learned by large language models (LLMs) be used to act in interactive environments? In this paper, we investigate the possibility of grounding high-level tasks, expressed in natural language (i.e. "make breakfast"), to a fixed set of actionable steps (i.e. "open fridge"). While prior work focused on learning from explicit step-by-step examples of how to act, we surprisingly find that if pre-trained LMs are large enough and prompted appropriately, they can effectively decompose high-level tasks into low-level plans without any further training. However, the plans produced naively by LLMs often cannot map precisely to admissible actions. We propose a procedure that conditions on existing demonstrations and semantically translates the plans to admissible actions. Our evaluation in the recent VirtualHome environment shows that the resulting method substantially improves executability over the LLM baseline. The conducted human evaluation reveals a trade-off between executability and correctness but shows a promising sign towards extracting actionable knowledge from language models. Videos at https://sites.google.com/view/language-model-as-planner',
      keywords: [
        "GPT-3",
        "Codex",
        "LLMs",
        "Language Models",
        "Knowledge Extraction",
        "Embodied Agents",
        "Action Planning",
      ],
      accepted: false,
      publication_venue: "International Conference on Machine Learning",
      publication_venue_id: "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
      url: "https://www.semanticscholar.org/paper/92a8f7f09f3705cb5a6009a42220a6f01ea084e8",
      citation_count: 990,
      authors: ["Wenlong Huang", "P. Abbeel", "Deepak Pathak", "Igor Mordatch"],
      authorIds: ["2158105356", "1689992", "2004879394", "2080746"],
      conference_year: 2022,
      conference_name: "iclr",
      conf_id: "iclr2022",
      review_scores: [5.0, 3.0, 8.0, 5.0, 6.0],
      review_score_avg: 5.4,
      review_confidences: [5.0, 3.0, 8.0, 5.0, 6.0],
      review_confidence_avg: 4.2,
    },
    {
      id: "iedYJm92o0a",
      semantic_scholar_id: "92173d081b15824d22a9ef070e118744ceee8052",
      raw_decision: "ICLR 2022 Rejected",
      normalized_decision: "Reject",
      title:
        "Show Your Work: Scratchpads for Intermediate Computation with Language Models",
      abstract:
        'Large pre-trained language models perform remarkably well on tasks that can be done "in one pass", such as generating realistic text or synthesizing computer programs. However, they struggle with tasks that require unbounded multi-step computation, such as adding integers  or executing programs. Surprisingly, we find that these same models are able to perform complex multi-step computations --- even in the few-shot regime --- when asked to perform the operation "step by step", showing the results of intermediate computations. In particular, we train transformers to perform multi-step computations by asking them to emit intermediate computation steps into a "scratchpad". On a series of increasingly complex tasks ranging from long addition to the execution of arbitrary programs, we show that scratchpads dramatically improve the ability of language models to perform multi-step computations. ',
      keywords: [
        "program synthesis",
        "transformers",
        "language models",
        "pre-training",
        "program induction",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/92173d081b15824d22a9ef070e118744ceee8052",
      citation_count: 673,
      authors: [
        "Maxwell Nye",
        "Anders Andreassen",
        "Guy Gur-Ari",
        "H. Michalewski",
        "Jacob Austin",
        "David Bieber",
        "David Dohan",
        "Aitor Lewkowycz",
        "Maarten Bosma",
        "D. Luan",
        "Charles Sutton",
        "Augustus Odena",
      ],
      authorIds: [
        "51150953",
        "39552848",
        "2284681044",
        "47407464",
        "2058365883",
        "3426307",
        "35363891",
        "102549875",
        "40377863",
        "150970919",
        "152549864",
        "2624088",
      ],
      conference_year: 2022,
      conference_name: "iclr",
      conf_id: "iclr2022",
      review_scores: [3.0, 8.0, 8.0, 3.0],
      review_score_avg: 5.5,
      review_confidences: [3.0, 8.0, 8.0, 3.0],
      review_confidence_avg: 4.25,
    },
    {
      id: "TVHS5Y4dNvM",
      semantic_scholar_id: "3425495ee3b6ead009f35aeb70edeac4e6eb2d10",
      raw_decision: "ICLR 2022 Rejected",
      normalized_decision: "Reject",
      title: "Patches Are All You Need?",
      abstract:
        "Although convolutional networks have been the dominant architecture for vision tasks for many years, recent experiments have shown that Transformer-based models, most notably the Vision Transformer (ViT), may exceed their performance in some settings. However, due to the quadratic runtime of the self-attention layers in Transformers, ViTs require the use of patch embeddings, which group together small regions of the image into single input features, in order to be applied to larger image sizes. This raises a question: Is the performance of ViTs due to the inherently-more-powerful Transformer architecture, or is it at least partly due to using patches as the input representation? In this paper, we present some evidence for the latter: specifically, we propose the ConvMixer, an extremely simple model that is similar in spirit to the ViT and the even-more-basic MLP-Mixer in that it operates directly on patches as input, separates the mixing of spatial and channel dimensions, and maintains equal size and resolution throughout the network. In contrast, however, the ConvMixer uses only standard convolutions to achieve the mixing steps. Despite its simplicity, we show that the ConvMixer outperforms the ViT, MLP-Mixer, and some of their variants for similar parameter counts and data set sizes, in addition to outperforming classical vision models such as the ResNet. Our code is available at https://github.com/tmp-iclr/convmixer.",
      keywords: [
        "computer vision",
        "vision transformer",
        "mixer",
        "patch embeddings",
        "convolution",
        "convolutional neural network",
      ],
      accepted: false,
      publication_venue: null,
      publication_venue_id: null,
      url: "https://www.semanticscholar.org/paper/3425495ee3b6ead009f35aeb70edeac4e6eb2d10",
      citation_count: 387,
      authors: ["Asher Trockman", "J. Z. Kolter"],
      authorIds: ["50820040", "145116464"],
      conference_year: 2022,
      conference_name: "iclr",
      conf_id: "iclr2022",
      review_scores: [5.0, 5.0, 8.0],
      review_score_avg: 6.0,
      review_confidences: [5.0, 5.0, 8.0],
      review_confidence_avg: 4.3333333333,
    },
    {
      id: "dtYnHcmQKeM",
      semantic_scholar_id: "319d0aea3b8d5500ea01d722bf9deaf776915634",
      raw_decision: "ICLR 2022 Rejected",
      normalized_decision: "Reject",
      title:
        "Physics-Informed Neural Operator for Learning Partial Differential Equations",
      abstract:
        "Machine learning methods have recently shown promise in solving partial differential equations (PDEs). They can be classified into two broad categories: solution function approximation, and operator learning. The Physics-Informed Neural Network (PINN) is an example of the former while the Fourier neural operator (FNO) is an example of the latter. Both these approaches have shortcomings. The optimization in PINN is challenging and prone to failure, especially on multi-scale dynamic systems. FNO does not suffer from this optimization issue since it carries out supervised learning on a given dataset, but obtaining such data may be too expensive or infeasible. In this work, we propose the physics-informed neural operator (PINO), where we combine the operating-learning and function-optimization frameworks, and this improves convergence rates and accuracy over both PINN and FNO models. In the operator-learning phase, PINO learns the solution operator over multiple instances of the parametric PDE family. In the test-time optimization phase, PINO optimizes the pre-trained operator ansatz for the querying instance of the PDE. Experiments show PINO outperforms previous ML methods on many popular PDE families while retaining the extraordinary speed-up of FNO compared to solvers. In particular, PINO accurately solves long temporal transient flows and chaotic Kolmogorov flows, while PINN and other methods fail to converge to a reasonable accuracy.  ",
      keywords: [
        "Partial Differential Equations",
        "operator learning",
        "physics-informed",
        "PINN",
        "inverse problem",
        "Navier-Stokes Equation",
      ],
      accepted: false,
      publication_venue: "ACM / IMS Journal of Data Science",
      publication_venue_id: "631003ea-2037-4ba9-bd3b-7519455cc411",
      url: "https://www.semanticscholar.org/paper/319d0aea3b8d5500ea01d722bf9deaf776915634",
      citation_count: 353,
      authors: [
        "Zong-Yi Li",
        "Hongkai Zheng",
        "Nikola B. Kovachki",
        "David Jin",
        "Haoxuan Chen",
        "Burigede Liu",
        "K. Azizzadenesheli",
        "Anima Anandkumar",
      ],
      authorIds: [
        "1390750243",
        "1388823889",
        "51219644",
        "2152284449",
        "2149053100",
        "2048777595",
        "3371922",
        "2047844",
      ],
      conference_year: 2022,
      conference_name: "iclr",
      conf_id: "iclr2022",
      review_scores: [5.0, 6.0, 5.0, 3.0],
      review_score_avg: 4.75,
      review_confidences: [5.0, 6.0, 5.0, 3.0],
      review_confidence_avg: 2.5,
    },
    {
      id: "nL2lDlsrZU",
      semantic_scholar_id: "5fa2103e36b3e76e49edb8433a1206a6b25e3ead",
      raw_decision: "ICLR 2022 Rejected",
      normalized_decision: "Reject",
      title:
        "SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training",
      abstract:
        "Tabular data underpins numerous high-impact applications of machine learning from fraud detection to genomics and healthcare.  Classical approaches to solving tabular problems, such as gradient boosting and random forests, are widely used by practitioners.  However, recent deep learning methods have achieved a degree of performance competitive with popular techniques.  We devise a hybrid deep learning approach to solving tabular data problems.  Our method, SAINT, performs attention over both rows and columns, and it includes an enhanced embedding method.  We also study a new contrastive self-supervised pre-training method for use when labels are scarce.  SAINT consistently improves performance over previous deep learning methods, and it even performs competitively with gradient boosting methods, including XGBoost, CatBoost, and LightGBM, on average over $30$ benchmark datasets in regression, binary classification, and multi-class classification tasks.",
      keywords: [
        "Transformer",
        "Tabular",
        "Attention",
        "Contrastive Pre-Training",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/5fa2103e36b3e76e49edb8433a1206a6b25e3ead",
      citation_count: 283,
      authors: [
        "Gowthami Somepalli",
        "Micah Goldblum",
        "Avi Schwarzschild",
        "C. B. Bruss",
        "T. Goldstein",
      ],
      authorIds: ["2003112028", "121592562", "102604362", "8954363", "1962083"],
      conference_year: 2022,
      conference_name: "iclr",
      conf_id: "iclr2022",
      review_scores: [6.0, 3.0, 3.0, 5.0],
      review_score_avg: 4.25,
      review_confidences: [6.0, 3.0, 3.0, 5.0],
      review_confidence_avg: 4.25,
    },
    {
      id: "R2aCiGQ9Qc",
      semantic_scholar_id: "5b1ce73eee6d80a3897bb03468b067f6583fdba8",
      raw_decision: "ICLR 2022 Rejected",
      normalized_decision: "Reject",
      title:
        "Two Sides of the Same Coin: Heterophily and Oversmoothing in Graph Convolutional Neural Networks",
      abstract:
        'In node classification tasks, heterophily and oversmoothing are two problems that can hurt the performance of graph convolutional neural networks (GCNs). The heterophily problem refers to the model\'s inability to handle heterophilous graphs where neighboring nodes belong to different classes; the oversmoothing problem refers to the model\'s degenerated performance with increasing number of layers. These two seemingly unrelated problems have been studied mostly independently, but there is recent empirical evidence that solving one problem may benefit the other. \n\nIn this work, beyond empirical observations, we aim to: (1) analyze the heterophily and oversmoothing problems from a unified theoretical perspective, (2) identify the common causes of the two problems based on our theories, and (3) propose simple yet effective strategies to address the common causes. In our theoretical analysis, we show that the common causes of the heterophily and oversmoothing problems---namely, the relative degree of a node (compared to its neighbors) and its heterophily level---trigger the node representations in consecutive layers to "move" closer to the original decision boundary, which increases the misclassification rate of node labels under certain constraints. We theoretically show that: (1) Nodes with high heterophily have a higher misclassification rate. (2) Even with low heterophily, degree disparity in a node\'s neighborhood can influence the movements of node representations and result in a "pseudo-heterophily" situation, which helps to explain oversmoothing. (3) Allowing not only positive, but also negative messages during message passing can help counteract the common causes of the two problems. Based on our theoretical insights, we propose simple modifications to the GCN architecture (i.e., learned degree corrections and signed messages), and we show that they alleviate the heteorophily and oversmoothing problems with extensive experiments on nine real networks. Compared to other approaches, which tend to work well in either heterophily or oversmoothing, our modified GCN model performs well in both problems.',
      keywords: [
        "graph convolutional neural networks",
        "node classification",
        "heterophily",
        "oversmoothing",
      ],
      accepted: false,
      publication_venue: "Industrial Conference on Data Mining",
      publication_venue_id: "67d15a94-d523-4b5f-be58-03fe2ef9dcfb",
      url: "https://www.semanticscholar.org/paper/5b1ce73eee6d80a3897bb03468b067f6583fdba8",
      citation_count: 239,
      authors: [
        "Yujun Yan",
        "Milad Hashemi",
        "Kevin Swersky",
        "Yaoqing Yang",
        "Danai Koutra",
      ],
      authorIds: ["7957569", "33798741", "2329092656", "49576470", "2479152"],
      conference_year: 2022,
      conference_name: "iclr",
      conf_id: "iclr2022",
      review_scores: [3.0, 6.0, 6.0, 5.0],
      review_score_avg: 5.0,
      review_confidences: [3.0, 6.0, 6.0, 5.0],
      review_confidence_avg: 3.5,
    },
    {
      id: "TCl7CbQ29hH",
      semantic_scholar_id: "458af0f3f03229290572a2630c75ac56e9dbec6e",
      raw_decision: "ICLR 2022 Rejected",
      normalized_decision: "Reject",
      title:
        "CPT: Colorful Prompt Tuning for Pre-trained Vision-Language Models",
      abstract:
        "Pre-Trained Vision-Language Models (VL-PTMs) have shown promising capabilities in grounding natural language in image data, facilitating a broad variety of cross-modal tasks. However, we note that there exists a significant gap between the objective forms of model pre-training and fine-tuning, resulting in a need for large amounts of labeled data to stimulate the visual grounding capability of VL-PTMs for downstream tasks. To address the challenge, we present Cross-modal Prompt Tuning (CPT, alternatively, Colorful Prompt Tuning), a novel paradigm for tuning VL-PTMs, which reformulates visual grounding into a fill-in-the-blank problem with color-based co-referential markers in image and text, maximally mitigating the gap. In this way, CPT enables strong few-shot and even zero-shot visual grounding capabilities of VL-PTMs. Comprehensive experimental results show that the prompt-tuned VL-PTMs outperform their fine-tuned counterparts by a large margin (e.g., 17.3% absolute accuracy improvement, and 73.8% relative standard deviation reduction on average with one shot in RefCOCO evaluation). All the data and codes will be available to facilitate future research.",
      keywords: [
        "Pretrained Vision-language Models",
        "Prompt Tuning",
        "Visual Grounding",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/458af0f3f03229290572a2630c75ac56e9dbec6e",
      citation_count: 218,
      authors: [
        "Yuan Yao",
        "Ao Zhang",
        "Zhengyan Zhang",
        "Zhiyuan Liu",
        "Tat-seng Chua",
        "Maosong Sun",
      ],
      authorIds: [
        "1390925224",
        "2153656874",
        "2148904862",
        "2141313179",
        "143779329",
        "1753344",
      ],
      conference_year: 2022,
      conference_name: "iclr",
      conf_id: "iclr2022",
      review_scores: [5.0, 5.0, 6.0, 6.0],
      review_score_avg: 5.5,
      review_confidences: [5.0, 5.0, 6.0, 6.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "SVcEx6SC_NL",
      semantic_scholar_id: "5d28bdfa02f0766febff32b7a6b287611d6f2995",
      raw_decision: "ICLR 2022 Rejected",
      normalized_decision: "Reject",
      title: "Adversarial Robustness as a Prior for Learned Representations",
      abstract:
        "An common goal in deep learning is to learn versatile, high-level feature representations of input data. However, standard networks' representations seem to possess shortcomings that, as we illustrate, prevent them from fully realizing this goal. In this work, we show that robust optimization can be re-cast as a tool for enforcing priors on the features learned by deep neural networks. It turns out that representations learned by robust models address the aforementioned shortcomings and make significant progress towards learning a high-level encoding of inputs. In particular, these representations are approximately invertible, while allowing for direct visualization and manipulation of salient input features. More broadly, our results indicate adversarial robustness as a promising avenue for improving learned representations. ",
      keywords: ["adversarial robustness", "representation learning"],
      accepted: false,
      publication_venue: null,
      publication_venue_id: null,
      url: "https://www.semanticscholar.org/paper/5d28bdfa02f0766febff32b7a6b287611d6f2995",
      citation_count: 214,
      authors: [
        "Logan Engstrom",
        "Andrew Ilyas",
        "Shibani Santurkar",
        "Dimitris Tsipras",
        "Brandon Tran",
        "A. Madry",
      ],
      authorIds: [
        "39468283",
        "34562927",
        "2852106",
        "2754804",
        "2057910582",
        "143826246",
      ],
      conference_year: 2022,
      conference_name: "iclr",
      conf_id: "iclr2022",
      review_scores: [3.0, 5.0, 5.0, 3.0],
      review_score_avg: 4.0,
      review_confidences: [3.0, 5.0, 5.0, 3.0],
      review_confidence_avg: 3.75,
    },
    {
      id: "TQ75Md-FqQp",
      semantic_scholar_id: "482c496bd7c328f219fe8a75298146edd35d3f46",
      raw_decision: "ICLR 2022 Rejected",
      normalized_decision: "Reject",
      title: "Efficient and Modular Implicit Differentiation",
      abstract:
        "Automatic differentiation (autodiff) has revolutionized machine learning.  It allows expressing complex computations by composing elementary ones in creative ways and removes the tedious burden of computing their derivatives by hand. More recently, differentiation of optimization problem solutions has attracted a great deal of research, with applications as a layer in a neural network, and in bi-level optimization, including hyper-parameter optimization. However, the formulae for these derivatives often involves a tedious manual derivation and implementation. In this paper, we propose a unified, efficient and modular approach for implicit differentiation of optimization problems. In our approach, the user defines directly in Python a function $F$ capturing the optimality conditions of the problem to be differentiated. Once this is done, we leverage autodiff of $F$ to automatically differentiate the optimization problem. This way, our approach combines the benefits of implicit differentiation and autodiff.  We show that seemingly simple principles allow to recover all recently proposed implicit differentiation methods and create new ones easily. We describe in details a JAX implementation of our framework and demonstrate the ease of differentiating through optimization problems thanks to it on four diverse tasks: hyperparameter optimization of multiclass SVMs, dataset distillation, task-driven dictionary learning and sensitivity analysis of molecular dynamics.",
      keywords: [
        "implicit differentiation",
        "bilevel optimization",
        "autodiff",
        "jax",
      ],
      accepted: false,
      publication_venue: "Neural Information Processing Systems",
      publication_venue_id: "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
      url: "https://www.semanticscholar.org/paper/482c496bd7c328f219fe8a75298146edd35d3f46",
      citation_count: 206,
      authors: [
        "Mathieu Blondel",
        "Quentin Berthet",
        "Marco Cuturi",
        "Roy Frostig",
        "Stephan Hoyer",
        "Felipe Llinares-L'opez",
        "Fabian Pedregosa",
        "Jean-Philippe Vert",
      ],
      authorIds: [
        "27257992",
        "3169833",
        "1711979",
        "34765463",
        "7018631",
        "2075355249",
        "2570016",
        "152303545",
      ],
      conference_year: 2022,
      conference_name: "iclr",
      conf_id: "iclr2022",
      review_scores: [10.0, 3.0, 8.0],
      review_score_avg: 7.0,
      review_confidences: [10.0, 3.0, 8.0],
      review_confidence_avg: 3.3333333333,
    },
  ],
  iclr2023: [
    {
      id: "NiEtU7blzN",
      semantic_scholar_id: "3fa70115248377c3d1517c9f978791a296fbc1dd",
      raw_decision: "ICLR 2023 Rejected",
      normalized_decision: "Reject",
      title: "Large Language Models Can Self-Improve",
      abstract:
        "Large Language Models (LLMs) have achieved excellent performances in various tasks. However, fine-tuning an LLM requires extensive supervision. Human, on the other hand, may improve their reasoning abilities by self-thinking without external inputs. In this work, we demonstrate that an LLM is also capable of self-improving with only unlabeled datasets. We use a pre-trained LLM to generate \u201chigh-confidence\u201d rationale-augmented answers for unlabeled questions using Chain-of-Thought prompting and self-consistency, and fine-tune the LLM using those self-generated solutions as target outputs. We show that our approach improves the general reasoning ability of a 540B-parameter LLM (74.4%\u219282.1% on GSM8K, 78.2%\u219283.0% on DROP, 90.0%\u219294.4% on OpenBookQA, and 63.4%\u219267.9% on ANLI-A3) and achieves state-of-the-art-level performance, without any ground truth label. We conduct ablation studies and show that finetuning on reasoning is critical for self-improvement.",
      keywords: [
        "natural language processing",
        "unsupervised learning",
        "chain of thought",
      ],
      accepted: false,
      publication_venue:
        "Conference on Empirical Methods in Natural Language Processing",
      publication_venue_id: "41bf9ed3-85b3-4c90-b015-150e31690253",
      url: "https://www.semanticscholar.org/paper/3fa70115248377c3d1517c9f978791a296fbc1dd",
      citation_count: 530,
      authors: [
        "Jiaxin Huang",
        "S. Gu",
        "Le Hou",
        "Yuexin Wu",
        "Xuezhi Wang",
        "Hongkun Yu",
        "Jiawei Han",
      ],
      authorIds: [
        "3488341",
        "2046135",
        "2153400663",
        "9287688",
        "1524732527",
        "40244451",
        "2111759643",
      ],
      conference_year: 2023,
      conference_name: "iclr",
      conf_id: "iclr2023",
      review_scores: [8.0, 3.0, 3.0],
      review_score_avg: 4.6666666667,
      review_confidences: [8.0, 3.0, 3.0],
      review_confidence_avg: 4.3333333333,
    },
    {
      id: "PUwbwZJz9dO",
      semantic_scholar_id: "e070ff286709db28312e08b52b05539debe88146",
      raw_decision: "ICLR 2023 Rejected",
      normalized_decision: "Reject",
      title:
        "Measuring and Narrowing the Compositionality Gap in Language Models",
      abstract:
        "We investigate the ability of language models to perform compositional reasoning tasks where the overall solution depends on correctly composing the answers to sub-problems. We measure how often models can correctly answer all sub-problems  but not generate the overall solution, a ratio we call the compositionality gap. We evaluate this ratio by asking multi-hop questions with answers that require composing multiple facts unlikely to have been observed together during pretraining. In the GPT-3 family of models, as model size increases we show that the single-hop question answering performance improves faster than the multi-hop performance does, therefore the compositionality gap does not decrease. This surprising result suggests that while more powerful models memorize and recall more factual knowledge, they show no corresponding improvement in their ability to perform this kind of compositional reasoning.\nWe then demonstrate how elicitive prompting (such as chain of thought) narrows the compositionality gap by reasoning explicitly instead of implicitly.  We present a new method, self-ask, that further improves on chain of thought. In our method, the model explicitly asks itself (and then answers) follow-up questions before answering the initial question. We finally show that self-ask's structured prompting lets us easily plug in a search engine to answer the follow-up questions, which additionally improves accuracy.",
      keywords: [
        "language modeling",
        "prompting",
        "question answering",
        "retrieval",
      ],
      accepted: false,
      publication_venue:
        "Conference on Empirical Methods in Natural Language Processing",
      publication_venue_id: "41bf9ed3-85b3-4c90-b015-150e31690253",
      url: "https://www.semanticscholar.org/paper/e070ff286709db28312e08b52b05539debe88146",
      citation_count: 515,
      authors: [
        "Ofir Press",
        "Muru Zhang",
        "Sewon Min",
        "Ludwig Schmidt",
        "Noah A. Smith",
        "M. Lewis",
      ],
      authorIds: [
        "40170001",
        "2116096584",
        "48872685",
        "2073229454",
        "144365875",
        "35084211",
      ],
      conference_year: 2023,
      conference_name: "iclr",
      conf_id: "iclr2023",
      review_scores: [6.0, 5.0, 6.0],
      review_score_avg: 5.6666666667,
      review_confidences: [6.0, 5.0, 6.0],
      review_confidence_avg: 4.3333333333,
    },
    {
      id: "4vGwQqviud5",
      semantic_scholar_id: "baa4f95081e9663fb045d145acc70049ace16ac9",
      raw_decision: "ICLR 2023 Rejected",
      normalized_decision: "Reject",
      title:
        "DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models",
      abstract:
        "Diffusion probabilistic models (DPMs) have achieved impressive success in high-resolution image synthesis, especially in recent large-scale text-to-image generation applications. An essential technique for improving the sample quality of DPMs is guided sampling, which usually needs a large guidance scale to obtain the best sample quality. The commonly-used fast sampler for guided sampling is DDIM, a first-order diffusion ODE solver that generally needs 100 to 250 steps for high-quality samples. Although recent works propose dedicated high-order solvers and achieve a further speedup for sampling without guidance, their effectiveness for guided sampling has not been well-tested before. In this work, we demonstrate that previous high-order fast samplers suffer from instability issues, and they even become slower than  DDIM when the guidance scale grows large. To further speed up guided sampling, we propose DPM-Solver++, a high-order solver for the guided sampling of DPMs. DPM-Solver++ solves the diffusion ODE with the data prediction model and adopts thresholding methods to keep the solution matches training data distribution. We further propose a multistep variant of DPM-Solver++ to address the instability issue by reducing the effective step size. Experiments show that DPM-Solver++ can generate high-quality samples within only 15 to 20 steps for guided sampling by pixel-space and latent-space DPMs.\n",
      keywords: [
        "diffusion probabilistic models",
        "score-based generative models",
        "fast sampling",
        "guided sampling",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/baa4f95081e9663fb045d145acc70049ace16ac9",
      citation_count: 511,
      authors: [
        "Cheng Lu",
        "Yuhao Zhou",
        "Fan Bao",
        "Jianfei Chen",
        "Chongxuan Li",
        "Jun Zhu",
      ],
      authorIds: [
        "102517285",
        "2120327644",
        "2071898125",
        "2276707",
        "2399563",
        "2155220672",
      ],
      conference_year: 2023,
      conference_name: "iclr",
      conf_id: "iclr2023",
      review_scores: [5.0, 5.0, 5.0, 6.0],
      review_score_avg: 5.25,
      review_confidences: [5.0, 5.0, 5.0, 6.0],
      review_confidence_avg: 3.75,
    },
    {
      id: "8mWlBArp1qx",
      semantic_scholar_id: "0d0dbfb1b315a43216020abaf74d289456198219",
      raw_decision: "ICLR 2023 Withdrawn",
      normalized_decision: "Withdrawn",
      title: "MaPLe: Multi-modal Prompt Learning",
      abstract:
        "Pre-trained vision-language (V-L) models such as CLIP have shown excellent generalization ability to downstream tasks. However, they are sensitive to the choice of input text prompts and require careful selection of prompt templates to perform well. Inspired by the Natural Language Processing (NLP) literature, recent CLIP adaptation approaches learn prompts as the textual inputs to fine-tune CLIP for downstream tasks. We note that using prompting to adapt representations in a single branch of CLIP (language or vision) is sub-optimal since it does not allow the flexibility to dynamically adjust both representation spaces on a downstream task. In this work, we propose Multi-modal Prompt Learning (MaPLe) for both vision and language branches to improve alignment between the vision and language representations. Our design promotes strong coupling between the vision-language prompts to ensure mutual synergy and discourages learning independent uni-modal solutions. Further, we learn separate prompts across different early stages to progressively model the stage-wise feature relationships to allow rich context learning. We evaluate the effectiveness of our approach on three representative tasks of generalization to novel classes, new target datasets and unseen domain shifts. Compared with the state-of-the-art method Co-CoOp, MaPLe exhibits favorable performance and achieves an absolute gain of 3.45% on novel classes and 2.72% on overall harmonic-mean, averaged over 11 diverse image recognition datasets. Our code and models will be publicly released.",
      keywords: [
        "Vision-language models",
        "Prompt learning",
        "Generalization",
        "Fine-tuning",
        "Transfer learning",
      ],
      accepted: false,
      publication_venue: "Computer Vision and Pattern Recognition",
      publication_venue_id: "768b87bb-8a18-4d9c-a161-4d483c776bcf",
      url: "https://www.semanticscholar.org/paper/0d0dbfb1b315a43216020abaf74d289456198219",
      citation_count: 490,
      authors: [
        "Muhammad Uzair Khattak",
        "H. Rasheed",
        "Muhammad Maaz",
        "Salman H. Khan",
        "F. Khan",
      ],
      authorIds: [
        "2175250687",
        "2097712964",
        "32437679",
        "2111181927",
        "2358803",
      ],
      conference_year: 2023,
      conference_name: "iclr",
      conf_id: "iclr2023",
      review_scores: [3.0, 8.0, 6.0, 5.0],
      review_score_avg: 5.5,
      review_confidences: [3.0, 8.0, 6.0, 5.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "nId8ZtIXub",
      semantic_scholar_id: "643914ae0ad9dcc5868348e4d867374aedbf9531",
      raw_decision: "ICLR 2023 Withdrawn",
      normalized_decision: "Withdrawn",
      title:
        "Observation-Centric SORT: Rethinking SORT for Robust Multi-Object Tracking",
      abstract:
        "Recent advances in object detection and re-identification have greatly improved the performance of Multi-Object Tracking (MOT) methods, but progress in motion modeling has been limited. The motion model is a key component of many MOT methods and is commonly used to predict an object's future position. However, mainstream motion models in MOT naively assume that object motion is linear. They rely on detections on each frame as the observation value to supervise motion models. However, in practice, the observations can be noisy and even missing, especially in crowded scenes, which greatly degrade the performance of existing MOT methods. In this work, we show that a simple filtering-based motion model can still obtain state-of-the-art tracking performance if proper care is given to missing observations and noisy estimates. We emphasize the role of observations when recovering tracks from being lost and reducing the error accumulated by the assumption of linear motion when the target is lost. In contrast to the popular motion-based method SORT, which is estimation-centric, we name our method Observation-Centric SORT (OC-SORT). It remains simple, online, and real-time but improves robustness over occlusion and non-linear motion. It achieves state-of-the-art on multiple MOT benchmarks, including MOT17, MOT20, KITTI, head tracking, and especially DanceTrack where the object motion is highly non-linear.",
      keywords: ["multi-object tracking"],
      accepted: false,
      publication_venue: "Computer Vision and Pattern Recognition",
      publication_venue_id: "768b87bb-8a18-4d9c-a161-4d483c776bcf",
      url: "https://www.semanticscholar.org/paper/643914ae0ad9dcc5868348e4d867374aedbf9531",
      citation_count: 423,
      authors: [
        "Jinkun Cao",
        "Xinshuo Weng",
        "Rawal Khirodkar",
        "Jiangmiao Pang",
        "Kris Kitani",
      ],
      authorIds: [
        "23590685",
        "2142561313",
        "51927417",
        "49968574",
        "144040368",
      ],
      conference_year: 2023,
      conference_name: "iclr",
      conf_id: "iclr2023",
      review_scores: [5.0, 6.0, 5.0],
      review_score_avg: 5.3333333333,
      review_confidences: [5.0, 6.0, 5.0],
      review_confidence_avg: 4.6666666667,
    },
    {
      id: "FELWgMjxZJj",
      semantic_scholar_id: "29c2d3d77b6d6f24f4356d5ba20c1a6ab4229c76",
      raw_decision: "ICLR 2023 Withdrawn",
      normalized_decision: "Withdrawn",
      title: "Open-Vocabulary Semantic Segmentation with Mask-adapted CLIP",
      abstract:
        'Open-vocabulary semantic segmentation aims to segment an image into semantic regions according to text descriptions, which may not have been seen during training. Recent two-stage methods first generate class-agnostic mask proposals and then leverage pre-trained vision-language models, e.g., CLIP, to classify masked regions. We identify the performance bottleneck of this paradigm to be the pre-trained CLIP model, since it does not perform well on masked images. To address this, we propose to finetune CLIP on a collection of masked image regions and their corresponding text descriptions. We collect training data by mining an existing image-caption dataset (e.g., COCO Captions), using CLIP to match masked image regions to nouns in the image captions. Compared with the more precise and manually annotated segmentation labels with fixed classes (e.g., COCO-Stuff), we find our noisy but diverse dataset can better retain CLIP\'s generalization ability. Along with finetuning the entire model, we utilize the "blank" areas in masked images using a method we dub mask prompt tuning. Experiments demonstrate mask prompt tuning brings significant improvement without modifying any weights of CLIP, and it can further improve a fully finetuned model. In particular, when trained on COCO and evaluated on ADE20K-150, our best model achieves 29.6% mIoU, which is +8.5% higher than the previous state-of-the-art. For the first time, open-vocabulary generalist models match the performance of supervised specialist models in 2017 without dataset-specific adaptations.',
      keywords: [
        "vision-language models",
        "open-vocabulary",
        "image segmentation",
      ],
      accepted: false,
      publication_venue: "Computer Vision and Pattern Recognition",
      publication_venue_id: "768b87bb-8a18-4d9c-a161-4d483c776bcf",
      url: "https://www.semanticscholar.org/paper/29c2d3d77b6d6f24f4356d5ba20c1a6ab4229c76",
      citation_count: 405,
      authors: [
        "Feng Liang",
        "Bichen Wu",
        "Xiaoliang Dai",
        "Kunpeng Li",
        "Yinan Zhao",
        "Hang Zhang",
        "Peizhao Zhang",
        "P\u00e9ter Vajda",
        "D. Marculescu",
      ],
      authorIds: [
        "2053834046",
        "3130257",
        "4527324",
        "49243413",
        "31812669",
        "2119077209",
        "2918780",
        "48682997",
        "92419662",
      ],
      conference_year: 2023,
      conference_name: "iclr",
      conf_id: "iclr2023",
      review_scores: [5.0, 8.0, 5.0, 5.0],
      review_score_avg: 5.75,
      review_confidences: [5.0, 8.0, 5.0, 5.0],
      review_confidence_avg: 4.25,
    },
    {
      id: "Gb2Rndy5595",
      semantic_scholar_id: "3387e9dedb7accc3c248d194b012cab0ab5ab0b8",
      raw_decision: "ICLR 2023 Rejected",
      normalized_decision: "Reject",
      title: "Context Autoencoder for Self-Supervised Representation Learning",
      abstract:
        "We present a novel masked image modeling (MIM) approach, context autoencoder (CAE), for self-supervised representation pretraining. The goal is to pretrain an encoder by solving the pretext task: estimate the masked patches from the visible patches in an image. Our approach first feeds the visible patches into the encoder, extracting the representations. Then, we make predictions from visible patches to masked patches in the encoded representation space. We introduce an alignment constraint, encouraging that the representations for masked patches, predicted from the encoded representations of visible patches, are aligned with the masked patch presentations computed from the encoder. In other words, the predicted representations are expected to lie in the encoded representation space, which empirically shows the benefit to representation learning. Last, the predicted masked patch representations are mapped to the targets of the pretext task through a decoder.\nOne additional characteristic is that our approach encourages the separation of the representation learning part (encoder), and the pretext task completion part that will be replaced by the downstream task part. In contrast, previous MIM methods (e.g., BEiT and MAE) couple the two parts, potentially limiting the representation learning quality. We demonstrate the effectiveness of our CAE through superior transfer performance in downstream tasks: semantic segmentation, and object detection and instance segmentation.",
      keywords: [
        "Self-Supervised Representation Learning",
        "Masked Image Modeling",
        "Context Autoencoder",
      ],
      accepted: false,
      publication_venue: "International Journal of Computer Vision",
      publication_venue_id: "939ee07c-6009-43f8-b884-69238b40659e",
      url: "https://www.semanticscholar.org/paper/3387e9dedb7accc3c248d194b012cab0ab5ab0b8",
      citation_count: 361,
      authors: [
        "Xiaokang Chen",
        "Mingyu Ding",
        "Xiaodi Wang",
        "Ying Xin",
        "Shentong Mo",
        "Yunhao Wang",
        "Shumin Han",
        "Ping Luo",
        "Gang Zeng",
        "Jingdong Wang",
      ],
      authorIds: [
        "2108954145",
        "2055624181",
        "2108430056",
        "153432926",
        "2066123456",
        "2108703264",
        "1488666685",
        "47571885",
        "1471609826",
        "2109534192",
      ],
      conference_year: 2023,
      conference_name: "iclr",
      conf_id: "iclr2023",
      review_scores: [6.0, 6.0, 5.0, 6.0],
      review_score_avg: 5.75,
      review_confidences: [6.0, 6.0, 5.0, 6.0],
      review_confidence_avg: 4.25,
    },
    {
      id: "hzjQWjPC04A",
      semantic_scholar_id: "25425e299101b13ec2872417a14f961f4f8aa18e",
      raw_decision: "ICLR 2023 Rejected",
      normalized_decision: "Reject",
      title: "VIMA: General Robot Manipulation with Multimodal Prompts",
      abstract:
        "Prompt-based learning has emerged as a successful paradigm in natural language processing, where a single general-purpose language model can be instructed to perform any task specified by input prompts. Yet task specification in robotics comes in various forms, such as imitating one-shot demonstrations, following language instructions, and reaching visual goals. They are often considered different tasks and tackled by specialized models. This work shows that we can express a wide spectrum of robot manipulation tasks with *multimodal prompts*, interleaving textual and visual tokens. We design a transformer-based generalist robot agent, VIMA, that processes these prompts and outputs motor actions autoregressively. To train and evaluate VIMA, we develop a new simulation benchmark with thousands of procedurally-generated tabletop tasks with multimodal prompts, 600K+ expert trajectories for imitation learning, and four levels of evaluation protocol for systematic generalization. VIMA achieves strong scalability in both model capacity and data size. It outperforms prior SOTA methods in the hardest zero-shot generalization setting by up to 2.9x task success rate given the same training data. With 10x less training data, VIMA still performs 2.7x better than the top competing approach. Video demos are available at https://iclr3081.github.io/.",
      keywords: [
        "Robot Learning",
        "Foundation Model",
        "Transformer",
        "Language Model",
        "Multi-Task Learning",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/25425e299101b13ec2872417a14f961f4f8aa18e",
      citation_count: 316,
      authors: [
        "Yunfan Jiang",
        "Agrim Gupta",
        "Zichen Zhang",
        "Guanzhi Wang",
        "Yongqiang Dou",
        "Yanjun Chen",
        "Li Fei-Fei",
        "Anima Anandkumar",
        "Yuke Zhu",
        "Linxi (Jim) Fan",
      ],
      authorIds: [
        "2171112793",
        "2315452357",
        "5630943",
        "96374437",
        "1768148923",
        "2187067176",
        "48004138",
        "47627049",
        "2117748",
        "3275727",
      ],
      conference_year: 2023,
      conference_name: "iclr",
      conf_id: "iclr2023",
      review_scores: [8.0, 5.0, 6.0, 3.0],
      review_score_avg: 5.5,
      review_confidences: [8.0, 5.0, 6.0, 3.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "VB75Pi89p7",
      semantic_scholar_id: "599be9043ef3571f65758cf36e184c9dc1781baf",
      raw_decision: "ICLR 2023 Rejected",
      normalized_decision: "Reject",
      title:
        "BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers",
      abstract:
        "Masked image modeling (MIM) has demonstrated impressive results in self-supervised representation learning by recovering corrupted image patches. However, most existing studies operate on low-level image pixels, which hinders the exploitation of high-level semantics for representation models. In this work, we propose to use a semantic-rich visual tokenizer as the reconstruction target for masked prediction, providing a systematic way to promote MIM from pixel-level to semantic-level. Specifically, we propose vector-quantized knowledge distillation to train the tokenizer, which discretizes a continuous semantic space to compact codes. We then pretrain vision Transformers by predicting the original visual tokens for the masked image patches. Furthermore, we introduce a patch aggregation strategy which associates discrete image patches to enhance global semantic representation. Experiments on image classification and semantic segmentation show that BEiT v2 outperforms all compared MIM methods. On ImageNet-1K (224 size), the base-size BEiT v2 achieves $85.5\\%$ top-1 accuracy for fine-tuning and $80.1\\%$ top-1 accuracy for linear probing. The large-size BEiT v2 obtains $87.3\\%$ top-1 accuracy for ImageNet-1K (224 size) fine-tuning, and $56.7\\%$ mIoU on ADE20K for semantic segmentation. The code can be found in the supplementary materials.",
      keywords: [],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/599be9043ef3571f65758cf36e184c9dc1781baf",
      citation_count: 287,
      authors: [
        "Zhiliang Peng",
        "Li Dong",
        "Hangbo Bao",
        "Qixiang Ye",
        "Furu Wei",
      ],
      authorIds: ["2087004998", "145307652", "10699417", "1694936", "49807919"],
      conference_year: 2023,
      conference_name: "iclr",
      conf_id: "iclr2023",
      review_scores: [5.0, 6.0, 5.0, 6.0],
      review_score_avg: 5.5,
      review_confidences: [5.0, 6.0, 5.0, 6.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "lmumJ2pC0JB",
      semantic_scholar_id: "134c165953e23a6dc7d4f0d86989e92362ca4335",
      raw_decision: "ICLR 2023 Rejected",
      normalized_decision: "Reject",
      title:
        "A Convergence Analysis of Gradient Descent for Deep Linear Neural Networks",
      abstract:
        "This paper provides sharp rates of convergence of the gradient descent (GD) method for deep linear neural networks with different random initialization. This study touches upon one major open theoretical problem in machine learning: why deep neural networks trained with GD methods are efficient in many practical applications. While the solution of this problem is still beyond reach for general nonlinear deep neural networks, there have been extensive efforts in the literature in studying relevant questions for deep linear neural networks and there are many interesting results in this research direction. For example, recent results on the loss landscape show that even though the loss function of deep linear neural networks is non-convex, every local minimizer is also a global minimizer. When the GD method is applied to train the deep linear networks, it has been shown in the literature that the convergence behavior of the GD method depends on the initialization. In this paper, we obtain the sharp rate of convergence of GD for deep linear networks, and we show that this rate does not depend on the types of random initialization. Furthermore, we show that the depth of the network does not affect the optimal rate of convergence, provided that the width of each hidden layer is appropriately large. ",
      keywords: [
        "deep linear neural networks",
        "non-convex optimization",
        "gradient descent",
        "initialization",
      ],
      accepted: false,
      publication_venue: "International Conference on Learning Representations",
      publication_venue_id: "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
      url: "https://www.semanticscholar.org/paper/134c165953e23a6dc7d4f0d86989e92362ca4335",
      citation_count: 276,
      authors: ["Sanjeev Arora", "Nadav Cohen", "Noah Golowich", "Wei Hu"],
      authorIds: ["145563465", "32289606", "3348246", "1471043558"],
      conference_year: 2023,
      conference_name: "iclr",
      conf_id: "iclr2023",
      review_scores: [5.0, 8.0, 5.0, 6.0],
      review_score_avg: 6.0,
      review_confidences: [5.0, 8.0, 5.0, 6.0],
      review_confidence_avg: 3.25,
    },
  ],
  iclr2024: [
    {
      id: "AL1fq05o7H",
      semantic_scholar_id: "7bbc7595196a0606a07506c4fb1473e5e87f6082",
      raw_decision: "ICLR 2024 Rejected",
      normalized_decision: "Reject",
      title: "Mamba: Linear-Time Sequence Modeling with Selective State Spaces",
      abstract:
        "Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on the Transformer architecture and its core attention module. Many subquadratic-time architectures such as linear attention, gated convolution and recurrent models, and structured state space models (SSMs) have been developed to address Transformers' computational inefficiency on long sequences, but they have not performed as well as attention on important modalities such as language.  We identify that a key weakness of such models is their inability to perform content-based reasoning, and make several improvements. First, simply letting the SSM parameters be functions of the input addresses their weakness with discrete modalities, allowing the model to *selectively* propagate or forget information along the sequence length dimension depending on the current token. Second, even though this change prevents the use of efficient convolutions, we design a hardware-aware parallel algorithm in recurrent mode. We integrate these selective SSMs into a simplified end-to-end neural network architecture without attention or even MLP blocks (**Mamba**). Mamba enjoys fast inference (5$\\times$ higher throughput than Transformers) and linear scaling in sequence length, and its performance improves on real data up to million-length sequences. As a general sequence model backbone, Mamba achieves state-of-the-art performance across several modalities such as language, audio, and genomics. On language modeling, our Mamba-1.4B model outperforms Transformers of the same size and matches Transformers twice its size, both in pretraining and downstream evaluation.",
      keywords: [
        "Sequence model",
        "language model",
        "state space model",
        "RNN",
        "SSM",
        "S4",
        "Mamba",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/7bbc7595196a0606a07506c4fb1473e5e87f6082",
      citation_count: 2058,
      authors: ["Albert Gu", "Tri Dao"],
      authorIds: ["2269161650", "2269146652"],
      conference_year: 2024,
      conference_name: "iclr",
      conf_id: "iclr2024",
      review_scores: [3.0, 6.0, 8.0, 8.0],
      review_score_avg: 6.25,
      review_confidences: [3.0, 6.0, 8.0, 8.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "DS5qRs0tQz",
      semantic_scholar_id: "c3e5a20b844c042d2174263d2fd5b30d8cc8f0b0",
      raw_decision: "ICLR 2024 Rejected",
      normalized_decision: "Reject",
      title:
        "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection",
      abstract:
        "In this paper, we develop an open-set object detector, called Grounding DINO, by marrying Transformer-based detector DINO with grounded pre-training, which can detect arbitrary objects with human inputs such as category names or referring expressions. \nThe key solution of open-set object detection is introducing language to a closed-set detector for open-set concept generalization. \nTo effectively fuse language and vision modalities, we conceptually divide a closed-set detector into three phases and propose a tight fusion solution, which includes a feature enhancer, a language-guided query selection, and a cross-modality decoder for cross-modality fusion. \nWhile previous works mainly evaluate open-set object detection on novel categories, we propose to also perform evaluations on referring expression comprehension for objects specified with attributes. \nGrounding DINO performs remarkably well on all three settings, including benchmarks on COCO, LVIS, ODinW, and RefCOCO/+/g. \nGrounding DINO achieves a $52.5$ AP on the COCO detection zero-shot transfer benchmark, i.e.,  without any training data from COCO. It sets a new record on the ODinW zero-shot benchmark with a mean $26.1$ AP.",
      keywords: ["Object Detection", "Visual Grounding", "Open Vocabulary"],
      accepted: false,
      publication_venue: "European Conference on Computer Vision",
      publication_venue_id: "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
      url: "https://www.semanticscholar.org/paper/c3e5a20b844c042d2174263d2fd5b30d8cc8f0b0",
      citation_count: 1629,
      authors: [
        "Shilong Liu",
        "Zhaoyang Zeng",
        "Tianhe Ren",
        "Feng Li",
        "Hao Zhang",
        "Jie Yang",
        "Chun-yue Li",
        "Jianwei Yang",
        "Hang Su",
        "Jun-Juan Zhu",
        "Lei Zhang",
      ],
      authorIds: [
        "8602739",
        "2075413603",
        "2143150727",
        "2152978390",
        "2315254849",
        "2146105297",
        "2109738542",
        "120157163",
        "2093561216",
        "89006344",
        "2152832911",
      ],
      conference_year: 2024,
      conference_name: "iclr",
      conf_id: "iclr2024",
      review_scores: [5.0, 8.0, 5.0],
      review_score_avg: 6.0,
      review_confidences: [5.0, 8.0, 5.0],
      review_confidence_avg: 3.6666666667,
    },
    {
      id: "7c3ZOKGQ6s",
      semantic_scholar_id: "ee19e8936275c8efe30c91a3c64e5ad8f3b15dc3",
      raw_decision: "ICLR 2024 Withdrawn",
      normalized_decision: "Withdrawn",
      title:
        "YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications",
      abstract:
        "We inaugurate YOLOv6, shipped with hardware-friendly architectural designs and a composite of novel training schemes tailored for industrial scenarios, which marks a new state-of-the-art real-time object detector as of early 2023. For a glimpse of performance, our YOLOv6-N hits 37.5% AP on the COCO dataset at a throughput of 1187 FPS tested with an NVIDIA Tesla T4 GPU. YOLOv6-S strikes 45.0% AP at 484 FPS, outperforming other mainstream detectors at the same scale (YOLOv5-S, YOLOv8-S, YOLOX-S, and PPYOLOE-S). Meantime, YOLOv6-M and L achieve better accuracy performance (50.0%/52.8% respectively) than other detectors at a similar inference speed. Additionally, with an extended backbone and neck design, our YOLOv6-L6 achieves state-of-the-art accuracy in real-time object detection. We carefully conducted extensive experiments to validate the effectiveness of each proposed component.",
      keywords: ["object detection", "single-stage"],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/ee19e8936275c8efe30c91a3c64e5ad8f3b15dc3",
      citation_count: 1460,
      authors: [
        "Chuyin Li",
        "Lu Li",
        "Hongliang Jiang",
        "Kaiheng Weng",
        "Yifei Geng",
        "L. Li",
        "Zaidan Ke",
        "Qingyuan Li",
        "Meng Cheng",
        "Weiqiang Nie",
        "Yiduo Li",
        "Bo Zhang",
        "Yufei Liang",
        "Linyuan Zhou",
        "Xiaoming Xu",
        "Xiangxiang Chu",
        "Xiaoming Wei",
        "Xiaolin Wei",
      ],
      authorIds: [
        "1391213352",
        "2145611981",
        "2158160569",
        "3355664",
        "97883934",
        "37498905",
        "2184248093",
        "30750669",
        "2184247957",
        "2184247869",
        "2184461062",
        null,
        "2157578071",
        "2184279774",
        "2184278681",
        "27628828",
        "50652918",
        "49141839",
      ],
      conference_year: 2024,
      conference_name: "iclr",
      conf_id: "iclr2024",
      review_scores: [3.0, 3.0, 3.0],
      review_score_avg: 3.0,
      review_confidences: [3.0, 3.0, 3.0],
      review_confidence_avg: 4.6666666667,
    },
    {
      id: "wFPfYccHJ1",
      semantic_scholar_id: "35b966347dae2f0d496ea713edf03a68211838a5",
      raw_decision: "ICLR 2024 Rejected",
      normalized_decision: "Reject",
      title: "Energy-based Out-of-distribution Detection",
      abstract:
        'As deep neural networks become adopted in high-stakes domains, it is crucial to be able to identify when inference inputs are Out-of-Distribution (OOD) so that users can be alerted of likely drops in performance and calibration despite high confidence. Among many others, existing methods use the following two scores to do so without training on any apriori OOD examples: a learned temperature and an energy score . In this paper we introduce Ablated Learned Temperature Energy (or "AbeT" for short), a method which combines these prior methods in novel ways with an effective ablation. Due to these contributions, AbeT lowers the False Positive Rate at 95\\% True Positive Rate (FPR@95) by $47.32\\%$ in classification (averaged across all ID and OOD datasets measured) compared to state of the art without training networks in multiple stages or requiring hyperparameters or test-time backward passes. We additionally provide empirical insights as to why our model learns to distinguish between In-Distribution (ID) and OOD samples while only being explicitly trained on ID samples via exposure to misclassified ID examples at training time. Lastly, we show the efficacy of our method in identifying predicted bounding boxes and pixels corresponding to OOD objects in object detection and semantic segmentation, respectively - with an AUROC increase of $5.15\\%$ in object detection and both a decrease in FPR@95 of $41.48\\%$ and an increase in AUPRC of $34.20\\%$ on average in semantic segmentation compared to previous state of the art.\n\nWe make our code publicly available at https://github.com/anonymousoodauthor/abet, with our method requiring only a single line change to the architectures of classifiers, object detectors, and segmentation models prior to training.',
      keywords: [
        "Out-of-Distribution",
        "Out-of-Distribution Detection",
        "OOD",
        "OOD Detection",
        "Distribution Shift",
      ],
      accepted: false,
      publication_venue: "Neural Information Processing Systems",
      publication_venue_id: "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
      url: "https://www.semanticscholar.org/paper/35b966347dae2f0d496ea713edf03a68211838a5",
      citation_count: 1222,
      authors: [
        "Weitang Liu",
        "Xiaoyun Wang",
        "John Douglas Owens",
        "Yixuan Li",
      ],
      authorIds: ["46641825", "2118776393", "1758404", "1527103472"],
      conference_year: 2024,
      conference_name: "iclr",
      conf_id: "iclr2024",
      review_scores: [3.0, 5.0, 5.0, 5.0],
      review_score_avg: 4.5,
      review_confidences: [3.0, 5.0, 5.0, 5.0],
      review_confidence_avg: 3.5,
    },
    {
      id: "BfMQIJ0nLc",
      semantic_scholar_id: "b37b1dc72b1882858f5120f2cd6883134089a6ed",
      raw_decision: "ICLR 2024 Rejected",
      normalized_decision: "Reject",
      title: "MMBench: Is Your Multi-modal Model an All-around Player?",
      abstract:
        "Large vision-language models have recently achieved remarkable progress, \nexhibiting great perception and reasoning abilities concerning visual information. \nHowever, how to effectively evaluate these large vision-language models remains a major obstacle, hindering future development in this domain. \nTraditional benchmarks like VQAv2 or COCO Caption provide quantitative performance measurements but suffer from a lack of fine-grained ability assessment and non-robust evaluation metrics. \nRecent subjective benchmarks, such as OwlEval, offer comprehensive evaluations of a model's abilities by incorporating human labor, but they are not scalable and display significant bias.\nIn response to these challenges, we propose MMBench, a new benchmark for assessing multi-modal capabilities of VLMs. \nMMBench methodically develops a comprehensive evaluation pipeline, primarily comprised of two key features: 1. MMBench is a meticulously curated dataset that surpasses existing similar benchmarks in terms of the number and the variety of evaluation questions and abilities; 2. MMBench introduces a rigorous CircularEval strategy and incorporates the use of ChatGPT to convert free-form predictions into pre-defined choices, thereby facilitating a fair and robust evaluation despite of VLMs' different instruction following capabilities. \nMMBench is a systematically-designed objective benchmark for robustly evaluating the various abilities of vision-language models. \nWe hope MMBench will assist the research community in better evaluating their models and encourage future advancements in this domain.",
      keywords: [
        "Vision-language Pre-training",
        "Multimodality",
        "Benchmark",
        "Dataset",
      ],
      accepted: false,
      publication_venue: "European Conference on Computer Vision",
      publication_venue_id: "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
      url: "https://www.semanticscholar.org/paper/b37b1dc72b1882858f5120f2cd6883134089a6ed",
      citation_count: 826,
      authors: [
        "Yuanzhan Liu",
        "Haodong Duan",
        "Yuanhan Zhang",
        "Bo Li",
        "Songyang Zhang",
        "Wangbo Zhao",
        "Yike Yuan",
        "Jiaqi Wang",
        "Conghui He",
        "Ziwei Liu",
        "Kai Chen",
        "Dahua Lin",
      ],
      authorIds: [
        "1604959737",
        "31463937",
        "2145784327",
        "2165247100",
        "1734973476",
        "2109435100",
        "2112499811",
        null,
        "3486481",
        "2145252993",
        "152568027",
        "1807606",
      ],
      conference_year: 2024,
      conference_name: "iclr",
      conf_id: "iclr2024",
      review_scores: [6.0, 6.0, 3.0, 6.0],
      review_score_avg: 5.25,
      review_confidences: [6.0, 6.0, 3.0, 6.0],
      review_confidence_avg: 3.5,
    },
    {
      id: "qrGjFJVl3m",
      semantic_scholar_id: "fc6a2f7478f68adefd69e2071f27e38aa1647f2f",
      raw_decision: "ICLR 2024 Rejected",
      normalized_decision: "Reject",
      title:
        "Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond",
      abstract:
        "In this work, we introduce the Qwen-VL series, a set of large-scale vision-language models (LVLMs) designed to perceive and understand both texts and images.\nStarting from the Qwen-LM as a foundation, we endow it with visual capacity by the meticulously designed (i) visual receptor, (ii) input-output interface, (iii) 3-stage training pipeline, and (iv) multilingual multimodal cleaned corpus.\nBeyond the conventional image description and question-answering, we implement the grounding and text-reading ability of Qwen-VLs by aligning image-caption-box tuples.\nThe resulting models, including Qwen-VL and Qwen-VL-Chat, set new records for generalist models under similar model scales on a broad range of visual-centric benchmarks (e.g., image captioning, question answering, visual grounding) and different settings (e.g., zero-shot, few-shot).\nMoreover, on real-world dialog benchmarks, our instruction-tuned Qwen-VL-Chat also demonstrates superiority compared to existing vision-language chatbots.\nAll models will be made public to facilitate future research.",
      keywords: [
        "multi-modal learning",
        "vision-language models",
        "generalist models",
      ],
      accepted: false,
      publication_venue: null,
      publication_venue_id: null,
      url: "https://www.semanticscholar.org/paper/fc6a2f7478f68adefd69e2071f27e38aa1647f2f",
      citation_count: 704,
      authors: [
        "Jinze Bai",
        "Shuai Bai",
        "Shusheng Yang",
        "Shijie Wang",
        "Sinan Tan",
        "Peng Wang",
        "Junyang Lin",
        "Chang Zhou",
        "Jingren Zhou",
      ],
      authorIds: [
        "41211611",
        "3768186",
        null,
        "2217429986",
        "2110171536",
        "2155302144",
        "35996608",
        "2192678144",
        "1709595",
      ],
      conference_year: 2024,
      conference_name: "iclr",
      conf_id: "iclr2024",
      review_scores: [3.0, 8.0, 5.0],
      review_score_avg: 5.3333333333,
      review_confidences: [3.0, 8.0, 5.0],
      review_confidence_avg: 3.6666666667,
    },
    {
      id: "QAwaaLJNCk",
      semantic_scholar_id: "4780d0a027c5c5a8e01d7cf697f6296880ffc945",
      raw_decision: "ICLR 2024 Rejected",
      normalized_decision: "Reject",
      title:
        "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
      abstract:
        'Large language models (LLMs) have demonstrated remarkable capabilities in language generation, understanding, and few-shot learning in recent years. An extensive body of work has explored how their performance may be further improved through the tools of prompting, ranging from verification, self-consistency, or intermediate scratchpads. In this paper, we present a complementary approach to improve language responses where multiple language model instances propose and debate their individual responses and reasoning processes over multiple rounds to arrive at a common final answer. Our findings indicate that this approach significantly enhances mathematical and strategic reasoning across a number of tasks. We also demonstrate that our approach improves the factual validity of generated content, reducing fallacious answers and hallucinations that contemporary models are prone to. Our approach may be directly applied to existing black-box models and uses identical procedure and prompts for all tasks we investigate. Overall, our findings suggest that such "society of minds" approach has the potential to significantly advance the capabilities of LLMs and pave the way for further breakthroughs in language generation and understanding.',
      keywords: [
        "Large Language Models",
        "Factuality",
        "Reasoning",
        "Multiagent Reasoning",
      ],
      accepted: false,
      publication_venue: "International Conference on Machine Learning",
      publication_venue_id: "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
      url: "https://www.semanticscholar.org/paper/4780d0a027c5c5a8e01d7cf697f6296880ffc945",
      citation_count: 542,
      authors: [
        "Yilun Du",
        "Shuang Li",
        "A. Torralba",
        "J. Tenenbaum",
        "Igor Mordatch",
      ],
      authorIds: [
        "15394275",
        "145015904",
        "143805211",
        "1763295",
        "2316241372",
      ],
      conference_year: 2024,
      conference_name: "iclr",
      conf_id: "iclr2024",
      review_scores: [8.0, 6.0, 5.0, 5.0],
      review_score_avg: 6.0,
      review_confidences: [8.0, 6.0, 5.0, 5.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "hkjcdmz8Ro",
      semantic_scholar_id: "4637f79ddfaf923ce569996ffa5b6cda1996faa1",
      raw_decision: "ICLR 2024 Rejected",
      normalized_decision: "Reject",
      title: "Jailbreaking Black Box Large Language Models in Twenty Queries",
      abstract:
        "There is growing research interest in ensuring that large language models align with human safety and ethical guidelines. Adversarial attacks known as 'jailbreaks' pose a significant threat as they coax models into overriding alignment safeguards. Identifying these vulnerabilities through attacking a language model (red teaming) is instrumental in understanding inherent weaknesses and preventing misuse. We present Prompt Automatic Iterative Refinement (PAIR), which generates semantic jailbreaks with only black-box access \nto a language model.\nEmpirically, PAIR often requires fewer than 20 queries, orders of magnitude fewer than prior jailbreak attacks. PAIR draws inspiration from the human process of social engineering, and employs an attacker language model to automatically generate adversarial prompts in place of a human. The attacker model uses the target model's response as additional context to iteratively refine the adversarial prompt. PAIR achieves competitive jailbreaking success rates and transferability on open and closed-source language models, including GPT-3.5/4, Vicuna, and PaLM.",
      keywords: ["large language models", "LLM", "jailbreaking", "red teaming"],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/4637f79ddfaf923ce569996ffa5b6cda1996faa1",
      citation_count: 516,
      authors: [
        "Patrick Chao",
        "Alexander Robey",
        "Edgar Dobriban",
        "Hamed Hassani",
        "George J. Pappas",
        "Eric Wong",
      ],
      authorIds: [
        "50981858",
        "66684655",
        "2694895",
        "2254218321",
        "2254286806",
        "2254236073",
      ],
      conference_year: 2024,
      conference_name: "iclr",
      conf_id: "iclr2024",
      review_scores: [5.0, 5.0, 6.0, 3.0],
      review_score_avg: 4.75,
      review_confidences: [5.0, 5.0, 6.0, 3.0],
      review_confidence_avg: 3.75,
    },
    {
      id: "c72vop46KY",
      semantic_scholar_id: "2313afae52d98e569da2dedbf14daf9efc74e7cf",
      raw_decision: "ICLR 2024 Rejected",
      normalized_decision: "Reject",
      title: "CogVLM: Visual Expert for Pretrained Language Models",
      abstract:
        "We introduce CogVLM, a powerful open-source visual language foundation model.\nDifferent from the popular *shallow-align* method which maps image features into the input space of language model, CogVLM bridges the gap between the frozen pretrained language model and image encoder by a trainable visual expert module in the attention and FFN layers. As a result, CogVLM enables deep fusion of visual language features without sacrificing any performance on NLP tasks. \nCogVLM-17B achieves state-of-the-art performance on 9 classic cross-modal benchmarks, including NoCaps, Flicker30k captioning, RefCOCO, RefCOCO+, RefCOCOg, Visual7W, GQA, ScienceQA, VizWiz VQA and TDIUC, and rank the 2nd on VQAv2, OKVQA, TextVQA, COCO captioning, etc., surpassing or matching PaLI-X 55B. Codes and checkpoints are available at Github.",
      keywords: [
        "vision-language model",
        "cross-modality",
        "pretrained language model",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/2313afae52d98e569da2dedbf14daf9efc74e7cf",
      citation_count: 444,
      authors: [
        "Weihan Wang",
        "Qingsong Lv",
        "Wenmeng Yu",
        "Wenyi Hong",
        "Ji Qi",
        "Yan Wang",
        "Junhui Ji",
        "Zhuoyi Yang",
        "Lei Zhao",
        "Xixuan Song",
        "Jiazheng Xu",
        "Bin Xu",
        "Juanzi Li",
        "Yuxiao Dong",
        "Ming Ding",
        "Jie Tang",
      ],
      authorIds: [
        "2265518149",
        "2053104889",
        "2265588447",
        "2105844599",
        "2091076497",
        "2265518311",
        "2265576430",
        "2109506541",
        "2265528226",
        "2265550676",
        "2214082934",
        "2258944802",
        "2133353675",
        "2243402027",
        "2055623340",
        "2238207092",
      ],
      conference_year: 2024,
      conference_name: "iclr",
      conf_id: "iclr2024",
      review_scores: [5.0, 6.0, 6.0, 6.0],
      review_score_avg: 5.75,
      review_confidences: [5.0, 6.0, 6.0, 6.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "nKvGCUoiuW",
      semantic_scholar_id: "1ddbd08ad8cf22a5c66c4242194c4286328533bf",
      raw_decision: "ICLR 2024 Rejected",
      normalized_decision: "Reject",
      title:
        "MiniGPT-v2: large language model as a unified interface for vision-language multi-task learning",
      abstract:
        "Large language models have shown their remarkable capabilities as a general interface for various language-related applications. Motivated by this, we target to build a unified interface for completing many vision-language tasks including image description, visual question answering, and visual grounding, among others. The challenge for achieving this is to use a single model for performing diverse vision-language tasks effectively with simple multi-modal instructions. To address this issue, we introduce MiniGPT-v2, a model can be treated a unified interface for better handling various vision-language tasks. We propose using unique identifiers for different tasks when training the model. These identifiers enable our model to distinguish each task instruction effortlessly and also improve the model learning efficiency for each task. After our three-stage training, our experiments show that MiniGPT-v2 achieves strong performance on many visual question answering and visual grounding benchmarks compared to other vision-language generalist models. Our trained models and codes will be made available.",
      keywords: ["vision-language foundation model"],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/1ddbd08ad8cf22a5c66c4242194c4286328533bf",
      citation_count: 424,
      authors: [
        "Jun Chen",
        "Deyao Zhu",
        "Xiaoqian Shen",
        "Xiang Li",
        "Zechun Liu",
        "Pengchuan Zhang",
        "Raghuraman Krishnamoorthi",
        "Vikas Chandra",
        "Yunyang Xiong",
        "Mohamed Elhoseiny",
      ],
      authorIds: [
        "2153417252",
        "1388731230",
        "2151708219",
        "2262463251",
        "2258786725",
        "2325206338",
        "2065915235",
        "144137037",
        "2259018056",
        "1712479",
      ],
      conference_year: 2024,
      conference_name: "iclr",
      conf_id: "iclr2024",
      review_scores: [8.0, 5.0, 6.0, 5.0],
      review_score_avg: 6.0,
      review_confidences: [8.0, 5.0, 6.0, 5.0],
      review_confidence_avg: 4.0,
    },
  ],
  iclr2025: [
    {
      id: "xNgmEWmd9T",
      semantic_scholar_id: "2c994fadbb84fb960d8306ee138dbeef41a5b323",
      raw_decision: "ICLR 2025 Rejected",
      normalized_decision: "Reject",
      title:
        "SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models",
      abstract:
        "Several recent studies have investigated low-precision accumulation, reporting improvements in throughput, power, and area across various platforms. However, the accompanying proposals have only considered the quantization-aware training (QAT) paradigm, in which models are fine-tuned or trained from scratch with quantization in the loop. As models continue to grow in size, QAT techniques become increasingly more expensive, which has motivated the recent surge in post-training quantization (PTQ) research. To the best of our knowledge, ours marks the first formal study of accumulator-aware quantization in the PTQ setting. To bridge this gap, we introduce AXE\u2014a practical, low-overhead framework of accumulator-aware extensions designed to endow overflow avoidance guarantees to existing layer-wise PTQ algorithms. We theoretically motivate AXE and demonstrate its flexibility by implementing it on top of two state-of-the-art PTQ algorithms: GPFQ and OPTQ. We further generalize AXE to support multi-stage accumulation for the first time, opening the door for full datapath optimization and scaling to large language models (LLMs). We evaluate AXE across autoregressive language generation models and observe significant improvements in the tradeoff between accumulator bit width and model accuracy over baseline methods.",
      keywords: ["Accumulators", "Deep Learning", "Inference", "Quantization"],
      accepted: false,
      publication_venue: "International Conference on Machine Learning",
      publication_venue_id: "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
      url: "https://www.semanticscholar.org/paper/2c994fadbb84fb960d8306ee138dbeef41a5b323",
      citation_count: 672,
      authors: [
        "Guangxuan Xiao",
        "Ji Lin",
        "Mickael Seznec",
        "Julien Demouth",
        "Song Han",
      ],
      authorIds: [
        "2046958974",
        "46698300",
        "2286429342",
        "32604218",
        "143840275",
      ],
      conference_year: 2025,
      conference_name: "iclr",
      conf_id: "iclr2025",
      review_scores: [6, 6, 5, 5],
      review_score_avg: 5.5,
      review_confidences: [6, 6, 5, 5],
      review_confidence_avg: 3.0,
    },
    {
      id: "YzXPU3QRnL",
      semantic_scholar_id: "154493f69d7db3d49da0e51df0192c6ad5f1724a",
      raw_decision: "ICLR 2025 Rejected",
      normalized_decision: "Reject",
      title: "Larger language models do in-context learning differently",
      abstract:
        "We study how in-context learning (ICL) in language models is affected by semantic priors versus input-label mappings. We investigate two setups - ICL with flipped labels and ICL with semantically-unrelated labels - across various model families (GPT-3, InstructGPT, Codex, an internal model, and an instruction-tuned variant of the internal model). First, experiments on ICL with flipped labels show that overriding semantic priors is an emergent ability of model scale. While small language models ignore flipped labels presented in-context and thus rely primarily on semantic priors from pretraining, large models can override semantic priors when presented with in-context exemplars that contradict priors, despite the stronger semantic priors that larger models may hold. We next study semantically-unrelated label ICL (SUL-ICL), in which labels are semantically unrelated to their inputs (e.g., foo/bar instead of negative/positive), thereby forcing language models to learn the input-label mappings shown in in-context exemplars in order to perform the task. The ability to do SUL-ICL also emerges primarily with scale, and large-enough language models can even perform linear classification in a SUL-ICL setting. Finally, we evaluate instruction-tuned models and find that instruction tuning strengthens both the use of semantic priors and the capacity to learn input-label mappings, but more of the former.",
      keywords: [
        "in-context learning",
        "natural language processing",
        "large language models",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/154493f69d7db3d49da0e51df0192c6ad5f1724a",
      citation_count: 328,
      authors: [
        "Jerry W. Wei",
        "Jason Wei",
        "Yi Tay",
        "Dustin Tran",
        "Albert Webson",
        "Yifeng Lu",
        "Xinyun Chen",
        "Hanxiao Liu",
        "Da Huang",
        "Denny Zhou",
        "Tengyu Ma",
      ],
      authorIds: [
        "47807379",
        "119640649",
        "144447820",
        "47497262",
        "1991019030",
        "2141538599",
        "1425082935",
        "2391802",
        "2110408964",
        "65855107",
        "2114186424",
      ],
      conference_year: 2025,
      conference_name: "iclr",
      conf_id: "iclr2025",
      review_scores: [1, 6, 6, 8, 8],
      review_score_avg: 5.8,
      review_confidences: [1, 6, 6, 8, 8],
      review_confidence_avg: 4.2,
    },
    {
      id: "ejGAytoWoe",
      semantic_scholar_id: "bc2ddba47a9d6b378abd8a8584849f3e4c410f24",
      raw_decision: "ICLR 2025 Rejected",
      normalized_decision: "Reject",
      title:
        "WorldSimBench: Towards Video Generation Models as World Simulators",
      abstract:
        "Recent advancements in predictive models have demonstrated exceptional capabilities in predicting the future state of objects and scenes. However, the lack of categorization based on inherent characteristics continues to hinder the progress of predictive model development. Additionally, existing benchmarks are unable to effectively evaluate higher-capability, highly embodied predictive models from an embodied perspective. In this work, we classify the functionalities of predictive models into a hierarchy and take the first step in evaluating World Simula\u0002tors by proposing a dual evaluation framework called WorldSimBench. World\u0002SimBench includes Explicit Perceptual Evaluation and Implicit Manipulative Evaluation, encompassing human preference assessments from the visual perspective and action-level evaluations in embodied tasks, covering three representative embodied scenarios: Open-Ended Embodied Environment, Autonomous, Driving, and Robot Manipulation. In the Explicit Perceptual Evaluation, we introduce the HF-Embodied Dataset, a video assessment dataset based on fine-grained human feedback, which we use to train a Human Preference Evaluator that aligns with human perception and explicitly assesses the visual fidelity of World Simu\u0002later. In the Implicit Manipulative Evaluation, we assess the video-action consistency of World Simulators by evaluating whether the generated situation-aware video can be accurately translated into the correct control signals in dynamic environments. Our comprehensive evaluation offers key insights that can drive further innovation in video generation models, positioning World Simulators as a pivotal advancement toward embodied artificial intelligence.",
      keywords: [
        "World Simulator",
        "Embodied AI",
        "Video Generation",
        "Benchmark",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/bc2ddba47a9d6b378abd8a8584849f3e4c410f24",
      citation_count: 328,
      authors: [
        "Yiran Qin",
        "Zhelun Shi",
        "Jiwen Yu",
        "Xijun Wang",
        "Enshen Zhou",
        "Lijun Li",
        "Zhen-fei Yin",
        "Xihui Liu",
        "Lu Sheng",
        "Jing Shao",
        "Lei Bai",
        "Wanli Ouyang",
        "Ruimao Zhang",
      ],
      authorIds: [
        "2240266091",
        "2144146362",
        "2327248453",
        "2327287661",
        "2273688063",
        "2280261471",
        "13050405",
        "2284733067",
        "2290983876",
        "2328076278",
        "2253472588",
        "2253464521",
        "2274031380",
      ],
      conference_year: 2025,
      conference_name: "iclr",
      conf_id: "iclr2025",
      review_scores: [6, 5, 8, 5],
      review_score_avg: 6.0,
      review_confidences: [6, 5, 8, 5],
      review_confidence_avg: 4.25,
    },
    {
      id: "xCFdAN5DY3",
      semantic_scholar_id: "874deb5f06f35e52ae13a921b23611eec4abd1da",
      raw_decision: "ICLR 2025 Rejected",
      normalized_decision: "Reject",
      title: "ClimaX: A foundation model for weather and climate",
      abstract:
        "Triggered by the realization that AI emulators can rival the performance of traditional numerical weather prediction models running on HPC systems, there is now an increasing number of large AI models that address use cases such as forecasting, downscaling, or nowcasting. While the parallel developments in the AI literature focus on foundation models -- models that can be effectively tuned to address multiple, different use cases -- the developments on the weather and climate side largely focus on single-use cases with particular emphasis on mid-range forecasting. We close this gap by introducing Prithvi WxC, a 2.3 billion parameter foundation model developed using 160 variables from the Modern-Era Retrospective Analysis for Research and Applications, Version 2 (MERRA-2). Prithvi WxC employs an encoder-decoder-based architecture, incorporating concepts from various recent transformer models to effectively capture both regional and global dependencies in the input data. The model has been designed to accommodate large token counts to model weather phenomena in different topologies at fine resolutions. Furthermore, it is trained with a mixed objective that combines the paradigms of masked reconstruction with forecasting. We test the model on a set of challenging downstream tasks namely: Autoregressive rollout forecasting, downscaling, gravity wave flux parameterization, and extreme events estimation.",
      keywords: [
        "Foundation models; atmospheric physics; weather; climate; fine-tuning; super-resolution",
      ],
      accepted: false,
      publication_venue: "International Conference on Machine Learning",
      publication_venue_id: "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
      url: "https://www.semanticscholar.org/paper/874deb5f06f35e52ae13a921b23611eec4abd1da",
      citation_count: 229,
      authors: [
        "Tung Nguyen",
        "Johannes Brandstetter",
        "Ashish Kapoor",
        "Jayesh K. Gupta",
        "Aditya Grover",
      ],
      authorIds: ["2175303602", "78843496", "2189118", "38303675", "1954250"],
      conference_year: 2025,
      conference_name: "iclr",
      conf_id: "iclr2025",
      review_scores: [5, 5, 3, 6],
      review_score_avg: 4.75,
      review_confidences: [5, 5, 3, 6],
      review_confidence_avg: 3.75,
    },
    {
      id: "1L9vdc7BB5",
      semantic_scholar_id: "458af0f3f03229290572a2630c75ac56e9dbec6e",
      raw_decision: "ICLR 2025 Rejected",
      normalized_decision: "Reject",
      title:
        "CPT: Colorful Prompt Tuning for Pre-trained Vision-Language Models",
      abstract:
        "Prompt tuning has emerged as an effective way for parameter-efficient fine-tuning. Conventional deep prompt tuning inserts continuous prompts of a fixed context length into the input to each layer. When a pre-trained model is tailored to a specific downstream task, different layers initialized with pre-trained weights might have, depending on the distribution shift type, different levels of deviation from the optimal weights. Inserted prompts with a fixed context length might have redundant context tokens or insufficient context length. To address this issue, we propose a deep continuous prompting method dubbed Adapt that encourages heterogeneous context lengths. Context lengths are automatically determined by iteratively pruning context tokens. We use the saliency criterion for the neural network pruning to compute the importance scores of context tokens in order to determine which tokens to prune. We examine the proposed method on the pre-trained vision-language model CLIP. Extensive experiments on 11 downstream datasets reveal the advantage of Adapt: the average test accuracy increases from 79.83% to 81.70%. The highest performance gain on individual datasets is 9.63%. At the same time, the computational overheads are comparable to or smaller than baseline methods.",
      keywords: [
        "Prompt Tuning; Multimodality; Vision-Language Models; Network Pruning",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/458af0f3f03229290572a2630c75ac56e9dbec6e",
      citation_count: 217,
      authors: [
        "Yuan Yao",
        "Ao Zhang",
        "Zhengyan Zhang",
        "Zhiyuan Liu",
        "Tat-seng Chua",
        "Maosong Sun",
      ],
      authorIds: [
        "1390925224",
        "2153656874",
        "2148904862",
        "2141313179",
        "143779329",
        "1753344",
      ],
      conference_year: 2025,
      conference_name: "iclr",
      conf_id: "iclr2025",
      review_scores: [6, 5, 5, 6],
      review_score_avg: 5.5,
      review_confidences: [6, 5, 5, 6],
      review_confidence_avg: 4.0,
    },
    {
      id: "okEwtOc5Go",
      semantic_scholar_id: "b38845e9adbeeeab37519a2fc30e899411b4a36a",
      raw_decision: "ICLR 2025 Withdrawn",
      normalized_decision: "Withdrawn",
      title:
        "Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models",
      abstract:
        "In this work, we introduce Mini-Gemini, a simple and effective framework enhancing multi-modality Vision Language Models (VLMs). Despite the advancements in VLMs facilitating basic visual dialog and reasoning, a performance gap persists compared to advanced models like GPT-4 and Gemini. We try to narrow the gap by mining the potential of VLMs for better performance across various cross-modal tasks %and any-to-any workflow from three aspects, i.e., high-resolution visual tokens, high-quality data, and VLM-guided generation. To enhance visual tokens, we propose to utilize an additional visual encoder for high-resolution refinement without increasing the visual token count. We further construct a high-quality dataset that promotes precise image comprehension and reasoning-based generation, expanding the operational scope of current VLMs. In general, Mini-Gemini further mines the potential of VLMs and empowers current frameworks with image understanding, reasoning, and generation simultaneously. Mini-Gemini supports a series of dense and MoE Large Language Models (LLMs) from 2B to 34B. It is demonstrated to achieve leading performance in several zero-shot benchmarks and even surpasses the developed private models. Code and models will be available to the public.",
      keywords: [
        "Vision Language Model",
        "Image Generation",
        "Multi-modality Model",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/b38845e9adbeeeab37519a2fc30e899411b4a36a",
      citation_count: 205,
      authors: [
        "Yanwei Li",
        "Yuechen Zhang",
        "Chengyao Wang",
        "Zhisheng Zhong",
        "Yixin Chen",
        "Ruihang Chu",
        "Shaoteng Liu",
        "Jiaya Jia",
      ],
      authorIds: [
        "2268644727",
        "2145915052",
        "2268721057",
        "2294147935",
        "2293625780",
        "1380477833",
        "2288676140",
        "2237811040",
      ],
      conference_year: 2025,
      conference_name: "iclr",
      conf_id: "iclr2025",
      review_scores: [6, 3, 6, 6],
      review_score_avg: 5.25,
      review_confidences: [6, 3, 6, 6],
      review_confidence_avg: 4.25,
    },
    {
      id: "0xUEBQV54B",
      semantic_scholar_id: "f66b6049946a10080d1f2a7ee6a40e5cca3ee6a0",
      raw_decision: "ICLR 2025 Rejected",
      normalized_decision: "Reject",
      title:
        "Large Language Monkeys: Scaling Inference Compute with Repeated Sampling",
      abstract:
        "Scaling the amount of compute used to train language models has dramatically improved their capabilities. However, when it comes to inference, we often limit the amount of compute to only one attempt per problem. Here, we explore inference compute as another axis for scaling, using the simple technique of repeatedly sampling candidate solutions from a model. Across multiple tasks and models, we observe that coverage \u2013 the fraction of problems that are solved by any generated sample \u2013 scales with the number of samples over four orders of magnitude. Interestingly, the relationship between coverage and the number of samples is often log-linear and can be modelled with an exponentiated power law, suggesting the existence of inference-time scaling laws. In domains like coding and formal proofs, where answers can be automatically verified, these increases in coverage directly translate into improved performance. When we apply repeated sampling to SWE-bench Lite, the fraction of issues solved with DeepSeek-Coder-V2-Instruct increases from 15.9% with one sample to 56% with 250 samples, outperforming the single-sample state-of-the-art of 43%. In domains without automatic verifiers, we find that common methods for picking from a sample collection (majority voting and reward models) plateau beyond several hundred samples and fail to fully scale with the sample budget.",
      keywords: ["Inference-Time Compute", "Large Language Models"],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/f66b6049946a10080d1f2a7ee6a40e5cca3ee6a0",
      citation_count: 184,
      authors: [
        "Bradley Brown",
        "Jordan Juravsky",
        "Ryan Ehrlich",
        "Ronald Clark",
        "Quoc V. Le",
        "Christopher R'e",
        "Azalia Mirhoseini",
      ],
      authorIds: [
        "2283198901",
        "50875781",
        "2283134957",
        "2313919316",
        "2151097303",
        "2313917068",
        "1861312",
      ],
      conference_year: 2025,
      conference_name: "iclr",
      conf_id: "iclr2025",
      review_scores: [6, 6, 5, 3],
      review_score_avg: 5.0,
      review_confidences: [6, 6, 5, 3],
      review_confidence_avg: 4.25,
    },
    {
      id: "Rs8fLyaOer",
      semantic_scholar_id: "9d29da83aba362c728c36f4dea9dde678ae3e2b2",
      raw_decision: "ICLR 2025 Rejected",
      normalized_decision: "Reject",
      title:
        "PLLaVA : Parameter-free LLaVA Extension from Images to Videos for Video Dense Captioning",
      abstract:
        "Vision-language pre-training has significantly elevated performance across a wide range of image-language applications. Yet, the pre-training process for video-related tasks demands exceptionally large computational and data resources, which hinders the progress of video-language models. This paper investigates a straightforward, highly efficient, and resource-light approach to adapting an existing image-language pre-trained model for dense video understanding. Our preliminary experiments reveal that directly fine-tuning pre-trained image-language models with multiple frames as inputs on video datasets leads to performance saturation or even a drop. Our further investigation reveals that it is largely attributed to the bias of learned high-norm visual features.  Motivated by this finding, we propose a simple but effective pooling strategy to smooth the feature distribution along the temporal dimension and thus reduce the dominant impacts from the extreme features. The new model is termed Pooling LLaVA, or PLLaVA in short.  PLLaVA achieves new state-of-the-art performance on modern benchmark datasets for both video question-answer and captioning tasks. Notably, on the recent popular Video ChatGPT benchmark, PLLaVA achieves a score of 3.25 out of 5 on average of five evaluated dimensions. On the latest multi-choice benchmark MVBench, PLLaVA achieves 58.1\\% accuracy on average across 20 sub-tasks, 14.5\\% higher than GPT4V (IG-VLM).",
      keywords: ["Video Understanding;Parameter-efficient;Pooling"],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/9d29da83aba362c728c36f4dea9dde678ae3e2b2",
      citation_count: 156,
      authors: [
        "Lin Xu",
        "Yilin Zhao",
        "Daquan Zhou",
        "Zhijie Lin",
        "See Kiong Ng",
        "Jiashi Feng",
      ],
      authorIds: [
        "2267005785",
        "2266749138",
        "2290239712",
        "2266462787",
        "2298950082",
        "2256994948",
      ],
      conference_year: 2025,
      conference_name: "iclr",
      conf_id: "iclr2025",
      review_scores: [5, 5, 6, 5],
      review_score_avg: 5.25,
      review_confidences: [5, 5, 6, 5],
      review_confidence_avg: 4.25,
    },
    {
      id: "cb4PoT7ePW",
      semantic_scholar_id: "ed5020eeda1fbe8c29b1282d654b34abee22d90f",
      raw_decision: "ICLR 2025 Withdrawn",
      normalized_decision: "Withdrawn",
      title:
        "DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models",
      abstract:
        "Large language models (LLMs) have made notable advancements across diverse applications,  but their susceptibility to  hallucinations remains a critical challenge. That is, they could produce outputs  divergent from real-world evidence or user-provided inputs. Recent studies have explored a contrastive decoding strategy known as DoLa, which mitigates output inaccuracy by contrasting the outputs from the final layer against those from the previous layers.  Nevertheless, such strategy has its limitation, as LLMs, which already have internalized extensive parametric knowledge through comprehensive pre-training and fine-tuning phases, may generate errors due to incorrect or obsolete information within their parameters.  As an alternative,  trusted external knowledge could be included in the prompt context for querying,  but the constrained context window of LLMs poses a significant barrier restricting the amount of information that can be provided. \nTo address the above issues,  we propose to integrate the contrasive decoding strategy with a long-context encoder that effectively condenses extensive initial contexts into a more concise format.  Extensive experiments have demonstrated that, \nour proposed methodology enhances the factual accuracy of the produced content, \nwhen applied to various datasets. For instance, it has improved the performance of LLaMA2-7B models on the Quality dataset by 61.61\\%, compared to the DoLa decoding method, showcasing its effectiveness in enhancing the reliability of LLMs in generating truthful information.",
      keywords: ["Factuality", "Contrastive Decoding", "Parametric Memory"],
      accepted: false,
      publication_venue: "International Conference on Learning Representations",
      publication_venue_id: "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
      url: "https://www.semanticscholar.org/paper/ed5020eeda1fbe8c29b1282d654b34abee22d90f",
      citation_count: 140,
      authors: [
        "Yung-Sung Chuang",
        "Yujia Xie",
        "Hongyin Luo",
        "Yoon Kim",
        "James R. Glass",
        "Pengcheng He",
      ],
      authorIds: [
        "2475831",
        "2167703904",
        "1944274",
        "143827730",
        "145898106",
        "50462546",
      ],
      conference_year: 2025,
      conference_name: "iclr",
      conf_id: "iclr2025",
      review_scores: [5, 5, 3, 5, 6],
      review_score_avg: 4.8,
      review_confidences: [5, 5, 3, 5, 6],
      review_confidence_avg: 3.6,
    },
    {
      id: "QETk0lBdVf",
      semantic_scholar_id: "d081584960c42f7793502bb496e46f682e3e43b3",
      raw_decision: "ICLR 2025 Rejected",
      normalized_decision: "Reject",
      title: "Long Context Transfer from Language to Vision",
      abstract:
        "Video sequences offer valuable temporal information, but existing large multimodal models (LMMs) fall short in understanding extremely long videos. Many works address this by reducing the number of visual tokens using visual resamplers. Alternatively, in this paper, we approach this problem from the perspective of the language model. By simply extrapolating the context length of the language backbone, we enable LMMs to comprehend orders of magnitude more visual tokens without any video training. We call this phenomenon long context transfer and carefully ablate its properties. To effectively measure LMMs' ability to generalize to long contexts in the vision modality, we develop V-NIAH (Visual Needle-In-A-Haystack), a purely synthetic long vision benchmark inspired by the language model's NIAH test. Our proposed Long Video Assistant (LongVA) can process 2000 frames or over 200K visual tokens without additional complexities. With its extended context length, LongVA achieves state-of-the-art performance on Video-MME among 7B-scale models by densely sampling more input frames.",
      keywords: ["Vision Language Model", "Long Context Model"],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/d081584960c42f7793502bb496e46f682e3e43b3",
      citation_count: 123,
      authors: [
        "Peiyuan Zhang",
        "Kaichen Zhang",
        "Bo Li",
        "Guangtao Zeng",
        "Jingkang Yang",
        "Yuanhan Zhang",
        "Ziyue Wang",
        "Haoran Tan",
        "Chunyuan Li",
        "Ziwei Liu",
      ],
      authorIds: [
        "2265621323",
        "2300086932",
        "2165247100",
        "2308040513",
        "2295601",
        "2145784327",
        "2257550096",
        "2258308833",
        "2264692022",
        "2279869111",
      ],
      conference_year: 2025,
      conference_name: "iclr",
      conf_id: "iclr2025",
      review_scores: [6, 5, 8, 5, 5],
      review_score_avg: 5.8,
      review_confidences: [6, 5, 8, 5, 5],
      review_confidence_avg: 4.2,
    },
  ],
  neurips2021: [
    {
      id: "IXexLXymbZ9",
      semantic_scholar_id: "0d0cf5f64c052aa7edc5bb638203616a620557f6",
      raw_decision: "NeurIPS 2021 Rejected",
      normalized_decision: "Reject",
      title:
        "VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning",
      abstract:
        "Recent self-supervised methods for image representation learning maximize the agreement between embedding vectors produced by encoders fed with different views of the same image. The main challenge is to prevent a collapse in which the encoders produce constant or non-informative vectors. We introduce VICReg (Variance-Invariance-Covariance Regularization), a method that explicitly avoids the collapse problem with two regularizations terms applied to both embeddings separately: (1) a term that maintains the variance of each embedding dimension above a threshold, (2) a term that decorrelates each pair of variables. Unlike most other approaches to the same problem, VICReg does not require techniques such as: weight sharing between the branches, batch normalization, feature-wise normalization, output quantization, stop gradient, memory banks, etc., and achieves results on par with the state of the art on several downstream tasks. In addition, we show that our variance regularization term stabilizes the training of other methods and leads to performance improvements.",
      keywords: ["self-supervised learning"],
      accepted: false,
      publication_venue: "International Conference on Learning Representations",
      publication_venue_id: "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
      url: "https://www.semanticscholar.org/paper/0d0cf5f64c052aa7edc5bb638203616a620557f6",
      citation_count: 869,
      authors: ["Adrien Bardes", "J. Ponce", "Yann LeCun"],
      authorIds: ["1453740540", "144189388", "1688882"],
      conference_year: 2021,
      conference_name: "neurips",
      conf_id: "neurips2021",
      review_scores: [5.0, 5.0, 8.0, 5.0],
      review_score_avg: 5.75,
      review_confidences: [5.0, 5.0, 8.0, 5.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "K9uApq7iyyI",
      semantic_scholar_id: "48a6aadf7fd6a1de64a6971ae3eeb24aae007bb5",
      raw_decision: "NeurIPS 2021 Rejected",
      normalized_decision: "Reject",
      title:
        "ResMLP: Feedforward Networks for Image Classification With Data-Efficient Training",
      abstract:
        "We  present ResMLP an architecture built entirely upon multi-layer perceptrons  for image classification. It is a simple residual network that alternates (i) a linear layer in which image patches interact, independently and identically across channels, and (ii)  a two-layer feed-forward network in which channels interact independently per patch. \nWhen trained with a modern training strategy using heavy data-augmentation and optionally distillation, it attains surprisingly good accuracy/complexity trade-offs on ImageNet. \nWe also train ResMLP models in a self-supervised setup, to further remove priors from employing a labelled dataset. \nFinally, by adapting our model to machine translation we achieve  surprisingly good results. \n\nWe will share our code based on the Timm library and  pre-trained models.",
      keywords: [
        "deep learning",
        "neural networks",
        "image classification",
        "machine translation",
        "transformer",
      ],
      accepted: false,
      publication_venue:
        "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      publication_venue_id: "25248f80-fe99-48e5-9b8e-9baef3b8e23b",
      url: "https://www.semanticscholar.org/paper/48a6aadf7fd6a1de64a6971ae3eeb24aae007bb5",
      citation_count: 628,
      authors: [
        "Hugo Touvron",
        "Piotr Bojanowski",
        "Mathilde Caron",
        "M. Cord",
        "Alaaeldin El-Nouby",
        "Edouard Grave",
        "Gautier Izacard",
        "Armand Joulin",
        "Gabriel Synnaeve",
        "Jakob Verbeek",
        "Herv'e J'egou",
      ],
      authorIds: [
        "2113243762",
        "2329288",
        "2062862676",
        "51021910",
        "1388811741",
        "3024698",
        "1410231361",
        "2319608",
        "2282478",
        "34602236",
        "2065248680",
      ],
      conference_year: 2021,
      conference_name: "neurips",
      conf_id: "neurips2021",
      review_scores: [7.0, 6.0, 5.0, 5.0],
      review_score_avg: 5.75,
      review_confidences: [7.0, 6.0, 5.0, 5.0],
      review_confidence_avg: 3.75,
    },
    {
      id: "oioB7Te7Bo",
      semantic_scholar_id: "61e06615f6cee5ed1ba7d22b801925b69a45653b",
      raw_decision: "NeurIPS 2021 Rejected",
      normalized_decision: "Reject",
      title: "The Values Encoded in Machine Learning Research",
      abstract:
        "Machine learning (ML) currently exerts an outsized influence on the world, increasingly affecting communities and institutional practices. It is therefore critical that we question vague conceptions of the field as value-neutral or universally beneficial, and investigate what specific values the field is advancing. In this paper, we present a rigorous examination of the values the field advances by quantitatively and qualitatively analysing 100 highly cited ML papers published at premier ML conferences, ICML and NeurIPS. We annotate key features of papers which reveal their values: how they justify their choice of project, which aspects they uplift, their consideration of potential negative consequences, and their institutional affiliations and funding sources. We find that societal needs are typically very loosely connected to the choice of project, if mentioned at all, and that consideration of negative consequences is extremely rare. We identify 63 values that are uplifted in these papers, and, of these, we find that papers most frequently justify and assess themselves based on performance, generalization, efficiency, researcher understanding, novelty, and building on previous work. We present extensive textual evidence and analysis of how these values are concretized. Notably, we find that each of these top values is being defined and applied with assumptions and implications generally supporting the centralization of power. Finally, we find increasingly close ties between these highly cited papers and tech companies and elite universities.",
      keywords: [
        "values",
        "machine learning",
        "justification",
        "negative consequences",
        "corporate affiliations",
      ],
      accepted: false,
      publication_venue:
        "Conference on Fairness, Accountability and Transparency",
      publication_venue_id: "cdc83875-a82d-445c-b097-cbe91afe99a8",
      url: "https://www.semanticscholar.org/paper/61e06615f6cee5ed1ba7d22b801925b69a45653b",
      citation_count: 263,
      authors: [
        "Abeba Birhane",
        "Pratyusha Kalluri",
        "Dallas Card",
        "William Agnew",
        "Ravit Dotan",
        "Michelle Bao",
      ],
      authorIds: [
        "8318698",
        "13014201",
        "35540755",
        "27377925",
        "1441101651",
        "2115910347",
      ],
      conference_year: 2021,
      conference_name: "neurips",
      conf_id: "neurips2021",
      review_scores: [5.0, 7.0, 3.0],
      review_score_avg: 5.0,
      review_confidences: [5.0, 7.0, 3.0],
      review_confidence_avg: 3.6666666667,
    },
    {
      id: "D8-iwC9UN3",
      semantic_scholar_id: "482c496bd7c328f219fe8a75298146edd35d3f46",
      raw_decision: "NeurIPS 2021 Rejected",
      normalized_decision: "Reject",
      title: "Efficient and Modular Implicit Differentiation",
      abstract:
        "Automatic differentiation (autodiff) has revolutionized machine learning.  It allows expressing complex computations by composing elementary ones in creative ways and removes the tedious burden of computing their derivatives by hand. More recently, differentiation of optimization problem solutions has attracted a great deal of research, with applications as a layer in a neural network, and in bi-level optimization, including hyper-parameter optimization. However, the formulae for these derivatives often involves a tedious manual derivation. In this paper, we propose a unified, efficient and modular approach for implicit differentiation of optimization problems. In our approach, the user defines directly in Python a function $F$ capturing the optimality conditions of the problem to be differentiated. Once this is done, we leverage autodiff of $F$ to automatically differentiate the optimization problem. This way, our approach combines the benefits of implicit differentiation and autodiff.  We show that seemingly simple principles allow to recover all recently proposed implicit differentiation methods and create new ones easily.  We demonstrate the ease of formulating and solving bi-level optimization problems using our framework.\n",
      keywords: ["implicit differentiation bilevel optimization autodiff"],
      accepted: false,
      publication_venue: "Neural Information Processing Systems",
      publication_venue_id: "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
      url: "https://www.semanticscholar.org/paper/482c496bd7c328f219fe8a75298146edd35d3f46",
      citation_count: 206,
      authors: [
        "Mathieu Blondel",
        "Quentin Berthet",
        "Marco Cuturi",
        "Roy Frostig",
        "Stephan Hoyer",
        "Felipe Llinares-L'opez",
        "Fabian Pedregosa",
        "Jean-Philippe Vert",
      ],
      authorIds: [
        "27257992",
        "3169833",
        "1711979",
        "34765463",
        "7018631",
        "2075355249",
        "2570016",
        "152303545",
      ],
      conference_year: 2021,
      conference_name: "neurips",
      conf_id: "neurips2021",
      review_scores: [6.0, 7.0, 6.0, 5.0],
      review_score_avg: 6.0,
      review_confidences: [6.0, 7.0, 6.0, 5.0],
      review_confidence_avg: 3.75,
    },
    {
      id: "l0BP1lHpPW",
      semantic_scholar_id: "238c5ae6a6c45c7a1ffdba24f752640d82190b34",
      raw_decision: "NeurIPS 2021 Rejected",
      normalized_decision: "Reject",
      title: "Optimal Client Sampling for Federated Learning",
      abstract:
        'It is well understood that client-master communication can be a primary bottleneck in Federated Learning. In this work, we address this issue with a novel client subsampling scheme, where we restrict the number of clients allowed to communicate their updates back to the master node. In each communication round, all participated clients compute their updates, but only the ones with "important" updates communicate back to the master. We show that importance can be measured using only the norm of the update and give a formula for optimal client participation. This formula minimizes the distance between the full update, where all clients participate, and our limited update, where the number of participating clients is restricted. In addition, we provide a simple algorithm that approximates the optimal formula for client participation which only requires secure aggregation and thus does not compromise client privacy. We show both theoretically and empirically that our approach leads to superior performance for Distributed SGD (DSGD) and Federated Averaging (FedAvg) compared to the baseline where participating clients are sampled uniformly. Our approach is orthogonal to and compatible with existing methods for reducing communication overhead, such as local methods and communication compression methods.',
      keywords: ["Federated Learning", "Distributed Optimization"],
      accepted: false,
      publication_venue: null,
      publication_venue_id: null,
      url: "https://www.semanticscholar.org/paper/238c5ae6a6c45c7a1ffdba24f752640d82190b34",
      citation_count: 178,
      authors: ["Wenlin Chen", "Samuel Horv\u00e1th", "Peter Richt\u00e1rik"],
      authorIds: ["48993665", "2066680718", "2662221"],
      conference_year: 2021,
      conference_name: "neurips",
      conf_id: "neurips2021",
      review_scores: [6.0, 5.0, 6.0, 5.0],
      review_score_avg: 5.5,
      review_confidences: [6.0, 5.0, 6.0, 5.0],
      review_confidence_avg: 3.5,
    },
    {
      id: "JzdYX8uzT4W",
      semantic_scholar_id: "40b68df4635298c32725891bc46ee0201dac56c1",
      raw_decision: "NeurIPS 2021 Rejected",
      normalized_decision: "Reject",
      title: "Decoupled Contrastive Learning",
      abstract:
        "Contrastive learning (CL) is one of the most successful paradigms for self-supervised learning (SSL). Specifically, contrastive learning treats two augmented ``views'' of the same sample as positive, pulling them close and treating all other samples as negative to push them far apart. Despite the evident success of CL SSL methods, there are several challenges in the existing methods as they may require special structures, large batches, or huge training epochs, etc. Our motivation in this work is to provide a simple, efficient, and yet competitive contrastive learning baseline. Through both theoretical and empirical studies, we identified a strong negative-positive-coupling (NPC) effect in the widely used cross-entropy loss in CL SSL methods. We hypothesize that the NPC effect may be a major cause of the inefficiency in many contrastive learning methods. By removing the NPC effect, we reach a decoupled contrastive learning (DCL) objective function, which significantly improves the training efficiency. DCL can achieve competitive performance, requiring neither large batches in SimCLR, momentum encoding in Moco, or large epochs. We demonstrate the benefit of DCL in various benchmarks. Further, DCL is also much less sensitive to suboptimal hyperparameters. Notably, our approach achieves $66.9\\%$ ImageNet top-1 accuracy with 256 batch size within 200 epochs pre-training, which outperforms its baseline SimCLR by $5.1\\%$. We believe DCL may provide a strong baseline for future contrastive learning-based SSL studies.",
      keywords: [
        "Contrastive Learning",
        "Unsupervised Learning",
        "Self-Supervised Learning",
      ],
      accepted: false,
      publication_venue: "European Conference on Computer Vision",
      publication_venue_id: "167fa0ca-e88a-4ef7-a16f-bc66c457c806",
      url: "https://www.semanticscholar.org/paper/40b68df4635298c32725891bc46ee0201dac56c1",
      citation_count: 174,
      authors: [
        "Chun-Hsiao Yeh",
        "Cheng-Yao Hong",
        "Yen-Chi Hsu",
        "Tyng-Luh Liu",
        "Yubei Chen",
        "Yann LeCun",
      ],
      authorIds: [
        "21288929",
        "1388735506",
        "2000588659",
        "1805102",
        "2109184424",
        "1688882",
      ],
      conference_year: 2021,
      conference_name: "neurips",
      conf_id: "neurips2021",
      review_scores: [6.0, 6.0, 6.0, 6.0],
      review_score_avg: 6.0,
      review_confidences: [6.0, 6.0, 6.0, 6.0],
      review_confidence_avg: 3.5,
    },
    {
      id: "OAMrSPRRxJx",
      semantic_scholar_id: "d568557a2c75e879373fd6b62e020cf86037a6c7",
      raw_decision: "NeurIPS 2021 Rejected",
      normalized_decision: "Reject",
      title: "Deep Policy Dynamic Programming for Vehicle Routing Problems",
      abstract:
        "Routing problems are a class of combinatorial problems with many practical applications. Recently, end-to-end deep learning methods have been proposed to learn approximate solution heuristics for such problems. In contrast, classical dynamic programming (DP) algorithms guarantee optimal solutions, but scale badly with the problem size. We propose \\emph{Deep Policy Dynamic Programming} (DPDP), which aims to combine the strengths of learned neural heuristics with those of DP algorithms.\nDPDP prioritizes and restricts the DP state space using a policy derived from a deep neural network, which is trained to predict edges from example solutions. We evaluate our framework on the travelling salesman problem (TSP), the vehicle routing problem (VRP) and TSP with time windows (TSPTW) and show that the neural policy improves the performance of (restricted) DP algorithms, making them competitive to strong alternatives such as LKH, while also outperforming most other 'neural approaches' for solving TSPs, VRPs and TSPTWs with 100 nodes.",
      keywords: [
        "vehicle routing",
        "travelling salesman problem",
        "dynamic programming",
        "neural",
        "network",
        "policy",
        "time windows",
        "constraints",
      ],
      accepted: false,
      publication_venue:
        "Integration of AI and OR Techniques in Constraint Programming",
      publication_venue_id: "ad649a48-7b8a-4f02-bf0b-64d9a6f73105",
      url: "https://www.semanticscholar.org/paper/d568557a2c75e879373fd6b62e020cf86037a6c7",
      citation_count: 113,
      authors: ["W. Kool", "H. V. Hoof", "J. Gromicho", "M. Welling"],
      authorIds: ["50349716", "47662867", "2291532", "1678311"],
      conference_year: 2021,
      conference_name: "neurips",
      conf_id: "neurips2021",
      review_scores: [6.0, 5.0, 5.0, 4.0],
      review_score_avg: 5.0,
      review_confidences: [6.0, 5.0, 5.0, 4.0],
      review_confidence_avg: 3.75,
    },
    {
      id: "n646avOVJ7q",
      semantic_scholar_id: "766f25e1e6adb4d76403e2a59733257b77d5db12",
      raw_decision: "NeurIPS 2021 Rejected",
      normalized_decision: "Reject",
      title:
        "Global Convergence of Multi-Agent Policy Gradient in Markov Potential Games",
      abstract:
        "Potential games are arguably one of the most important and widely studied classes of normal form games. They define the archetypal setting of multi-agent coordination as all agent utilities are perfectly aligned with each other via a common potential function. Can this intuitive framework be transplanted in the setting of Markov Games? What are the similarities and differences between multi-agent coordination with and without state dependence? We present a novel definition of Markov Potential Games (MPG) that generalizes prior attempts at capturing complex stateful multi-agent coordination. Counter-intuitively, insights from normal-form potential games do not carry over as MPGs can consist of settings where state-games can be zero-sum games. In the opposite direction, Markov games where every state-game is a potential game are not necessarily MPGs. Nevertheless, MPGs showcase standard desirable properties such as the existence of deterministic Nash policies. In our main technical result, we prove fast convergence of independent policy gradient to Nash policies by adapting recent gradient dominance property arguments developed for single agent MDPs to multi-agent learning settings. ",
      keywords: [
        "Multi-agent Reinforcement Learning",
        "Markov Potential Games",
        "Policy Gradient",
      ],
      accepted: false,
      publication_venue: "International Conference on Learning Representations",
      publication_venue_id: "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
      url: "https://www.semanticscholar.org/paper/766f25e1e6adb4d76403e2a59733257b77d5db12",
      citation_count: 112,
      authors: [
        "Stefanos Leonardos",
        "W. Overman",
        "Ioannis Panageas",
        "G. Piliouras",
      ],
      authorIds: ["7658372", "1389939192", "2522024", "1787822"],
      conference_year: 2021,
      conference_name: "neurips",
      conf_id: "neurips2021",
      review_scores: [5.0, 7.0, 5.0, 7.0],
      review_score_avg: 6.0,
      review_confidences: [5.0, 7.0, 5.0, 7.0],
      review_confidence_avg: 3.5,
    },
    {
      id: "ZyugLlWzdO",
      semantic_scholar_id: "7544db2ae3140081b1581a99eee88960cc31415a",
      raw_decision: "NeurIPS 2021 Rejected",
      normalized_decision: "Reject",
      title:
        "Is Heterophily A Real Nightmare For Graph Neural Networks To Do Node Classification?",
      abstract:
        "Graph Neural Networks (GNNs) extend basic Neural Networks (NNs) by using the graph structures based on the relational inductive bias (homophily assumption). Though GNNs are believed to outperform NNs in real-world tasks, performance advantages of GNNs over graph-agnostic NNs seem not generally satisfactory. Heterophily has been considered as a main cause and numerous works have been put forward to address it. In this paper, we first show that not all cases of heterophily are harmful for GNNs with aggregation operation. Then, we propose new metrics based on a similarity matrix which considers the influence of graph structure and input features on GNNs. The metrics demonstrate advantages over the commonly used homophily metrics by tests on synthetic graphs. From the metrics and the observations, we find some cases of harmful heterophily can be addressed by diversification operation. With this fact and knowledge of filterbanks, we propose the Adaptive Channel Mixing (ACM) framework to adaptively exploit aggregation, diversification and identity operations in each GNN layer to address harmful heterophily. We validate the ACM-augmented baselines with 11 real-world node classification tasks. They consistently achieve significant performance gain and exceed the state-of-the-art GNNs on most of the tasks without incurring significant computational burden.",
      keywords: [
        "Graph Neural Networks",
        "Homophily",
        "Heterophily",
        "Filterbank",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/7544db2ae3140081b1581a99eee88960cc31415a",
      citation_count: 107,
      authors: [
        "Sitao Luan",
        "Chenqing Hua",
        "Qincheng Lu",
        "Jiaqi Zhu",
        "Mingde Zhao",
        "Shuyuan Zhang",
        "Xiaoming Chang",
        "Doina Precup",
      ],
      authorIds: [
        "121556146",
        "1658053701",
        "2151674463",
        "2290362966",
        "2152527029",
        "2108021834",
        "2151237251",
        "144368601",
      ],
      conference_year: 2021,
      conference_name: "neurips",
      conf_id: "neurips2021",
      review_scores: [6.0, 5.0, 6.0, 5.0],
      review_score_avg: 5.5,
      review_confidences: [6.0, 5.0, 6.0, 5.0],
      review_confidence_avg: 3.75,
    },
    {
      id: "zGsRcuoR5-0",
      semantic_scholar_id: "b9ea1c5fd417c5af2e3aa44a2a3c66f77bac190e",
      raw_decision: "NeurIPS 2021 Rejected",
      normalized_decision: "Reject",
      title:
        "Sample Selection with Uncertainty of Losses for Learning with Noisy Labels",
      abstract:
        "In learning with noisy labels, the sample selection approach is very popular, which regards small-loss data as correctly labeled data during training. However, losses are generated on-the-\ufb02y based on the model being trained with noisy labels, and thus large-loss data are likely but not certainly to be incorrect. There are actually two possibilities of a large-loss data point: (a) it is mislabeled, and then its loss decreases slower than other data, since deep neural networks learn patterns \ufb01rst; (b) it belongs to an underrepresented group of data and has not been selected yet. In this paper, we incorporate the uncertainty of losses by adopting interval estimation instead of point estimation of losses, where lower bounds of the con\ufb01dence intervals of losses derived from distribution-free concentration inequalities, but not losses themselves, are used for sample selection. In this way, we also give large-loss but less selected data a try; then, we can better distinguish between the cases (a) and (b) by seeing if the losses effectively decrease with the uncertainty after the try. As a result, we can better explore underrepresented data that are correctly labeled but seem to be mislabeled at \ufb01rst glance. Experiments demonstrate that the proposed method is superior to baselines and robust to a broad range of label noise types.",
      keywords: [
        "Learning with noisy labels",
        "Sample selection",
        "Uncertainty",
      ],
      accepted: false,
      publication_venue: "International Conference on Learning Representations",
      publication_venue_id: "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
      url: "https://www.semanticscholar.org/paper/b9ea1c5fd417c5af2e3aa44a2a3c66f77bac190e",
      citation_count: 107,
      authors: [
        "Xiaobo Xia",
        "Tongliang Liu",
        "Bo Han",
        "Mingming Gong",
        "Jun Yu",
        "Gang Niu",
        "Masashi Sugiyama",
      ],
      authorIds: [
        "2077454998",
        "121698214",
        "2087238859",
        "29393235",
        "2117884081",
        "47537639",
        "67154907",
      ],
      conference_year: 2021,
      conference_name: "neurips",
      conf_id: "neurips2021",
      review_scores: [6.0, 7.0, 6.0],
      review_score_avg: 6.3333333333,
      review_confidences: [6.0, 7.0, 6.0],
      review_confidence_avg: 4.3333333333,
    },
  ],
  neurips2022: [
    {
      id: "n7XbkHOwKn6",
      semantic_scholar_id: "707bd332d2c21dc5eb1f02a52d4a0506199aae76",
      raw_decision: "NeurIPS 2022 Opt-In Rejected",
      normalized_decision: "Reject",
      title:
        "CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers",
      abstract:
        "Large-scale pretrained transformers have created milestones in text (GPT-3) and text-to-image (DALL-E) generation. Its application on video generation is still faced difficulties: The huge computation makes training from scratch unaffordable; The scarcity and weak relevance of text-video datasets hinder the model understanding complex movements. In this work, we present 9-billion-parameter CogVideo, which is trained by inheriting the knowledge from the pretrained large-scale text-to-image model, CogView2. We also propose multi-frame-rate hierarchical training strategy to better align text and video clips. As (probably) the first open-source large-scale pretrained text-to-video model, the CogVideo outperforms the previous public available models at a large margin in both machine and human evaluation. \n",
      keywords: ["pretraining"],
      accepted: false,
      publication_venue: "International Conference on Learning Representations",
      publication_venue_id: "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
      url: "https://www.semanticscholar.org/paper/707bd332d2c21dc5eb1f02a52d4a0506199aae76",
      citation_count: 511,
      authors: [
        "Wenyi Hong",
        "Ming Ding",
        "Wendi Zheng",
        "Xinghan Liu",
        "Jie Tang",
      ],
      authorIds: [
        "2105844599",
        "2055623340",
        "2163967642",
        "46522721",
        "2148911990",
      ],
      conference_year: 2022,
      conference_name: "neurips",
      conf_id: "neurips2022",
      review_scores: [6.0, 3.0, 6.0, 6.0],
      review_score_avg: 5.25,
      review_confidences: [6.0, 3.0, 6.0, 6.0],
      review_confidence_avg: 3.4,
    },
    {
      id: "IfFZr1gl0b",
      semantic_scholar_id: "11f42721f56f36a64638677ccde7784040829656",
      raw_decision: "NeurIPS 2022 Opt-In Rejected",
      normalized_decision: "Reject",
      title:
        "Uni-Mol: A Universal 3D Molecular Representation Learning Framework",
      abstract:
        "Molecular representation learning (MRL) has gained tremendous attention due to its critical role in learning from limited supervised data for applications like drug design. In most MRL methods, molecules are treated as 1D sequential tokens or 2D topology graphs, limiting their ability to incorporate 3D information for downstream tasks and, in particular, making it almost impossible for 3D geometry prediction or generation. Herein, we propose Uni-Mol, a universal MRL framework that significantly enlarges the representation ability and application scope of MRL schemes. Uni-Mol is composed of two models with the same SE(3)-equivariant transformer architecture: a molecular pretraining model trained by 209M molecular conformations; a pocket pretraining model trained by 3M candidate protein pocket data. The two models are used independently for separate tasks, and are combined when used in protein-ligand binding tasks. By properly incorporating 3D information, Uni-Mol outperforms SOTA in 14/15 molecular property prediction tasks. Moreover, Uni-Mol achieves superior performance in 3D spatial tasks, including protein-ligand binding pose prediction, molecular conformation generation, etc. Finally, we show that Uni-Mol can be successfully applied to the tasks with few-shot data like pocket druggability prediction. ",
      keywords: [
        "Representation Learning",
        "Large-Scale 3D Molecular Pretraining",
        "Molecular Property",
        "Protein-Ligand Complex",
      ],
      accepted: false,
      publication_venue: "International Conference on Learning Representations",
      publication_venue_id: "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
      url: "https://www.semanticscholar.org/paper/11f42721f56f36a64638677ccde7784040829656",
      citation_count: 265,
      authors: [
        "G. Zhou",
        "Zhifeng Gao",
        "Qiankun Ding",
        "Hang Zheng",
        "Hongteng Xu",
        "Zhewei Wei",
        "Linfeng Zhang",
        "Guolin Ke",
      ],
      authorIds: [
        "2107531769",
        "2205712751",
        "2220891376",
        "2205719576",
        "2146235527",
        "12457830",
        "2181109681",
        "35286545",
      ],
      conference_year: 2022,
      conference_name: "neurips",
      conf_id: "neurips2022",
      review_scores: [4.0, 6.0, 4.0, 6.0],
      review_score_avg: 5.0,
      review_confidences: [4.0, 6.0, 4.0, 6.0],
      review_confidence_avg: 4.4,
    },
    {
      id: "_efamP7PSjg",
      semantic_scholar_id: "1ede15a0aa5204de1f3013d7616a93dbd46fd849",
      raw_decision: "NeurIPS 2022 Opt-In Rejected",
      normalized_decision: "Reject",
      title:
        "Equiformer: Equivariant Graph Attention Transformer for 3D Atomistic Graphs",
      abstract:
        "3D-related inductive biases like translational invariance and rotational equivariance are indispensable to graph neural networks operating on 3D atomistic graphs such as molecules. Inspired by the success of Transformers in various domains, we study how to incorporate these inductive biases into Transformers. In this paper, we present Equiformer, a graph neural network leveraging the strength of Transformer architectures and incorporating SE(3)/E(3)-equivariant features based on irreducible representations (irreps). Irreps features encode equivariant information in channel dimensions without complicating graph structures. The simplicity enables us to directly incorporate them by replacing original operations with equivariant counterparts. Moreover, to better adapt Transformers to 3D graphs, we propose a novel equivariant graph attention, which considers both content and geometric information such as relative position contained in irreps features. To improve expressivity of the attention, we replace dot product attention with multi\u0002-layer perceptron attention and include non-linear message passing. We benchmark Equiformer on two quantum properties prediction datasets, QM9 and OC20. For QM9, among models trained with the same data partition, Equiformer achieves best results on 11 out of 12 regression tasks. For OC20, under the same setting of training with IS2RE data only, Equiformer improves upon state-of-the-art models.",
      keywords: [
        "equivariant neural networks",
        "graph neural networks",
        "computational physics",
        "transformer networks",
      ],
      accepted: false,
      publication_venue: "International Conference on Learning Representations",
      publication_venue_id: "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
      url: "https://www.semanticscholar.org/paper/1ede15a0aa5204de1f3013d7616a93dbd46fd849",
      citation_count: 200,
      authors: ["Yi Liao", "T. Smidt"],
      authorIds: ["2048004675", "5485763"],
      conference_year: 2022,
      conference_name: "neurips",
      conf_id: "neurips2022",
      review_scores: [4.0, 5.0, 5.0, 6.0],
      review_score_avg: 5.0,
      review_confidences: [4.0, 5.0, 5.0, 6.0],
      review_confidence_avg: 3.4,
    },
    {
      id: "zSeoDvsDCe",
      semantic_scholar_id: "eb984b142db9965b10a3b5ae5813eeb3e0f6e676",
      raw_decision: "NeurIPS 2022 Opt-In Rejected",
      normalized_decision: "Reject",
      title:
        "Sign and Basis Invariant Networks for Spectral Graph Representation Learning",
      abstract:
        "We introduce SignNet and BasisNet---new neural architectures that are invariant to two key symmetries displayed by eigenvectors: (i) sign flips, since if v is an eigenvector then so is -v; and (ii) more general basis symmetries, which occur in higher dimensional eigenspaces with infinitely many choices of basis eigenvectors. We prove that our networks are universal, i.e., they can approximate any continuous function of eigenvectors with the desired invariances. Moreover, when used with Laplacian eigenvectors, our architectures are provably expressive for graph representation learning: they can approximate any spectral graph convolution, can compute spectral invariants that go beyond message passing neural networks, and can provably simulate previously proposed graph positional encodings. Experiments show the strength of our networks for molecular graph regression, learning expressive graph representations, and learning neural fields on triangle meshes.",
      keywords: [
        "Invariance",
        "Equivariance",
        "Graph Neural Networks",
        "Eigenvectors",
        "Spectral",
      ],
      accepted: false,
      publication_venue: "International Conference on Learning Representations",
      publication_venue_id: "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
      url: "https://www.semanticscholar.org/paper/eb984b142db9965b10a3b5ae5813eeb3e0f6e676",
      citation_count: 134,
      authors: [
        "Derek Lim",
        "Joshua Robinson",
        "Lingxiao Zhao",
        "T. Smidt",
        "S. Sra",
        "Haggai Maron",
        "S. Jegelka",
      ],
      authorIds: [
        "50436643",
        "4594310",
        "21613538",
        "5485763",
        "3072326",
        "3416939",
        "2594093",
      ],
      conference_year: 2022,
      conference_name: "neurips",
      conf_id: "neurips2022",
      review_scores: [6.0, 6.0, 7.0, 3.0],
      review_score_avg: 5.5,
      review_confidences: [6.0, 6.0, 7.0, 3.0],
      review_confidence_avg: 3.0,
    },
    {
      id: "nVV6S2sb_UL",
      semantic_scholar_id: "2cb10b11951246878ad3fbd26313014e7d55b863",
      raw_decision: "NeurIPS 2022 Opt-In Rejected",
      normalized_decision: "Reject",
      title:
        "Securing Secure Aggregation: Mitigating Multi-Round Privacy Leakage in Federated Learning",
      abstract:
        "Secure aggregation is a critical component in federated learning, which enables the server to learn the aggregate model of the users without observing their local models. Conventionally, secure aggregation algorithms focus only on ensuring the privacy of individual users in a single training round. We contend that such designs can lead to significant privacy leakages over multiple training rounds, due to partial user selection/participation at each round of FL. In fact, we show that the conventional random user selection strategies in FL may lead to leaking users' individual models within a number of rounds that is linear in the number of users. To address this challenge, we introduce a secure aggregation framework, Multi-RoundSecAgg, with multi-round privacy guarantees. In particular, we introduce a new metric to quantify the privacy guarantees of FL over multiple training rounds, and develop a structured user selection strategy that guarantees the long-term privacy of each user (over any number of training rounds). Our framework also carefully accounts for the fairness and the average number of participating users at each round. Our experiments on MNIST, CIFAR-$10$ and CIFAR-$100$ datasets in the IID and the non-IID settings demonstrate the performance improvement over the baselines, both in terms of privacy protection and test accuracy.",
      keywords: [],
      accepted: false,
      publication_venue: "IACR Cryptology ePrint Archive",
      publication_venue_id: "166fd2b5-a928-4a98-a449-3b90935cc101",
      url: "https://www.semanticscholar.org/paper/2cb10b11951246878ad3fbd26313014e7d55b863",
      citation_count: 76,
      authors: [
        "Jinhyun So",
        "Ramy E. Ali",
        "Basak Guler",
        "Jiantao Jiao",
        "S. Avestimehr",
      ],
      authorIds: ["144491689", "2083487", "2325667", "2784735", "121011351"],
      conference_year: 2022,
      conference_name: "neurips",
      conf_id: "neurips2022",
      review_scores: [6.0, 7.0, 8.0, 4.0],
      review_score_avg: 6.25,
      review_confidences: [6.0, 7.0, 8.0, 4.0],
      review_confidence_avg: 2.8,
    },
    {
      id: "plu6AK3qs5T",
      semantic_scholar_id: "e73d51188ca5d71e183be4a828796d0a98ff7520",
      raw_decision: "NeurIPS 2022 Opt-In Rejected",
      normalized_decision: "Reject",
      title:
        "Automatic Clipping: Differentially Private Deep Learning Made Easier and Stronger",
      abstract:
        "Per-example gradient clipping is a key algorithmic step that enables practical differential private (DP) training for deep learning models. The choice of clipping norm $R$, however, is shown to be vital for achieving high accuracy under DP. We propose an easy-to-use replacement, called AutoClipping, that eliminates the need to tune $R$ for any DP optimizers, including DP-SGD, DP-Adam, DP-LAMB and many others.\nThe automatic variants are as private and computationally efficient as existing DP optimizers, but require no DP-specific hyperparameters and thus make DP training as amenable as the standard non-private training. We give a rigorous convergence analysis of automatic DP-SGD in the non-convex setting, which shows that it can enjoy an asymptotic convergence rate that matches the standard SGD, under a symmetric noise assumption of the per-sample gradients. We also demonstrate on various language and vision tasks that automatic clipping outperforms or matches the state-of-the-art, and can be easily employed with minimal changes to existing codebases.",
      keywords: [
        "deep learning",
        "differential privacy",
        "per-sample gradient clipping",
        "convergence",
      ],
      accepted: false,
      publication_venue: "Neural Information Processing Systems",
      publication_venue_id: "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
      url: "https://www.semanticscholar.org/paper/e73d51188ca5d71e183be4a828796d0a98ff7520",
      citation_count: 63,
      authors: ["Zhiqi Bu", "Yu-Xiang Wang", "Sheng Zha", "G. Karypis"],
      authorIds: ["151267882", "2040617", "40881843", "50877490"],
      conference_year: 2022,
      conference_name: "neurips",
      conf_id: "neurips2022",
      review_scores: [4.0, 6.0, 3.0, 6.0],
      review_score_avg: 4.75,
      review_confidences: [4.0, 6.0, 3.0, 6.0],
      review_confidence_avg: 3.2,
    },
    {
      id: "b9APFSTylGT",
      semantic_scholar_id: "0d5103378a9f4f6e08bfcd364da207f93b31b8b7",
      raw_decision: "NeurIPS 2022 Opt-In Rejected",
      normalized_decision: "Reject",
      title:
        "Prompt Learning with Optimal Transport for Vision-Language Models",
      abstract:
        "With the increasing attention to large vision-language models such as CLIP, there has been a significant amount of effort dedicated to building efficient prompts. Unlike conventional methods of only learning one single prompt, we propose to learn multiple comprehensive prompts to describe diverse characteristics of categories such as intrinsic attributes or extrinsic contexts. However, directly matching each prompt to the same visual feature is problematic, as it pushes the prompts to converge to one point. To solve this problem, we propose to apply optimal transport to match the vision and text modalities. Specifically, we first model images and the categories with visual and textual feature sets. Then, we apply a two-stage optimization strategy to learn the prompts. In the inner loop, we optimize the optimal transport distance to align visual features and prompts by the Sinkhorn algorithm, while in the outer loop, we learn the prompts by this distance from the supervised data. Extensive experiments are conducted on the few-shot recognition task and the significant improvement demonstrates the superiority of our method.",
      keywords: [
        "Prompt learning",
        "Few shot learning",
        "Vision-language pretrained model",
        "Optimal transport",
      ],
      accepted: false,
      publication_venue: "International Conference on Learning Representations",
      publication_venue_id: "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
      url: "https://www.semanticscholar.org/paper/0d5103378a9f4f6e08bfcd364da207f93b31b8b7",
      citation_count: 61,
      authors: [
        "Guangyi Chen",
        "Weiran Yao",
        "Xiangchen Song",
        "Xinyue Li",
        "Yongming Rao",
        "Kun Zhang",
      ],
      authorIds: [
        "9230423",
        "2087699735",
        "19214393",
        "2144455457",
        "39358728",
        "2175349484",
      ],
      conference_year: 2022,
      conference_name: "neurips",
      conf_id: "neurips2022",
      review_scores: [7.0, 6.0, 7.0],
      review_score_avg: 6.6666666667,
      review_confidences: [7.0, 6.0, 7.0],
      review_confidence_avg: 4.5,
    },
    {
      id: "dJgYhYKvr1",
      semantic_scholar_id: "ff53cb49cb18e71e622fce7d96692e813630e878",
      raw_decision: "NeurIPS 2022 Opt-In Rejected",
      normalized_decision: "Reject",
      title:
        "The Slingshot Mechanism: An Empirical Study of Adaptive Optimizers and the Grokking Phenomenon",
      abstract:
        "The \\emph{grokking phenomenon} as reported by Power et al.~\\cite{power2021grokking} refers to a regime where a long period of overfitting is followed by a seemingly sudden transition to perfect generalization. In this paper, we attempt to reveal the underpinnings of Grokking via a series of empirical studies. Specifically, we uncover an optimization anomaly plaguing adaptive optimizers at extremely late stages of training, referred to as the \\emph{Slingshot Mechanism}. A prominent artifact of the Slingshot Mechanism can be measured by the cyclic phase transitions between stable and unstable training regimes, and can be easily monitored by the cyclic behavior of the norm of the last layers weights. We empirically observe that without explicit regularization, Grokking as reported in \\cite{power2021grokking} almost exclusively happens at the onset of \\emph{Slingshots}, and is absent without it. \n    While common and easily reproduced in more general settings, the Slingshot Mechanism does not follow from any known optimization theories that we are aware of, and can be easily overlooked without an in depth examination. Our work points to a surprising and useful inductive bias of adaptive gradient optimizers at late stages of training, calling for a revised theoretical analysis of their origin.",
      keywords: [
        "optimization",
        "adam",
        "adamw",
        "adaptive optimizers",
        "grokking",
        "training instability",
        "instability",
        "empirical",
        "empirical science of deep learning",
        "double descent",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/ff53cb49cb18e71e622fce7d96692e813630e878",
      citation_count: 55,
      authors: [
        "Vimal Thilak",
        "Etai Littwin",
        "Shuangfei Zhai",
        "O. Saremi",
        "Roni Paiss",
        "J. Susskind",
      ],
      authorIds: [
        "3042871",
        "1762320",
        "2443456",
        "2438203",
        "2134839079",
        "49158771",
      ],
      conference_year: 2022,
      conference_name: "neurips",
      conf_id: "neurips2022",
      review_scores: [6.0, 5.0, 5.0],
      review_score_avg: 5.3333333333,
      review_confidences: [6.0, 5.0, 5.0],
      review_confidence_avg: 2.5,
    },
    {
      id: "QUyasQGv1Nl",
      semantic_scholar_id: "6bae49801828b6e075e13d07332f755c6290d856",
      raw_decision: "NeurIPS 2022 Opt-In Rejected",
      normalized_decision: "Reject",
      title:
        "Hyperbolic Contrastive Learning for Visual Representations beyond Objects",
      abstract:
        "Despite the rapid progress in visual representation learning driven by self-/un-supervised methods, both objects and scenes have been primarily treated using the same lens. In this paper, we focus on learning representations for objects and scenes explicitly in the same space. Motivated by the observation that visually similar objects are close in the representation space, we argue that the scenes and objects should further follow a hierarchical structure based on their compositionality. To exploit such a structure, we propose a contrastive learning framework where a Euclidean loss is used to learn object representations and a hyperbolic loss is used to regularize scene representations according to the hierarchy. This novel hyperbolic objective encourages the scene-object hypernymy among the representations by optimizing the magnitude of their norms. We show that when pretraining on the COCO and OpenImages datasets, the hyperbolic loss improves downstream performance across multiple datasets and tasks, including image classification, object detection, and semantic segmentation. We also show that the properties of the learned representations allow us to solve various vision tasks that involve the interaction between scenes and objects in a zero-shot way.",
      keywords: [
        "contrastive learning",
        "self-supervised learning",
        "Riemannian geometry",
        "representation learning",
      ],
      accepted: false,
      publication_venue: "Computer Vision and Pattern Recognition",
      publication_venue_id: "768b87bb-8a18-4d9c-a161-4d483c776bcf",
      url: "https://www.semanticscholar.org/paper/6bae49801828b6e075e13d07332f755c6290d856",
      citation_count: 47,
      authors: [
        "Songwei Ge",
        "Shlok Kumar Mishra",
        "Simon Kornblith",
        "Chun-Liang Li",
        "David Jacobs",
      ],
      authorIds: [
        "51499340",
        "2850880",
        "40464924",
        "2116729195",
        "2059096514",
      ],
      conference_year: 2022,
      conference_name: "neurips",
      conf_id: "neurips2022",
      review_scores: [5.0, 6.0, 6.0],
      review_score_avg: 5.6666666667,
      review_confidences: [5.0, 6.0, 6.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "VwRFJi9crEH",
      semantic_scholar_id: "fe5b9a1b5e242d3cb23b8143ec26bd56c72ad139",
      raw_decision: "NeurIPS 2022 Opt-In Rejected",
      normalized_decision: "Reject",
      title: "Personalized Subgraph Federated Learning",
      abstract:
        "In real-world scenarios, subgraphs of a larger global graph may be distributed across multiple devices or institutions, and only locally accessible due to privacy restrictions, although there may be links between them. Recently proposed subgraph Federated Learning (FL) methods deal with those missing links across private local subgraphs while distributively training Graph Neural Networks (GNNs) on them. However, they have overlooked the inevitable heterogeneity among subgraphs, caused by subgraphs comprising different parts of a global graph. For example, a subgraph may belong to one of the communities within the larger global graph. A naive subgraph FL in such a case will collapse incompatible knowledge from local GNN models trained on heterogeneous graph distributions. To overcome such a limitation, we introduce a new subgraph FL problem, personalized subgraph FL, which focuses on the joint improvement of the interrelated local GNN models rather than learning a single global GNN model, and propose a novel framework, FEDerated Personalized sUBgraph learning (FED-PUB), to tackle it. A crucial challenge in personalized subgraph FL is that the server does not know which subgraph each client has. FED-PUB thus utilizes functional embeddings of the local GNNs using random graphs as inputs to compute similarities between them, and use them to perform weighted averaging for server-side aggregation. Further, it learns a personalized sparse mask at each client to select and update only the subgraph-relevant subset of the aggregated parameters. We validate FED-PUB for its subgraph FL performance on six datasets, considering both non-overlapping and overlapping subgraphs, on which ours largely outperforms relevant baselines.",
      keywords: [
        "Graph Representation Learning",
        "Graph Neural Networks",
        "Federated Learning",
        "Subgraph Federated Learning",
      ],
      accepted: false,
      publication_venue: "International Conference on Machine Learning",
      publication_venue_id: "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
      url: "https://www.semanticscholar.org/paper/fe5b9a1b5e242d3cb23b8143ec26bd56c72ad139",
      citation_count: 44,
      authors: [
        "Jinheon Baek",
        "Wonyong Jeong",
        "Jiongdao Jin",
        "Jaehong Yoon",
        "Sung Ju Hwang",
      ],
      authorIds: [
        "90765684",
        "148346757",
        "2171805177",
        "13563486",
        "35788904",
      ],
      conference_year: 2022,
      conference_name: "neurips",
      conf_id: "neurips2022",
      review_scores: [5.0, 5.0, 4.0, 6.0],
      review_score_avg: 5.0,
      review_confidences: [5.0, 5.0, 4.0, 6.0],
      review_confidence_avg: 4.2,
    },
  ],
  neurips2023: [
    {
      id: "a648X9AoL4",
      semantic_scholar_id: "bda605928d6ebe4db906e69ab5d343df75918727",
      raw_decision: "NeurIPS 2023 Rejected",
      normalized_decision: "Reject",
      title: "Large Language Model Guided Tree-of-Thought",
      abstract:
        "In this paper, we introduce the Tree-of-Thought (ToT) framework, a novel approach aimed at improving the problem-solving capabilities of auto-regressive large language models (LLMs). The ToT technique is inspired by the human mind's approach for solving complex reasoning tasks through trial and error. In this process, the human mind explores the solution space through a tree-like thought process, allowing for backtracking when necessary. To implement ToT as a software system, we augment an LLM with additional modules including a prompter agent, a checker module, a memory module, and a ToT controller. In order to solve a given problem, these modules engage in a multi-round conversation with the LLM. The memory module records the conversation and state history of the problem solving process, which allows the system to backtrack to the previous steps of the thought-process and explore other directions from there. To verify the effectiveness of the proposed technique, we implement a ToT-based solver for the Sudoku Puzzle. Experimental results show that the ToT framework can significantly increase the success rate of Sudoku puzzle solving.",
      keywords: ["LLM", "tree of thought", "problem solving"],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/bda605928d6ebe4db906e69ab5d343df75918727",
      citation_count: 168,
      authors: ["Jieyi Long"],
      authorIds: ["2210091344"],
      conference_year: 2023,
      conference_name: "neurips",
      conf_id: "neurips2023",
      review_scores: [3.0, 3.0, 2.0, 4.0, 4.0],
      review_score_avg: 3.2,
      review_confidences: [3.0, 3.0, 2.0, 4.0, 4.0],
      review_confidence_avg: 4.2,
    },
    {
      id: "lSZXSDwvGv",
      semantic_scholar_id: "2e6b6de08f459e2165b11ed8d2103916966b0fcf",
      raw_decision: "NeurIPS 2023 Rejected",
      normalized_decision: "Reject",
      title:
        "Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback",
      abstract:
        "We study whether multiple large language models (LLMs) can autonomously\nimprove each other in a negotiation game by playing, reflecting, and criticizing.\nWe are interested in this question because if LLMs were able to improve each other, it\nwould imply the possibility of creating strong AI agents with minimal human\nintervention. We ask two LLMs to bargain with each other, playing the roles of a\nbuyer and a seller, respectively. They aim to reach a deal with the buyer targeting\na lower price and the seller a higher one. A third language model, playing the\ncritic, provides feedback to a player to improve the player\u2019s negotiation strategies.\nWe let the two agents play multiple rounds, using previous negotiation history\nand AI feedback as in-context demonstrations to improve the\nmodel\u2019s negotiation strategy iteratively. We use different LLMs (GPT and Claude)\nfor different roles and use the deal price as the evaluation metric. Our experiments\nreveal multiple intriguing findings: (1) Only a subset of the language models we\nconsider can self-play and improve the deal price from AI feedback, weaker models\neither do not understand the game\u2019s rules or cannot incorporate AI feedback for\nfurther improvement. (2) Models\u2019 abilities to learn from the feedback differ when\nplaying different roles. For example, it is harder for Claude-instant to improve\nas the buyer than as the seller. (3) When unrolling the game to multiple rounds,\nstronger agents can consistently improve their performance by meaningfully using\nprevious experiences and iterative AI feedback, yet have a higher risk of breaking\nthe deal. We hope our work provides insightful initial explorations of having\nmodels autonomously improve each other with game playing and AI feedback.",
      keywords: [
        "large language models",
        "negotiation game",
        "in-context learning",
        "self-play",
        "AI feedback",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/2e6b6de08f459e2165b11ed8d2103916966b0fcf",
      citation_count: 157,
      authors: ["Yao Fu", "Hao-Chun Peng", "Tushar Khot", "Mirella Lapata"],
      authorIds: ["46956602", "2293471", "2236429", "1747893"],
      conference_year: 2023,
      conference_name: "neurips",
      conf_id: "neurips2023",
      review_scores: [5.0, 5.0, 4.0, 4.0],
      review_score_avg: 4.5,
      review_confidences: [5.0, 5.0, 4.0, 4.0],
      review_confidence_avg: 3.75,
    },
    {
      id: "3o4jU8fWVj",
      semantic_scholar_id: "713a0269aa8ffa9f5e8f5671fddc3768a2da9ec5",
      raw_decision: "NeurIPS 2023 Rejected",
      normalized_decision: "Reject",
      title:
        "EquiformerV2: Improved Equivariant Transformer for Scaling to Higher-Degree Representations",
      abstract:
        "Equivariant Transformers such as Equiformer have demonstrated the efficacy of applying Transformers to the domain of 3D atomistic systems. However, they are still limited to small degrees of equivariant representations due to their computational complexity. In this paper, we investigate whether these architectures can scale well to higher degrees. Starting from Equiformer, we first replace $SO(3)$ convolutions with eSCN convolutions to efficiently incorporate higher-degree tensors. Then, to better leverage the power of higher degrees, we propose three architectural improvements \u2013 attention re-normalization, separable $S^2$ activation and separable layer normalization. Putting this all together, we propose EquiformerV2, which outperforms previous state-of-the-art methods on the large-scale OC20 dataset by up to 15% on forces, 5% on energies, offers better speed-accuracy trade-offs, and 2$\\times$ reduction in DFT calculations needed for computing adsorption energies.",
      keywords: [
        "equivariant neural networks",
        "graph neural networks",
        "computational physics",
        "transformer networks",
      ],
      accepted: false,
      publication_venue: "International Conference on Learning Representations",
      publication_venue_id: "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
      url: "https://www.semanticscholar.org/paper/713a0269aa8ffa9f5e8f5671fddc3768a2da9ec5",
      citation_count: 116,
      authors: ["Yidong Liao", "Brandon Wood", "Abhishek Das", "T. Smidt"],
      authorIds: ["14078416", "2064495202", "2313517", "5485763"],
      conference_year: 2023,
      conference_name: "neurips",
      conf_id: "neurips2023",
      review_scores: [6.0, 5.0, 5.0, 5.0],
      review_score_avg: 5.25,
      review_confidences: [6.0, 5.0, 5.0, 5.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "m2getD1hpk",
      semantic_scholar_id: "afba7beaa7c66cfc72972eb2a569f13c7554bfef",
      raw_decision: "NeurIPS 2023 Rejected",
      normalized_decision: "Reject",
      title: "FITS: Modeling Time Series with 10k Parameters",
      abstract:
        "In this paper, we introduce FITS, a lightweight yet powerful model for time series analysis. Unlike existing models that directly process raw time-domain data, FITS operates on the principle that time series can be manipulated through interpolation in the complex frequency domain. By discarding high-frequency components with negligible impact on time series data, FITS achieves performance comparable to state-of-the-art models for time series forecasting and anomaly detection tasks, while having a remarkably compact size of only approximately $10k$ parameters. Such a lightweight model can be easily trained and deployed in edge devices, creating opportunities for various applications.\nThe anonymous code repo is available in: \\url{https://anonymous.4open.science/r/FITS}",
      keywords: [
        "Time series analysis",
        "Time series forecasting",
        "Complex-valued neural network",
      ],
      accepted: false,
      publication_venue: "International Conference on Learning Representations",
      publication_venue_id: "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
      url: "https://www.semanticscholar.org/paper/afba7beaa7c66cfc72972eb2a569f13c7554bfef",
      citation_count: 74,
      authors: ["Zhijian Xu", "Ailing Zeng", "Qiang Xu"],
      authorIds: ["2187789328", "51286000", "2149106517"],
      conference_year: 2023,
      conference_name: "neurips",
      conf_id: "neurips2023",
      review_scores: [5.0, 6.0, 3.0, 6.0, 7.0],
      review_score_avg: 5.4,
      review_confidences: [5.0, 6.0, 3.0, 6.0, 7.0],
      review_confidence_avg: 4.0,
    },
    {
      id: "0QpwcDPiHT",
      semantic_scholar_id: "95a0c8feccc01f2799c961ca850f75f9b054de6c",
      raw_decision: "NeurIPS 2023 Rejected",
      normalized_decision: "Reject",
      title:
        "Language Models Implement Simple Word2Vec-style Vector Arithmetic",
      abstract:
        "A primary criticism towards language models (LMs) is their inscrutability. This paper presents evidence that, despite their size and complexity, LMs sometimes exploit a computational mechanism familiar from traditional word embeddings: the use of simple vector arithmetic in order to encode abstract relations (e.g., Poland:Warsaw::China:Beijing). We investigate a range of language model sizes (from 124M parameters to 176B parameters) in an in-context learning setting, and find that for a variety of tasks (involving capital cities, upper-casing, and past-tensing), a key part of the mechanism reduces to a simple linear update applied by the feedforward networks. We further show that this mechanism is specific to tasks that require retrieval from pretraining memory, rather than retrieval from local context. Our results contribute to a growing body of work on the mechanistic interpretability of LLMs, and offer reason to be optimistic that, despite the massive and non-linear nature of the models, the strategies they ultimately use to solve tasks can sometimes reduce to familiar and even intuitive algorithms.",
      keywords: [
        "interpretability",
        "nlp",
        "neural networks",
        "deep learning",
        "explainability",
        "representation learning",
      ],
      accepted: false,
      publication_venue:
        "North American Chapter of the Association for Computational Linguistics",
      publication_venue_id: "01103732-3808-4930-b8e4-7e9e68d5c68d",
      url: "https://www.semanticscholar.org/paper/95a0c8feccc01f2799c961ca850f75f9b054de6c",
      citation_count: 49,
      authors: ["Jack Merullo", "Carsten Eickhoff", "Ellie Pavlick"],
      authorIds: ["1405408066", "30044743", "2949185"],
      conference_year: 2023,
      conference_name: "neurips",
      conf_id: "neurips2023",
      review_scores: [8.0, 5.0, 4.0, 6.0, 6.0],
      review_score_avg: 5.8,
      review_confidences: [8.0, 5.0, 4.0, 6.0, 6.0],
      review_confidence_avg: 3.6,
    },
    {
      id: "9B57dEeP3O",
      semantic_scholar_id: "e8753374e402cd756dcfec9bc74a34f8a5047f80",
      raw_decision: "NeurIPS 2023 Rejected",
      normalized_decision: "Reject",
      title:
        "Intelligent Grimm - Open-ended Visual Storytelling via Latent Diffusion Models",
      abstract:
        "Benefiting from the impressive diffusion models, conditional generative models have exhibited exceptional capabilities in various generation tasks, for example, image or short video generation based on text description. In this work, we focus on the task of generating a series of coherent images based on a given storyline, denoted as open-ended visual storytelling. We make the following three contributions: (i) to fulfill the task of visual storytelling, we introduce two modules into a pre-trained stable diffusion model, and construct an auto-regressive image generator, termed as StoryGen, that enables to generate the current frame by conditioning on a text prompt and preceding frame; (ii) to train our proposed model, we collect paired image and text samples by sourcing from various online sources, such as videos, E-books, and establish a data processing pipeline for constructing a diverse dataset, named StorySalon, with a far larger vocabulary than existing animation-specific datasets; (iii) we adopt a three-stage curriculum training strategy, that enables style transfer, visual context conditioning, and human feedback alignment, respectively. Quantitative experiments and human evaluation have validated the superiority of our proposed model, in terms of image quality, style consistency, content consistency, and visual-language alignment. We will make the code, model, and dataset publicly available to the research community.",
      keywords: ["Story Generation", "Diffusion Model"],
      accepted: false,
      publication_venue: "Computer Vision and Pattern Recognition",
      publication_venue_id: "768b87bb-8a18-4d9c-a161-4d483c776bcf",
      url: "https://www.semanticscholar.org/paper/e8753374e402cd756dcfec9bc74a34f8a5047f80",
      citation_count: 43,
      authors: [
        "Chang Liu",
        "Haoning Wu",
        "Yujie Zhong",
        "Xiaoyu Zhang",
        "Weidi Xie",
      ],
      authorIds: [
        "2118485386",
        "120155330",
        "1624475253",
        "2133402042",
        "10096695",
      ],
      conference_year: 2023,
      conference_name: "neurips",
      conf_id: "neurips2023",
      review_scores: [4.0, 6.0, 3.0, 3.0, 5.0],
      review_score_avg: 4.2,
      review_confidences: [4.0, 6.0, 3.0, 3.0, 5.0],
      review_confidence_avg: 4.2,
    },
    {
      id: "7w4RGjzd81",
      semantic_scholar_id: "15b0fadb0c703c915ad2caa3b5338415eb1ec0d2",
      raw_decision: "NeurIPS 2023 Rejected",
      normalized_decision: "Reject",
      title: "Unbiased Watermark for Large Language Models",
      abstract:
        "The recent advancements in large language models (LLMs) have sparked a growing apprehension regarding the potential misuse. One approach to mitigating this risk is to incorporate watermarking techniques into LLMs, allowing for the tracking and attribution of model outputs. This study examines a crucial aspect of watermarking: how significantly watermarks impact the quality of model-generated outputs. Previous studies have suggested a trade-off between watermark strength and output quality. However, our research demonstrates that it is possible to integrate watermarks without affecting the output probability distribution with appropriate implementation. We refer to this type of watermark as an unbiased watermark. This has significant implications for the use of LLMs, as it becomes impossible for users to discern whether a service provider has incorporated watermarks or not. Furthermore, the presence of watermarks does not compromise the performance of the model in downstream tasks, ensuring that the overall utility of the language model is preserved. Our findings contribute to the ongoing discussion around responsible AI development, suggesting that unbiased watermarks can serve as an effective means of tracking and attributing model outputs without sacrificing output quality.",
      keywords: ["watermark", "language model"],
      accepted: false,
      publication_venue: "International Conference on Learning Representations",
      publication_venue_id: "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
      url: "https://www.semanticscholar.org/paper/15b0fadb0c703c915ad2caa3b5338415eb1ec0d2",
      citation_count: 42,
      authors: [
        "Zhengmian Hu",
        "Lichang Chen",
        "Xidong Wu",
        "Yihan Wu",
        "Hongyang Zhang",
        "Heng Huang",
      ],
      authorIds: [
        "2048028814",
        "2108451006",
        "2145926918",
        "2254326623",
        "2257093062",
        "2254900739",
      ],
      conference_year: 2023,
      conference_name: "neurips",
      conf_id: "neurips2023",
      review_scores: [3.0, 5.0, 5.0, 6.0],
      review_score_avg: 4.75,
      review_confidences: [3.0, 5.0, 5.0, 6.0],
      review_confidence_avg: 3.25,
    },
    {
      id: "B4TAPfHa7g",
      semantic_scholar_id: "e79d9351477e48ca8e20cd97d6fb14973f26f004",
      raw_decision: "NeurIPS 2023 Rejected",
      normalized_decision: "Reject",
      title:
        "Model-based Safe Deep Reinforcement Learning via a Constrained Proximal Policy Optimization Algorithm",
      abstract:
        "The problem of constrained reinforcement learning (CRL) holds significant importance as it provides a framework for addressing critical safety satisfaction concerns in the field of reinforcement learning (RL). However, with the introduction of constraint satisfaction, the current CRL methods necessitate the utilization of second-order optimization or primal-dual frameworks with additional Lagrangian multipliers, resulting in increased complexity and inefficiency during implementation. To address these issues, we propose a novel first-order feasible method named Constrained Proximal Policy Optimization (CPPO). By treating the CRL problem as a probabilistic inference problem, our approach integrates the Expectation-Maximization framework to solve it through two steps: 1) calculating the optimal policy distribution within the feasible region (E-step), and 2) conducting a first-order update to adjust the current policy towards the optimal policy obtained in the E-step (M-step). We establish the relationship between the probability ratios and KL divergence to convert the E-step into a convex optimization problem. Furthermore, we develop an iterative heuristic algorithm from a geometric perspective to solve this problem. Additionally, we introduce a conservative update mechanism to overcome the constraint violation issue that occurs in the existing feasible region method. Empirical evaluations conducted in complex and uncertain environments validate the effectiveness of our proposed method, as it performs at least as well as other baselines.",
      keywords: ["constrained reinforcement learning"],
      accepted: false,
      publication_venue: "Neural Information Processing Systems",
      publication_venue_id: "d9720b90-d60b-48bc-9df8-87a30b9a60dd",
      url: "https://www.semanticscholar.org/paper/e79d9351477e48ca8e20cd97d6fb14973f26f004",
      citation_count: 36,
      authors: ["Ashish Kumar Jayant", "S. Bhatnagar"],
      authorIds: ["2187873478", "143683893"],
      conference_year: 2023,
      conference_name: "neurips",
      conf_id: "neurips2023",
      review_scores: [3.0, 4.0, 5.0, 5.0, 5.0, 4.0],
      review_score_avg: 4.3333333333,
      review_confidences: [3.0, 4.0, 5.0, 5.0, 5.0, 4.0],
      review_confidence_avg: 3.0,
    },
    {
      id: "srJvUWZu6L",
      semantic_scholar_id: "44375d0996ef965e9555e1a0d12e150a8e864a04",
      raw_decision: "NeurIPS 2023 Rejected",
      normalized_decision: "Reject",
      title:
        "ViDA: Homeostatic Visual Domain Adapter for Continual Test Time Adaptation",
      abstract:
        "Since real-world machine systems are running in non-stationary and continually changing environments, Continual Test-Time Adaptation (CTTA) task is proposed to adapt the pre-trained model to continually changing target domains. Recently, existing methods mainly focus on model-based adaptation, which aims to leverage a self-training manner to extract the target domain knowledge. However, pseudo labels can be noisy and the updated model parameters are uncertain under dynamic data distributions, leading to error accumulation and catastrophic forgetting in the continual adaptation process. To tackle these challenges and maintain the model plasticity, we tactfully design a Visual Domain Adapter (ViDA) for CTTA,  explicitly handling both domain-specific and domain-agnostic knowledge. Specifically, we first comprehensively explore the different domain representations of the adapters with trainable high and low-rank embedding space. Then we inject ViDAs into the pre-trained model, which leverages high-rank and low-rank prototypes to adapt the current domain distribution and maintain the continual domain-shared knowledge, respectively. To adapt to the various distribution shifts of each sample in target domains, we further propose a Homeostatic Knowledge Allotment (HKA) strategy, which adaptively merges knowledge from each ViDA with different rank prototypes. Extensive experiments conducted on four widely-used benchmarks demonstrate that our proposed method achieves state-of-the-art performance in both classification and segmentation CTTA tasks. In addition, our method can be regarded as a novel transfer paradigm and showcases promising results in zero-shot adaptation of foundation models to continual downstream tasks and distributions.",
      keywords: [
        "Domain Adapter",
        "Continual Test Time Adaptation",
        "Efficient Fine-tuning",
      ],
      accepted: false,
      publication_venue: "International Conference on Learning Representations",
      publication_venue_id: "939c6e1d-0d17-4d6e-8a82-66d960df0e40",
      url: "https://www.semanticscholar.org/paper/44375d0996ef965e9555e1a0d12e150a8e864a04",
      citation_count: 34,
      authors: [
        "Jiaming Liu",
        "Senqiao Yang",
        "Peidong Jia",
        "Ming Lu",
        "Yandong Guo",
        "Wei Xue",
        "Shanghang Zhang",
      ],
      authorIds: [
        "2108327121",
        "2191631097",
        "101105478",
        "2149494006",
        "3133575",
        "2195745651",
        "2437353",
      ],
      conference_year: 2023,
      conference_name: "neurips",
      conf_id: "neurips2023",
      review_scores: [6.0, 5.0, 6.0, 5.0],
      review_score_avg: 5.5,
      review_confidences: [6.0, 5.0, 6.0, 5.0],
      review_confidence_avg: 4.25,
    },
    {
      id: "au9VfbABDO",
      semantic_scholar_id: "e134ec1e834b0d56945916cdc02df653dc4e175d",
      raw_decision: "NeurIPS 2023 Rejected",
      normalized_decision: "Reject",
      title: "Diffusion Model-Augmented Behavioral Cloning",
      abstract:
        "Imitation learning addresses the challenge of learning by observing an expert\u2019s demonstrations without access to reward signals from the environment. Most existing imitation learning methods that do not require interacting with the environment either model the expert distribution as the conditional probability p(a|s) (e.g., behavioral cloning, BC) or the joint probability p(s, a) (e.g., implicit behavioral cloning). Despite its simplicity, modeling the conditional probability with BC usually struggles with generalization. While modeling the joint probability can lead to improved generalization performance, the inference procedure can be time-consuming and it often suffers from manifold overfitting. This work proposes an imitation learning framework that benefits from modeling both the conditional and joint probability of the expert distribution. Our proposed diffusion model-augmented behavioral cloning (DBC) employs a diffusion model trained to model expert behaviors and learns a policy to optimize both the BC loss (conditional) and our proposed diffusion model loss (joint). DBC outperforms baselines in various continuous control tasks in navigation, robot arm manipulation, dexterous manipulation, and locomotion. We design additional experiments to verify the limitations of modeling either the conditional probability or the joint probability of the expert distribution as well as compare different generative models.",
      keywords: [
        "Imitation Learning",
        "Learning from Demonstration",
        "Diffusion Models",
        "Behavioral Cloning",
      ],
      accepted: false,
      publication_venue: "International Conference on Machine Learning",
      publication_venue_id: "fc0a208c-acb7-47dc-a0d4-af8190e21d29",
      url: "https://www.semanticscholar.org/paper/e134ec1e834b0d56945916cdc02df653dc4e175d",
      citation_count: 26,
      authors: ["Hsiang-Chun Wang", "Shangcheng Chen", "Shao-Hua Sun"],
      authorIds: ["2210254136", "2118435475", "2109374418"],
      conference_year: 2023,
      conference_name: "neurips",
      conf_id: "neurips2023",
      review_scores: [7.0, 3.0, 3.0, 3.0, 6.0],
      review_score_avg: 4.4,
      review_confidences: [7.0, 3.0, 3.0, 3.0, 6.0],
      review_confidence_avg: 3.8,
    },
  ],
  neurips2024: [
    {
      id: "sxZlp9ZoHD",
      semantic_scholar_id: "240103933ffe3dac2179cc160a2bd91299357a53",
      raw_decision: "NeurIPS 2024 Rejected",
      normalized_decision: "Reject",
      title:
        "Retentive Network: A Successor to Transformer for Large Language Models",
      abstract:
        "In this work, we propose Retentive Network (RetNet) as a foundation architecture for large language models, simultaneously achieving training parallelism, low-cost inference, and good performance. We theoretically derive the connection between recurrence and attention. Then we propose the retention mechanism for sequence modeling, which supports three computation paradigms, i.e., parallel, recurrent, and chunkwise recurrent. Specifically, the parallel representation allows for training parallelism. The recurrent representation enables low-cost \n inference, which improves decoding throughput, latency, and GPU memory without sacrificing performance. The chunkwise recurrent representation facilitates efficient long-sequence modeling with linear complexity, where each chunk is encoded parallelly while recurrently summarizing the chunks. Experimental results on language modeling show that RetNet achieves favorable scaling results, parallel training, low-cost deployment, and efficient inference.",
      keywords: ["Retentive Network", "Model Architecture"],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/240103933ffe3dac2179cc160a2bd91299357a53",
      citation_count: 282,
      authors: [
        "Yutao Sun",
        "Li Dong",
        "Shaohan Huang",
        "Shuming Ma",
        "Yuqing Xia",
        "Jilong Xue",
        "Jianyong Wang",
        "Furu Wei",
      ],
      authorIds: [
        "2108540694",
        "145307652",
        "3110003",
        "2118866998",
        "4866834",
        "2870618",
        "2115642141",
        "49807919",
      ],
      conference_year: 2024,
      conference_name: "neurips",
      conf_id: "neurips2024",
      review_scores: [5, 4, 6],
      review_score_avg: 5.0,
      review_confidences: [5, 4, 6],
      review_confidence_avg: 4.3333333333,
    },
    {
      id: "zFHJUSTZka",
      semantic_scholar_id: "b46d05bcf42295b872f3cebf875643d2e66496a4",
      raw_decision: "NeurIPS 2024 Rejected",
      normalized_decision: "Reject",
      title: "Direct Language Model Alignment from Online AI Feedback",
      abstract:
        "Direct alignment from preferences (DAP) methods, such as DPO, have recently emerged as efficient alternatives to reinforcement learning from human feedback (RLHF), that do not require a separate reward model. However, the preference datasets used in DAP methods are usually collected ahead of training and never updated, thus the feedback is purely offline. Moreover, responses in these datasets are often sampled from a language model distinct from the one being aligned, and since the model evolves over training, the alignment phase is inevitably off-policy. In this study, we posit that online feedback is key and improves DAP methods. Our method, online AI feedback (OAIF), uses an LLM as annotator: on each training iteration, we sample two responses from the current model and prompt the LLM annotator to choose which one is preferred, thus providing online feedback. Despite its simplicity, we demonstrate via human evaluation in several tasks that OAIF outperforms both offline DAP and RLHF methods. We further show that the feedback leveraged in OAIF is easily controllable, via instruction prompts to the LLM annotator.",
      keywords: [
        "LLM Alignment; AI Feedback;  On-policy Learning; Online Feedback",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/b46d05bcf42295b872f3cebf875643d2e66496a4",
      citation_count: 114,
      authors: [
        "Shangmin Guo",
        "Biao Zhang",
        "Tianlin Liu",
        "Tianqi Liu",
        "Misha Khalman",
        "Felipe Llinares-L\u00f3pez",
        "Alexandre Ram\u00e9",
        "Thomas Mesnard",
        "Yao Zhao",
        "Bilal Piot",
        "Johan Ferret",
        "Mathieu Blondel",
      ],
      authorIds: [
        "2283016358",
        "48335426",
        "2281864351",
        "2239381730",
        "2140488873",
        "2283854295",
        "26384385",
        "2237423540",
        "2266491128",
        "1808897",
        "151047979",
        "2281742464",
      ],
      conference_year: 2024,
      conference_name: "neurips",
      conf_id: "neurips2024",
      review_scores: [4, 4, 5, 3],
      review_score_avg: 4.0,
      review_confidences: [4, 4, 5, 3],
      review_confidence_avg: 3.75,
    },
    {
      id: "vYmvgxpgwH",
      semantic_scholar_id: "b945115f175231d7fafefbdeacdc40edc391273f",
      raw_decision: "NeurIPS 2024 Rejected",
      normalized_decision: "Reject",
      title:
        "Inference Scaling Laws: An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models",
      abstract:
        "The optimal training configurations of large language models (LLMs) with respect to model sizes and compute budgets have been extensively studied. But how to optimally configure LLMs during inference has not been explored in sufficient depth. We study compute-optimal inference: designing models and inference strategies that optimally trade off additional inference-time compute for improved performance. As a first step towards understanding and designing compute-optimal inference methods, we assessed the effectiveness and computational efficiency of multiple inference strategies such as Greedy Search, Majority Voting, Best-of-N, Weighted Voting, and their variants on two different Tree Search algorithms, involving different model sizes (e.g., 7B and 34B) and computational budgets. We found that a smaller language model with a novel tree search algorithm typically achieves a Pareto-optimal trade-off. These results highlight the potential benefits of deploying smaller models equipped with more sophisticated decoding algorithms in end-devices to enhance problem-solving accuracy. For instance, we show that the Llemma-7B model can achieve competitive accuracy to a Llemma-34B model on MATH500 while using 2\u00d7 less FLOPs. Our findings could potentially apply to any generation task with a well-defined measure of success.",
      keywords: [
        "Tree Search",
        "Language Model Problem-Solving",
        "Compute-Optimal Scaling",
      ],
      accepted: false,
      publication_venue: null,
      publication_venue_id: null,
      url: "https://www.semanticscholar.org/paper/b945115f175231d7fafefbdeacdc40edc391273f",
      citation_count: 89,
      authors: [
        "Yangzhen Wu",
        "Zhiqing Sun",
        "Shanda Li",
        "S. Welleck",
        "Yiming Yang",
      ],
      authorIds: [
        "2314347409",
        "48064856",
        "2257057803",
        "2129663",
        "2257099254",
      ],
      conference_year: 2024,
      conference_name: "neurips",
      conf_id: "neurips2024",
      review_scores: [6, 5, 4],
      review_score_avg: 5.0,
      review_confidences: [6, 5, 4],
      review_confidence_avg: 2.6666666667,
    },
    {
      id: "rcch4UsMBi",
      semantic_scholar_id: "3d4fbb81345bac2a4ec3e6d89e36adf42b214fae",
      raw_decision: "NeurIPS 2024 Rejected",
      normalized_decision: "Reject",
      title:
        "Synthetic Data (Almost) from Scratch: Generalized Instruction Tuning for Language Models",
      abstract:
        "We introduce Generalized Instruction Tuning (called GLAN), a general and scalable method for instruction tuning of Large Language Models (LLMs). \nUnlike prior work that relies on seed examples or existing datasets to construct instruction tuning data, \nGLAN exclusively utilizes a pre-curated taxonomy of human knowledge and capabilities as input and generates large-scale \nsynthetic instruction data across all disciplines.\nSpecifically, inspired by the systematic structure in human education system, we build the taxonomy by decomposing human knowledge and capabilities to various fields, sub-fields and ultimately, distinct disciplines semi-automatically, facilitated by LLMs. \nSubsequently, we generate a comprehensive list of subjects for every discipline and proceed to design a syllabus tailored to each subject, again utilizing LLMs.\nWith the fine-grained key concepts detailed in every class session of the syllabus, we are able to generate diverse instructions with a broad coverage across the entire spectrum of human knowledge and skills. \nExtensive experiments on large language models (e.g., Mistral) demonstrate that GLAN excels in multiple dimensions from mathematical reasoning, coding, academic exams, logical reasoning to general instruction following without using task-specific training data of these tasks. In addition, GLAN allows for easy customization and new fields or skills can be added by simply incorporating a new node into our taxonomy.",
      keywords: ["Synthetic data; large language models"],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/3d4fbb81345bac2a4ec3e6d89e36adf42b214fae",
      citation_count: 45,
      authors: [
        "Haoran Li",
        "Qingxiu Dong",
        "Zhengyang Tang",
        "Chaojun Wang",
        "Xingxing Zhang",
        "Haoyang Huang",
        "Shaohan Huang",
        "Xiaolong Huang",
        "Zeqiang Huang",
        "Dongdong Zhang",
        "Yuxian Gu",
        "Xin Cheng",
        "Xun Wang",
        "Si-Qing Chen",
        "Li Dong",
        "Wei Lu",
        "Zhifang Sui",
        "Benyou Wang",
        "Wai Lam",
        "Furu Wei",
      ],
      authorIds: [
        "47893214",
        "2047143813",
        "2284834012",
        "2144522700",
        "2284863493",
        "15086992",
        "3110003",
        "2116768132",
        "2284830389",
        "2273919921",
        "2116405624",
        "2193630544",
        "2193104542",
        "2263708536",
        "145307652",
        "2261087197",
        "3335836",
        "2284827140",
        "2273358252",
        "2253471545",
      ],
      conference_year: 2024,
      conference_name: "neurips",
      conf_id: "neurips2024",
      review_scores: [7, 5, 4, 6],
      review_score_avg: 5.5,
      review_confidences: [7, 5, 4, 6],
      review_confidence_avg: 3.5,
    },
    {
      id: "5tOVh81aze",
      semantic_scholar_id: "98755a7ca75afbb29a19f8129b9f25796ad0e0b7",
      raw_decision: "NeurIPS 2024 Rejected",
      normalized_decision: "Reject",
      title:
        "Language models scale reliably with over-training and on downstream tasks",
      abstract:
        'Scaling laws are useful guides for derisking expensive training runs, as they predict performance of large models using cheaper, small-scale experiments. However, there remain gaps between current scaling studies and how language models are ultimately trained and evaluated. For instance, scaling is usually studied in the compute-optimal training regime (i.e., "Chinchilla optimal" regime). In contrast, models are often over-trained to reduce inference costs. Moreover, scaling laws mostly predict loss on next-token prediction, but models are usually compared on downstream task performance. To address both shortcomings, we create a testbed of 104 models with 0.011B to 6.9B parameters trained with various numbers of tokens on three data distributions. First, we fit scaling laws that extrapolate in both the amount of over-training and the number of model parameters. This enables us to predict the validation loss of a 1.4B parameter, 900B token run (i.e., 32$\\times$ over-trained) and a 6.9B parameter, 138B token run (i.e., a compute-optimal run)\u2013\u2013each from experiments that take 300$\\times$ less compute. Second, we relate the perplexity of a language model to its downstream task performance by proposing a power law. We use this law to predict top-1 error averaged over downstream tasks for the two aforementioned models, using experiments that take 20$\\times$ less compute.',
      keywords: [
        "large language models",
        "scaling laws",
        "over-training",
        "task prediction",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/98755a7ca75afbb29a19f8129b9f25796ad0e0b7",
      citation_count: 38,
      authors: [
        "S. Gadre",
        "Georgios Smyrnis",
        "Vaishaal Shankar",
        "Suchin Gururangan",
        "Mitchell Wortsman",
        "Rulin Shao",
        "Jean-Pierre Mercat",
        "Alex Fang",
        "Jeffrey Li",
        "Sedrick Scott Keh",
        "Rui Xin",
        "Marianna Nezhurina",
        "Igor Vasiljevic",
        "J. Jitsev",
        "Alexandros G. Dimakis",
        "Gabriel Ilharco",
        "Shuran Song",
        "Thomas Kollar",
        "Y. Carmon",
        "Achal Dave",
        "Reinhard Heckel",
        "Niklas Muennighoff",
        "Ludwig Schmidt",
      ],
      authorIds: [
        "1387466862",
        "1438310376",
        "34961417",
        "40895369",
        "52193502",
        "2287946530",
        "72847120",
        "46372713",
        "2287821949",
        "150299584",
        "2291068532",
        "2174178585",
        "2291068185",
        "2191688",
        "2257301126",
        "1387994137",
        "2265621012",
        "2283843631",
        "2444742",
        "2298523",
        "2291068369",
        "2037383772",
        "2253541812",
      ],
      conference_year: 2024,
      conference_name: "neurips",
      conf_id: "neurips2024",
      review_scores: [7, 5, 5],
      review_score_avg: 5.6666666667,
      review_confidences: [7, 5, 5],
      review_confidence_avg: 3.0,
    },
    {
      id: "7yqjVgWWxx",
      semantic_scholar_id: "7a73cc4bc0ce80661b5acbb51bbde30ea5167280",
      raw_decision: "NeurIPS 2024 Rejected",
      normalized_decision: "Reject",
      title:
        "Your Absorbing Discrete Diffusion Secretly Models the Conditional Distributions of Clean Data",
      abstract:
        "Discrete diffusion models with absorbing processes have shown promise in language modeling. The key quantities to be estimated are the ratios between the marginal probabilities of two transitive states at all timesteps, called the concrete score. In this paper, we reveal that the concrete score in absorbing diffusion can be expressed as conditional probabilities of clean data, multiplied by a time-dependent scalar in an analytic form. Motivated by the finding, we propose reparameterized absorbing discrete diffusion (RADD), a dedicated diffusion model that characterizes the time-independent conditional probabilities. Besides its simplicity, RADD can reduce the number of function evaluations (NFEs) by caching the output of the time-independent network when the noisy sample remains unchanged in a sampling interval. Empirically, RADD is up to 3.5 times faster while consistently achieving a better performance than the strongest baseline.\nBuilt upon the new factorization of the concrete score, we further prove a surprising result that the exact likelihood of absorbing diffusion can be rewritten to a simple form (named denoise cross-entropy) and then estimated efficiently by the Monte Carlo method. The resulting approach also applies to the original parameterization of the concrete score. It significantly advances the state-of-the-art discrete diffusion on 5 zero-shot language modeling benchmarks (measured by perplexity) at the GPT-2 scale.",
      keywords: [
        "Discrete Diffusion Models",
        "Diffusion Models",
        "Language Modeling",
        "Concrete Score",
        "Score Entropy",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/7a73cc4bc0ce80661b5acbb51bbde30ea5167280",
      citation_count: 24,
      authors: [
        "Jingyang Ou",
        "Shen Nie",
        "Kaiwen Xue",
        "Fengqi Zhu",
        "Jiacheng Sun",
        "Zhenguo Li",
        "Chongxuan Li",
      ],
      authorIds: [
        "2304954469",
        "2191077545",
        "2054220757",
        "2305318534",
        "2305734851",
        "2305329016",
        "2253823025",
      ],
      conference_year: 2024,
      conference_name: "neurips",
      conf_id: "neurips2024",
      review_scores: [6, 6, 6],
      review_score_avg: 6.0,
      review_confidences: [6, 6, 6],
      review_confidence_avg: 3.3333333333,
    },
    {
      id: "RGnjY6l2HT",
      semantic_scholar_id: "66a05b7405aa3591a8fb74e5958c8d6dc994606e",
      raw_decision: "NeurIPS 2024 Rejected",
      normalized_decision: "Reject",
      title:
        "UniEdit: A Unified Tuning-Free Framework for Video Motion and Appearance Editing",
      abstract:
        "Recent advances in text-guided video editing have showcased promising results in appearance editing (e.g., stylization). However, video motion editing in the temporal dimension (e.g., from eating to waving), which distinguishes video editing from image editing, is underexplored. In this work, we present UniEdit, a tuning-free framework that supports both video motion and appearance editing by harnessing the power of a pre-trained text-to-video generator within an inversion-then-generation framework.\nTo realize motion editing while preserving source video content, based on the insights that temporal and spatial self-attention layers encode inter-frame and intra-frame dependency respectively, we introduce auxiliary motion-reference and reconstruction branches to produce text-guided motion and source features respectively. The obtained features are then injected into the main editing path via temporal and spatial self-attention layers. Extensive experiments demonstrate that UniEdit covers video motion editing and various appearance editing scenarios, and surpasses the state-of-the-art methods.",
      keywords: ["Video Editing", "Diffusion Model"],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/66a05b7405aa3591a8fb74e5958c8d6dc994606e",
      citation_count: 24,
      authors: [
        "Jianhong Bai",
        "Tianyu He",
        "Yuchi Wang",
        "Junliang Guo",
        "Haoji Hu",
        "Zuozhu Liu",
        "Jiang Bian",
      ],
      authorIds: [
        "2155929084",
        "2259935939",
        "2268433805",
        "2284789660",
        "2254179601",
        "2284825324",
        "2192822005",
      ],
      conference_year: 2024,
      conference_name: "neurips",
      conf_id: "neurips2024",
      review_scores: [5, 5, 6],
      review_score_avg: 5.3333333333,
      review_confidences: [5, 5, 6],
      review_confidence_avg: 2.3333333333,
    },
    {
      id: "uvvVjWP1aj",
      semantic_scholar_id: "07d73ca3e2b7bbb4ea09309d96834cd2a036c237",
      raw_decision: "NeurIPS 2024 Rejected",
      normalized_decision: "Reject",
      title:
        "AI Sandbagging: Language Models can Strategically Underperform on Evaluations",
      abstract:
        "Trustworthy capability evaluations are crucial for ensuring the safety of AI systems, and are becoming a key component of AI regulation. However, the developers of an AI system, or the AI system itself, may have incentives for evaluations to understate the AI's actual capability. These conflicting interests lead to the problem of *sandbagging* \u2013 which we define as *strategic underperformance on an evaluation*. In this paper we assess sandbagging capabilities in contemporary language models (LMs). We prompt frontier LMs, like GPT-4 and Claude 3 Opus, to selectively underperform on dangerous capability evaluations, while maintaining performance on general (harmless) capability evaluations. Moreover, we find that models can be fine-tuned, on a synthetic dataset, to hide specific capabilities unless given a password. This behaviour generalizes to high-quality, held-out benchmarks such as WMDP. In addition, we show that both frontier and smaller models can be prompted or password-locked to target specific scores on a capability evaluation. We have mediocre success in password-locking a model to mimic the answers a weaker model would give. Overall, our results suggest that capability evaluations are vulnerable to sandbagging. This vulnerability decreases the trustworthiness of evaluations, and thereby undermines important safety decisions regarding the development and deployment of advanced AI systems.\n\nWe publish our code and results at https://anonymous.4open.science/r/Sandbagging-8305/README.md",
      keywords: [
        "Alignment",
        "AI safety",
        "sandbagging",
        "AI evaluations",
        "AI governance",
        "NLP",
        "LLM",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/07d73ca3e2b7bbb4ea09309d96834cd2a036c237",
      citation_count: 23,
      authors: [
        "Teun van der Weij",
        "Felix Hofst\u00e4tter",
        "Ollie Jaffe",
        "Samuel F. Brown",
        "Francis Rhys Ward",
      ],
      authorIds: [
        "2221010426",
        "2310323657",
        "2305679880",
        "2306690172",
        "2305679954",
      ],
      conference_year: 2024,
      conference_name: "neurips",
      conf_id: "neurips2024",
      review_scores: [8, 4, 5, 5],
      review_score_avg: 5.5,
      review_confidences: [8, 4, 5, 5],
      review_confidence_avg: 3.5,
    },
    {
      id: "hGhLd2ByoR",
      semantic_scholar_id: "e0652850ad3744dd4c4da1046bdaacc0df20bec3",
      raw_decision: "NeurIPS 2024 Rejected",
      normalized_decision: "Reject",
      title: "Challenges with unsupervised LLM knowledge discovery",
      abstract:
        "We reveal novel pathologies in existing unsupervised methods seeking to discover latent knowledge from large language model (LLM) activations---instead of knowledge they seem to discover whatever feature of the activations is most prominent. These methods search for hypothesised consistency structures of latent knowledge. We first prove theoretically that arbitrary features (not just knowledge) satisfy the consistency structure of a popular unsupervised knowledge-elicitation method: contrast-consistent search. We then present a series of experiments showing settings in which this and other unsupervised methods result in classifiers that do not predict knowledge, but instead predict a different prominent feature. We conclude that existing unsupervised methods for discovering latent knowledge are insufficient, and we contribute sanity checks to apply to evaluating future knowledge elicitation methods. We offer conceptual arguments grounded in identification issues such as distinguishing a model's knowledge from that of a simulated character's that are likely to persist in future unsupervised methods.",
      keywords: [
        "Eliciting latent knowledge",
        "large language models",
        "deception",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/e0652850ad3744dd4c4da1046bdaacc0df20bec3",
      citation_count: 22,
      authors: [
        "Sebastian Farquhar",
        "Vikrant Varma",
        "Zachary Kenton",
        "Johannes Gasteiger",
        "Vladimir Mikulik",
        "Rohin Shah",
      ],
      authorIds: [
        "2274932640",
        "144711236",
        "40947466",
        "2226693699",
        "148305440",
        "2290032398",
      ],
      conference_year: 2024,
      conference_name: "neurips",
      conf_id: "neurips2024",
      review_scores: [6, 4, 3],
      review_score_avg: 4.3333333333,
      review_confidences: [6, 4, 3],
      review_confidence_avg: 2.6666666667,
    },
    {
      id: "VajjTXRj6J",
      semantic_scholar_id: "5c9eec060bd9b7af1b8f71a18c0402de3dc98388",
      raw_decision: "NeurIPS 2024 Rejected",
      normalized_decision: "Reject",
      title: "Robust Preference Optimization through Reward Model Distillation",
      abstract:
        "Language model (LM) post-training (or alignment) involves maximizing a reward function that is derived from preference annotations. Recently, Direct Preference Optimization (DPO) has gained popularity as an offline alignment method that is directly supervised with human preference annotations. However, DPO is overconfident about preference annotations, implicitly assigning them rewards of infinite magnitude. This frequently leads to degenerate policies, sometimes causing even the probability of the preferred output to go to zero. In this work, we propose to use distillation to combat overconfidence: we train the LM to match the reward distribution induced by a model trained on the preference data. Moreover, to account for uncertainty in the reward model we are distilling from, we optimize against a family of reward models, which may be instantiated either implicitly or explicitly. Our results show that both measures lead to improved robustness to distribution shift in preference annotations, while preserving the supervised nature of DPO.",
      keywords: [
        "alignment",
        "dpo",
        "preferences",
        "pessimism",
        "rlhf",
        "llms",
      ],
      accepted: false,
      publication_venue: "arXiv.org",
      publication_venue_id: "1901e811-ee72-4b20-8f7e-de08cd395a10",
      url: "https://www.semanticscholar.org/paper/5c9eec060bd9b7af1b8f71a18c0402de3dc98388",
      citation_count: 21,
      authors: [
        "Adam Fisch",
        "Jacob Eisenstein",
        "Vicky Zayats",
        "Alekh Agarwal",
        "Ahmad Beirami",
        "Chirag Nagpal",
        "Peter Shaw",
        "Jonathan Berant",
      ],
      authorIds: [
        "2274102752",
        "2256409622",
        "2303651624",
        "2274120058",
        "2258964830",
        "2963503",
        "38759328",
        "1750652",
      ],
      conference_year: 2024,
      conference_name: "neurips",
      conf_id: "neurips2024",
      review_scores: [6, 6, 6],
      review_score_avg: 6.0,
      review_confidences: [6, 6, 6],
      review_confidence_avg: 3.6666666667,
    },
  ],
};
